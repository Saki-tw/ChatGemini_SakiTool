# 自動快取完整指南

**專案**: ChatGemini_SakiTool
**版本**: v1.0.2
**最後更新**: 2025-10-24

本指南詳細說明 v1.0.1 新增的自動快取功能，協助您最大化節省 API 成本。

---

## 📖 什麼是快取？

Gemini API 的 Context Caching 功能允許將重複使用的內容（如程式碼、文檔、對話歷史）快取起來，後續查詢時只需付快取讀取費用（約原價的 10%），大幅降低成本。

### 節省效果

| 模型 | 一般輸入價格 | 快取讀取價格 | 節省 |
|------|-------------|-------------|------|
| Gemini 2.5 Flash | NT$ 0.000031/token | NT$ 0.0000031/token | 90% |
| Gemini 2.5 Pro | NT$ 0.0974/1K tokens | NT$ 0.0244/1K tokens | 75% |

---

## 🚀 快速開始

### 第一次啟動

執行 `ChatGemini` 或 `python3 gemini_chat.py`，會看到：

```
啟用自動快取？
  [y] 是（推薦，5000 tokens 自動建立）
  [c] 自訂設定
  [n] 否

你的選擇 [y]:
```

**推薦選擇**: 直接按 `Enter` 使用預設設定（5000 tokens 自動觸發）。

### 自訂設定 (選 `c`)

```
請輸入自動快取門檻（tokens，最低 1024）: 3000
```

輸入您希望累積多少 tokens 後自動建立快取。

---

## 💡 使用方式

### 自動模式（推薦）

啟用自動快取後，系統會：

1. **累積對話內容**：每次對話都會累積 tokens
2. **達到門檻自動觸發**：例如累積到 5000 tokens 時
3. **顯示通知**：
   ```
   🔔 已達快取門檻（5,234 tokens），自動建立快取...
   ✅ 快取建立成功！後續對話將自動使用快取節省成本。

   💰 快取成本分析：
   建立成本: NT$ 0.16（一次性）
   後續每次查詢節省: NT$ 0.36（省 90%）
   損益平衡: 1 次查詢
   ```
4. **自動使用快取**：後續對話自動載入快取，成本大幅降低

### 手動控制

#### 立即建立快取
```bash
你: [cache:now]
```

不管是否達到門檻，立即建立快取。

#### 暫停自動快取
```bash
你: [cache:off]
```

停用自動觸發，但仍可使用 `[cache:now]` 手動建立。

#### 恢復自動快取
```bash
你: [cache:on]
```

重新啟用自動觸發。

#### 本次對話不列入快取
```bash
你: [no-cache] 順便問一下，Python 有什麼新功能？
```

這次對話不會加入快取內容，適合臨時問題或不重要的內容。

---

## 📊 成本分析

### 範例 1：5000 tokens 快取

假設使用 Gemini 2.5 Flash：

```
快取建立成本（一次性）: NT$ 0.16

後續每次查詢（假設 5000 tokens 輸入）:
  不使用快取: NT$ 0.40
  使用快取:   NT$ 0.04
  每次節省:   NT$ 0.36（省 90%）

損益平衡: 1 次查詢後開始真正省錢
```

**結論**: 只要後續查詢 1 次以上，就划算。

### 範例 2：10000 tokens 快取

```
快取建立成本（一次性）: NT$ 0.31

後續每次查詢（假設 10000 tokens 輸入）:
  不使用快取: NT$ 0.80
  使用快取:   NT$ 0.08
  每次節省:   NT$ 0.72（省 90%）

損益平衡: 1 次查詢
```

---

## 🎯 使用場景

### 場景 1：程式碼分析

```bash
# 第一次讀取多個檔案
你: 讀取 gemini_chat.py 讀取 gemini_cache_manager.py 分析這兩個檔案的關聯性

✅ 已讀取文字檔: gemini_chat.py (3,200 tokens)
✅ 已讀取文字檔: gemini_cache_manager.py (1,900 tokens)

Gemini: [詳細分析...]

# 累積到門檻後自動建立快取
🔔 已達快取門檻（5,234 tokens），自動建立快取...
✅ 快取建立成功！

# 後續問題使用快取，省 90% 成本
你: CacheManager 類別有哪些公開方法？

Gemini: [使用快取回應...]
💰 本次成本: NT$ 0.05（使用快取節省 89%）
```

### 場景 2：長文檔理解

```bash
# 讀取長文檔
你: 讀取 API_documentation.md 幫我整理重點

✅ 已讀取文字檔: API_documentation.md (8,500 tokens)

# 立即建立快取
你: [cache:now]

✅ 快取建立成功！

# 後續多次查詢都使用快取
你: 這個 API 的認證方式是什麼？
你: 有哪些端點可以用？
你: 速率限制是多少？

💰 累積節省: NT$ 2.16（使用快取 3 次）
```

### 場景 3：深入技術討論

```bash
# 複雜問題需要深度思考
你: [think:8000] 解釋量子糾纏的物理原理，並說明在量子計算中的應用

Gemini: [詳細回應，使用 8000 tokens 思考預算...]

# 後續追問使用快取
你: 量子糾纏在量子通訊中的角色？

💰 本次成本: NT$ 0.08（使用快取節省 85%）
```

---

## ⚙️ 進階設定

### 對話中切換設定

```bash
# 查看目前快取設定
你: cache

顯示:
快取狀態: 已啟用
自動觸發: 開啟
門檻值: 5000 tokens
目前累積: 3,200 tokens
```

### 不同模型的最低門檻

| 模型 | 最低 tokens 要求 |
|------|-----------------|
| gemini-2.5-flash | 1024 |
| gemini-2.5-flash-8b | 1024 |
| gemini-2.5-pro | 4096 |
| gemini-2.0-flash | 1024 |

**注意**: 如果門檻設定低於模型要求，會顯示錯誤訊息。

### 快取過期時間

- **預設**: 60 分鐘
- **過期後**: 系統會自動更新快取
- **使用者無需手動處理**

---

## 🐛 常見問題

### Q: 快取建立失敗，顯示 tokens 不足

**原因**: 模型有最低 tokens 要求（例如 gemini-2.5-pro 需要 4096 tokens）

**解決方法**: 繼續對話累積更多內容，或手動設定更高的門檻值。

---

### Q: 如何知道快取是否在使用？

**答案**: 對話成本顯示會包含節省百分比：
```
💰 本次成本: NT$ 0.05（使用快取節省 89%）
```

---

### Q: 快取會一直存在嗎？

**答案**: 快取有 60 分鐘 TTL（Time To Live），過期後系統會自動更新。

---

### Q: 切換模型後快取還有效嗎？

**答案**: 需要重新建立快取，因為不同模型的快取不共用。

---

### Q: 臨時問題不想列入快取怎麼辦？

**答案**: 使用 `[no-cache]` 標籤：
```bash
你: [no-cache] 現在幾點？
```

---

### Q: 可以手動刪除快取嗎？

**答案**: 使用 `clear` 指令清除對話歷史，快取會一併清除。

---

### Q: 快取建立會影響回應速度嗎？

**答案**: 建立快取約需 1-2 秒，但後續查詢會更快（不需重新處理所有內容）。

---

## 💡 最佳實踐

### 1. 啟動時就設定好
第一次執行時選擇 `[y]` 使用推薦設定，無腦省錢。

### 2. 長對話才啟用
如果只是簡單問答（1-2 輪），不需要快取。

### 3. 讀取大量檔案時立即建立
```bash
你: 讀取 file1.py 讀取 file2.py 讀取 file3.py
你: [cache:now]
```

### 4. 臨時問題使用 [no-cache]
不重要的內容不要污染快取。

### 5. 定期檢查累積量
```bash
你: cache
```
查看目前累積多少 tokens。

---

## 🔗 相關文檔

- [功能實作清單](FEATURES_IMPLEMENTED.md)
- [媒體檔案指南](MEDIA_FILES_GUIDE.md)
- [API 金鑰設定](API_KEY_SETUP.md)

---

**作者**: Saki-TW (Saki@saki-studio.com.tw) with Claude
**最後更新**: 2025-10-24
**版本**: v1.0.2
