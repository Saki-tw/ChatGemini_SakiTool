#!/usr/bin/env python3
"""
Gemini è‡ªå‹•å ´æ™¯æª¢æ¸¬æ¨¡çµ„
ä½¿ç”¨ AI åˆ†æå½±ç‰‡é—œéµå¹€ï¼Œè‡ªå‹•æª¢æ¸¬å ´æ™¯è®ŠåŒ–ä¸¦ç”Ÿæˆå ´æ™¯ç´¢å¼•
"""
import os
import json
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn

# å°å…¥ç¾æœ‰æ¨¡çµ„
from gemini_video_preprocessor import VideoPreprocessor
from utils.api_client import get_gemini_client
from google.genai import types

# å°å…¥åƒ¹æ ¼æ¨¡çµ„
from utils.pricing_loader import get_pricing_calculator, PRICING_ENABLED
from gemini_pricing import USD_TO_TWD

console = Console()
client = get_gemini_client()

# åˆå§‹åŒ–åƒ¹æ ¼è¨ˆç®—å™¨
global_pricing_calculator = get_pricing_calculator(silent=True)


@dataclass
class Scene:
    """å ´æ™¯è³‡æ–™çµæ§‹"""
    id: int
    start_time: float          # é–‹å§‹æ™‚é–“ï¼ˆç§’ï¼‰
    end_time: float            # çµæŸæ™‚é–“ï¼ˆç§’ï¼‰
    start_frame_path: str      # é–‹å§‹å¹€åœ–ç‰‡è·¯å¾‘
    end_frame_path: str        # çµæŸå¹€åœ–ç‰‡è·¯å¾‘
    description: str           # å ´æ™¯æè¿°
    confidence: float          # ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
    key_elements: List[str]    # é—œéµå…ƒç´ åˆ—è¡¨


class SceneDetector:
    """è‡ªå‹•å ´æ™¯æª¢æ¸¬å™¨"""

    def __init__(
        self,
        model_name: str = "gemini-2.0-flash-exp",
        output_dir: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–å ´æ™¯æª¢æ¸¬å™¨

        Args:
            model_name: ä½¿ç”¨çš„ Gemini æ¨¡å‹
            output_dir: è¼¸å‡ºç›®éŒ„
        """
        self.model_name = model_name
        self.preprocessor = VideoPreprocessor()

        if output_dir is None:
            # ä½¿ç”¨çµ±ä¸€è¼¸å‡ºç›®éŒ„é…ç½®
            from utils.path_manager import get_video_dir
            output_dir = str(get_video_dir('scenes'))
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)

    def detect_scenes(
        self,
        video_path: str,
        num_keyframes: int = 30,
        similarity_threshold: float = 0.7,
        show_cost: bool = True
    ) -> List[Scene]:
        """
        æª¢æ¸¬å½±ç‰‡ä¸­çš„å ´æ™¯è®ŠåŒ–

        Args:
            video_path: å½±ç‰‡è·¯å¾‘
            num_keyframes: æå–çš„é—œéµå¹€æ•¸é‡ï¼ˆé è¨­ 30ï¼‰
            similarity_threshold: ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆ0-1ï¼‰ï¼Œä½æ–¼æ­¤å€¼è¦–ç‚ºå ´æ™¯åˆ‡æ›
            show_cost: æ˜¯å¦é¡¯ç¤ºæˆæœ¬

        Returns:
            å ´æ™¯åˆ—è¡¨
        """
        console.print(Panel.fit(
            "[bold magenta]ğŸ¬ è‡ªå‹•å ´æ™¯æª¢æ¸¬[/bold magenta]",
            border_style="bright_magenta"
        ))

        # 1. æå–é—œéµå¹€
        console.print(f"\n[magenta]ğŸ“¹ åˆ†æå½±ç‰‡ï¼š{os.path.basename(video_path)}[/magenta]")

        # ç²å–å½±ç‰‡è³‡è¨Š
        video_info = self.preprocessor.get_video_info(video_path)
        duration = video_info["duration"]

        console.print(f"[dim]  æ™‚é•·ï¼š{duration:.2f} ç§’[/dim]")
        console.print(f"[dim]  å°‡æå– {num_keyframes} å€‹é—œéµå¹€[/dim]\n")

        # ä¿®æ”¹ extract_keyframes ç‚ºæ”¯æŒæ›´å¤šå¹€æ•¸
        keyframes = self._extract_uniform_frames(video_path, num_keyframes, duration)

        console.print(f"[bright_magenta]âœ“ å·²æå– {len(keyframes)} å€‹é—œéµå¹€[/green]\n")

        # 2. åˆ†ææ¯å€‹å¹€çš„å…§å®¹
        console.print("[magenta]ğŸ¤– ä½¿ç”¨ Gemini Vision åˆ†æé—œéµå¹€...[/magenta]\n")

        frame_descriptions = []
        total_cost = 0.0

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("{task.completed}/{task.total}"),
            console=console
        ) as progress:
            task = progress.add_task("åˆ†æä¸­", total=len(keyframes))

            for frame_data in keyframes:
                description = self._analyze_frame(
                    frame_data['path'],
                    frame_data['timestamp'],
                    show_cost=False
                )

                frame_descriptions.append({
                    **frame_data,
                    'description': description
                })

                progress.update(task, advance=1)

        # 3. æª¢æ¸¬å ´æ™¯è®ŠåŒ–
        console.print("\n[magenta]ğŸ” æª¢æ¸¬å ´æ™¯è®ŠåŒ–...[/magenta]")
        scenes = self._detect_scene_changes(
            frame_descriptions,
            similarity_threshold
        )

        console.print(f"[bright_magenta]âœ“ æª¢æ¸¬åˆ° {len(scenes)} å€‹å ´æ™¯[/green]\n")

        # 4. é¡¯ç¤ºæˆæœ¬
        if PRICING_ENABLED and show_cost and global_pricing_calculator:
            console.print(f"[dim]ğŸ’° æœ¬æ¬¡æˆæœ¬: NT${global_pricing_calculator.total_cost * USD_TO_TWD:.2f} (${global_pricing_calculator.total_cost:.6f})[/dim]\n")

        return scenes

    def _extract_uniform_frames(
        self,
        video_path: str,
        num_frames: int,
        duration: float
    ) -> List[Dict]:
        """
        ç­‰è·æå–é—œéµå¹€

        Args:
            video_path: å½±ç‰‡è·¯å¾‘
            num_frames: å¹€æ•¸
            duration: å½±ç‰‡æ™‚é•·

        Returns:
            å¹€è³‡è¨Šåˆ—è¡¨ [{'path': ..., 'timestamp': ...}, ...]
        """
        import subprocess

        # è¨ˆç®—æ™‚é–“é–“éš”
        interval = duration / (num_frames + 1)
        timestamps = [interval * (i + 1) for i in range(num_frames)]

        frame_paths = []
        base_name = os.path.splitext(os.path.basename(video_path))[0]

        for i, timestamp in enumerate(timestamps):
            output_filename = f"{base_name}_scene_frame_{i+1:03d}_{timestamp:.2f}s.jpg"
            output_path = os.path.join(self.preprocessor.output_dir, output_filename)

            cmd = [
                "ffmpeg",
                "-ss", str(timestamp),
                "-i", video_path,
                "-vframes", "1",
                "-q:v", "2",
                "-y",
                output_path
            ]

            try:
                subprocess.run(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    check=True
                )
                frame_paths.append({
                    'path': output_path,
                    'timestamp': timestamp,
                    'frame_number': i + 1
                })
            except subprocess.CalledProcessError as e:
                console.print(f"[magenta]è­¦å‘Šï¼šæå–å¹€ {i+1} å¤±æ•—[/yellow]")

        return frame_paths

    def _analyze_frame(
        self,
        frame_path: str,
        timestamp: float,
        show_cost: bool = False
    ) -> str:
        """
        åˆ†æå–®å€‹å¹€çš„å…§å®¹

        Args:
            frame_path: å¹€åœ–ç‰‡è·¯å¾‘
            timestamp: æ™‚é–“æˆ³
            show_cost: æ˜¯å¦é¡¯ç¤ºæˆæœ¬

        Returns:
            å¹€å…§å®¹æè¿°
        """
        # ä¸Šå‚³åœ–ç‰‡
        try:
            with open(frame_path, 'rb') as f:
                image_data = f.read()

            uploaded_file = client.files.upload(file=image_data)

            # åˆ†ææç¤º
            prompt = """è«‹ç°¡æ½”æè¿°é€™å€‹ç•«é¢çš„ä¸»è¦å…§å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. å ´æ™¯é¡å‹ï¼ˆå®¤å…§/æˆ¶å¤–/ç‰¹å¯«ç­‰ï¼‰
2. ä¸»è¦ç‰©é«”æˆ–äººç‰©
3. ä¸»è¦å‹•ä½œæˆ–ç‹€æ…‹
4. æ•´é«”æ°›åœ

ç”¨ 1-2 å¥è©±ç¸½çµå³å¯ã€‚"""

            # ç™¼é€è«‹æ±‚
            response = client.models.generate_content(
                model=self.model_name,
                contents=[uploaded_file, prompt]
            )

            # æå– tokens
            if PRICING_ENABLED and global_pricing_calculator:
                thinking_tokens = getattr(response.usage_metadata, 'thinking_tokens', 0)
                input_tokens = getattr(response.usage_metadata, 'prompt_tokens', 0)
                output_tokens = getattr(response.usage_metadata, 'candidates_tokens', 0)

                cost, _ = global_pricing_calculator.calculate_text_cost(
                    self.model_name,
                    input_tokens,
                    output_tokens,
                    thinking_tokens
                )

            return response.text.strip()

        except Exception as e:
            console.print(f"[magenta]è­¦å‘Šï¼šåˆ†æå¹€å¤±æ•—ï¼š{e}[/yellow]")
            return "ç„¡æ³•åˆ†æ"

    def _detect_scene_changes(
        self,
        frame_descriptions: List[Dict],
        threshold: float = 0.7
    ) -> List[Scene]:
        """
        æ ¹æ“šå¹€æè¿°æª¢æ¸¬å ´æ™¯è®ŠåŒ–

        Args:
            frame_descriptions: å¹€æè¿°åˆ—è¡¨
            threshold: ç›¸ä¼¼åº¦é–¾å€¼

        Returns:
            å ´æ™¯åˆ—è¡¨
        """
        scenes = []
        current_scene_start = 0
        scene_id = 1

        for i in range(1, len(frame_descriptions)):
            prev_desc = frame_descriptions[i-1]['description']
            curr_desc = frame_descriptions[i]['description']

            # ä½¿ç”¨ Gemini åˆ¤æ–·å…©å€‹æè¿°æ˜¯å¦å±¬æ–¼åŒä¸€å ´æ™¯
            is_same_scene = self._compare_scenes(prev_desc, curr_desc, threshold)

            if not is_same_scene:
                # å ´æ™¯åˆ‡æ›ï¼Œä¿å­˜å‰ä¸€å€‹å ´æ™¯
                scene = Scene(
                    id=scene_id,
                    start_time=frame_descriptions[current_scene_start]['timestamp'],
                    end_time=frame_descriptions[i-1]['timestamp'],
                    start_frame_path=frame_descriptions[current_scene_start]['path'],
                    end_frame_path=frame_descriptions[i-1]['path'],
                    description=self._summarize_scene(
                        frame_descriptions[current_scene_start:i]
                    ),
                    confidence=0.8,  # ç°¡åŒ–ç‰ˆæœ¬ä½¿ç”¨å›ºå®šå€¼
                    key_elements=self._extract_key_elements(
                        frame_descriptions[current_scene_start:i]
                    )
                )
                scenes.append(scene)

                # é–‹å§‹æ–°å ´æ™¯
                current_scene_start = i
                scene_id += 1

        # æ·»åŠ æœ€å¾Œä¸€å€‹å ´æ™¯
        scene = Scene(
            id=scene_id,
            start_time=frame_descriptions[current_scene_start]['timestamp'],
            end_time=frame_descriptions[-1]['timestamp'],
            start_frame_path=frame_descriptions[current_scene_start]['path'],
            end_frame_path=frame_descriptions[-1]['path'],
            description=self._summarize_scene(
                frame_descriptions[current_scene_start:]
            ),
            confidence=0.8,
            key_elements=self._extract_key_elements(
                frame_descriptions[current_scene_start:]
            )
        )
        scenes.append(scene)

        return scenes

    def _compare_scenes(
        self,
        desc1: str,
        desc2: str,
        threshold: float
    ) -> bool:
        """
        æ¯”è¼ƒå…©å€‹å ´æ™¯æè¿°æ˜¯å¦ç›¸ä¼¼

        Args:
            desc1: æè¿° 1
            desc2: æè¿° 2
            threshold: ç›¸ä¼¼åº¦é–¾å€¼

        Returns:
            æ˜¯å¦ç‚ºåŒä¸€å ´æ™¯
        """
        # ç°¡åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨é—œéµè©æ¯”è¼ƒ
        # åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­å¯ä»¥ä½¿ç”¨ Gemini çš„ embedding æˆ–æ›´ç²¾ç¢ºçš„æ¯”è¼ƒæ–¹æ³•

        # æå–é—œéµè©
        keywords1 = set(desc1.lower().split())
        keywords2 = set(desc2.lower().split())

        # è¨ˆç®— Jaccard ç›¸ä¼¼åº¦
        intersection = len(keywords1 & keywords2)
        union = len(keywords1 | keywords2)

        similarity = intersection / union if union > 0 else 0

        return similarity >= threshold

    def _summarize_scene(self, frames: List[Dict]) -> str:
        """ç¸½çµå ´æ™¯æè¿°"""
        if not frames:
            return "æœªçŸ¥å ´æ™¯"

        # ä½¿ç”¨ç¬¬ä¸€å¹€çš„æè¿°ä½œç‚ºå ´æ™¯æè¿°
        return frames[0]['description']

    def _extract_key_elements(self, frames: List[Dict]) -> List[str]:
        """æå–å ´æ™¯çš„é—œéµå…ƒç´ """
        # ç°¡åŒ–ç‰ˆæœ¬ï¼šå¾æè¿°ä¸­æå–åè©
        all_words = []
        for frame in frames:
            all_words.extend(frame['description'].split())

        # è¿”å›å‰ 5 å€‹å¸¸è¦‹è©ï¼ˆç°¡åŒ–ï¼‰
        from collections import Counter
        common_words = Counter(all_words).most_common(5)
        return [word for word, _ in common_words if len(word) > 2]

    def display_scenes(self, scenes: List[Scene]):
        """
        ä»¥è¡¨æ ¼å½¢å¼é¡¯ç¤ºå ´æ™¯

        Args:
            scenes: å ´æ™¯åˆ—è¡¨
        """
        table = Table(title="ğŸ¬ å ´æ™¯åˆ—è¡¨", show_header=True, header_style="bold magenta")

        console_width = console.width or 120
        table.add_column("#", style="dim", width=max(4, int(console_width * 0.03)))
        table.add_column("æ™‚é–“ç¯„åœ", width=max(18, int(console_width * 0.15)))
        table.add_column("æ™‚é•·", width=max(8, int(console_width * 0.08)))
        table.add_column("æè¿°", width=max(35, int(console_width * 0.40)))
        table.add_column("é—œéµå…ƒç´ ", width=max(20, int(console_width * 0.25)))

        for scene in scenes:
            duration = scene.end_time - scene.start_time
            time_range = f"{self._format_time(scene.start_time)} - {self._format_time(scene.end_time)}"

            table.add_row(
                str(scene.id),
                time_range,
                f"{duration:.1f}s",
                scene.description,
                ", ".join(scene.key_elements[:3]) if scene.key_elements else "-"
            )

        console.print("\n")
        console.print(table)
        console.print("\n")

    def save_scenes(
        self,
        scenes: List[Scene],
        video_path: str,
        format: str = "json"
    ) -> str:
        """
        ä¿å­˜å ´æ™¯ç´¢å¼•åˆ°æª”æ¡ˆ

        Args:
            scenes: å ´æ™¯åˆ—è¡¨
            video_path: åŸå½±ç‰‡è·¯å¾‘
            format: è¼¸å‡ºæ ¼å¼ï¼ˆjson æˆ– txtï¼‰

        Returns:
            è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        base_name = os.path.splitext(os.path.basename(video_path))[0]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if format == "json":
            output_file = os.path.join(
                self.output_dir,
                f"{base_name}_scenes_{timestamp}.json"
            )

            data = {
                'video': os.path.basename(video_path),
                'total_scenes': len(scenes),
                'generated_at': datetime.now().isoformat(),
                'scenes': [asdict(scene) for scene in scenes]
            }

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

        elif format == "txt":
            output_file = os.path.join(
                self.output_dir,
                f"{base_name}_scenes_{timestamp}.txt"
            )

            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"å½±ç‰‡å ´æ™¯ç´¢å¼•\n")
                f.write(f"{'=' * 60}\n\n")
                f.write(f"å½±ç‰‡ï¼š{os.path.basename(video_path)}\n")
                f.write(f"å ´æ™¯æ•¸é‡ï¼š{len(scenes)}\n")
                f.write(f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"{'=' * 60}\n\n")

                for scene in scenes:
                    duration = scene.end_time - scene.start_time
                    f.write(f"å ´æ™¯ {scene.id}\n")
                    f.write(f"-" * 40 + "\n")
                    f.write(f"æ™‚é–“ï¼š{self._format_time(scene.start_time)} - {self._format_time(scene.end_time)} ({duration:.1f}s)\n")
                    f.write(f"æè¿°ï¼š{scene.description}\n")
                    if scene.key_elements:
                        f.write(f"é—œéµå…ƒç´ ï¼š{', '.join(scene.key_elements)}\n")
                    f.write(f"\n")

        console.print(f"[bright_magenta]âœ“ å ´æ™¯ç´¢å¼•å·²ä¿å­˜ï¼š{output_file}[/green]")
        return output_file

    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ™‚é–“ï¼ˆç§’ -> mm:ssï¼‰"""
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes:02d}:{secs:02d}"


# ==================== CLI ä»‹é¢ ====================

def main():
    """ä¸»ç¨‹å¼"""
    import argparse

    parser = argparse.ArgumentParser(description='Gemini è‡ªå‹•å ´æ™¯æª¢æ¸¬')
    parser.add_argument('video', help='å½±ç‰‡æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--frames', type=int, default=30, help='æå–é—œéµå¹€æ•¸é‡ï¼ˆé è¨­ 30ï¼‰')
    parser.add_argument('--threshold', type=float, default=0.7, help='ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.7ï¼‰')
    parser.add_argument('--model', default='gemini-2.0-flash-exp', help='ä½¿ç”¨çš„æ¨¡å‹')
    parser.add_argument('--output', choices=['json', 'txt', 'both'], default='both', help='è¼¸å‡ºæ ¼å¼')

    args = parser.parse_args()

    # æª¢æŸ¥æª”æ¡ˆ
    if not os.path.isfile(args.video):
        console.print(f"[dim magenta]éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆï¼š{args.video}[/red]")
        return

    # å‰µå»ºæª¢æ¸¬å™¨
    detector = SceneDetector(model_name=args.model)

    # æª¢æ¸¬å ´æ™¯
    scenes = detector.detect_scenes(
        args.video,
        num_keyframes=args.frames,
        similarity_threshold=args.threshold
    )

    # é¡¯ç¤ºçµæœ
    detector.display_scenes(scenes)

    # ä¿å­˜çµæœ
    if args.output in ['json', 'both']:
        detector.save_scenes(scenes, args.video, format='json')

    if args.output in ['txt', 'both']:
        detector.save_scenes(scenes, args.video, format='txt')


if __name__ == "__main__":
    main()
