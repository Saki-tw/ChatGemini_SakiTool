#!/usr/bin/env python3
"""
å°è©±æ­·å²ç®¡ç†å™¨ - ConversationHistoryManager

åŠŸèƒ½ï¼š
- æœå°‹æ­·å²å°è©±
- åˆ—å‡ºå°è©±è¨˜éŒ„
- åŒ¯å‡ºå°è©±è¨˜éŒ„
- åˆªé™¤å°è©±è¨˜éŒ„ï¼ˆéœ€äºŒæ¬¡ç¢ºèªï¼‰
- çµ±è¨ˆè³‡è¨Š

è¨­è¨ˆåŸå‰‡ï¼š
- æ™ºèƒ½é™ç´šï¼šæ‰€æœ‰éŒ¯èª¤éƒ½å„ªé›…è™•ç†
- è¨˜æ†¶é«”å„ªåŒ–ï¼šä½¿ç”¨ç”Ÿæˆå™¨è™•ç†å¤§æª”æ¡ˆ
- é›¶ç ´å£æ€§ï¼šä¸ä¿®æ”¹ç¾æœ‰æ—¥èªŒæª”æ¡ˆ
- è³‡æ–™åˆªé™¤åŸå‰‡ï¼šå°è©±è¨˜éŒ„å±¬æ–¼ã€Œè²¡ç”¢ã€ï¼Œåˆªé™¤éœ€äºŒæ¬¡ç¢ºèª
"""

import json
import logging
from pathlib import Path
from typing import List, Dict, Optional, Generator, Tuple
from datetime import datetime
from collections import defaultdict

logger = logging.getLogger(__name__)

# å¾é…ç½®å–å¾—é è¨­æ—¥èªŒç›®éŒ„
try:
    from config import OUTPUT_DIRS
    DEFAULT_LOG_DIR = str(OUTPUT_DIRS.get('chat_logs', Path.cwd() / 'ChatLogs'))
except ImportError:
    DEFAULT_LOG_DIR = str(Path.cwd() / 'ChatLogs')


class ConversationHistoryManager:
    """
    å°è©±æ­·å²ç®¡ç†å™¨

    ä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å¼è™•ç†å¤§å‹æ—¥èªŒæª”æ¡ˆï¼Œé¿å…è¨˜æ†¶é«”æº¢å‡ºã€‚
    """

    def __init__(self, log_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–å°è©±æ­·å²ç®¡ç†å™¨

        Args:
            log_dir: æ—¥èªŒç›®éŒ„è·¯å¾‘ï¼Œé è¨­ä½¿ç”¨ DEFAULT_LOG_DIR
        """
        if log_dir is None:
            log_dir = DEFAULT_LOG_DIR

        self.log_dir = Path(log_dir)

        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        try:
            self.log_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            logger.warning(f"ç„¡æ³•å»ºç«‹æ—¥èªŒç›®éŒ„ {self.log_dir}: {e}")
            # é™ç´šï¼šä½¿ç”¨ç•¶å‰ç›®éŒ„
            self.log_dir = Path.cwd() / 'ChatLogs'
            self.log_dir.mkdir(parents=True, exist_ok=True)

    def _read_messages(self, log_file: Path) -> Generator[Dict, None, None]:
        """
        ç”Ÿæˆå™¨ï¼šé€è¡Œè®€å–å°è©±è¨˜éŒ„ï¼ˆJSONL æ ¼å¼ï¼‰

        Args:
            log_file: æ—¥èªŒæª”æ¡ˆè·¯å¾‘

        Yields:
            è¨Šæ¯å­—å…¸
        """
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        yield json.loads(line)
                    except json.JSONDecodeError as e:
                        logger.debug(f"è·³éç„¡æ•ˆ JSON è¡Œ: {e}")
                        continue
        except FileNotFoundError:
            logger.debug(f"æ—¥èªŒæª”æ¡ˆä¸å­˜åœ¨: {log_file}")
            return
        except Exception as e:
            logger.warning(f"è®€å–æ—¥èªŒå¤±æ•— {log_file}: {e}")
            return

    def _get_log_files(self) -> List[Path]:
        """
        ç²å–æ‰€æœ‰æ—¥èªŒæª”æ¡ˆï¼ŒæŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼ˆæ–°â†’èˆŠï¼‰

        Returns:
            æ—¥èªŒæª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        """
        try:
            files = list(self.log_dir.glob('*.jsonl'))
            # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
            files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
            return files
        except Exception as e:
            logger.warning(f"ç²å–æ—¥èªŒæª”æ¡ˆåˆ—è¡¨å¤±æ•—: {e}")
            return []

    def search(
        self,
        keyword: str,
        limit: int = 50,
        case_sensitive: bool = False
    ) -> List[Dict]:
        """
        æœå°‹å°è©±æ­·å²

        Args:
            keyword: æœå°‹é—œéµå­—
            limit: æœ€å¤šè¿”å›çµæœæ•¸é‡
            case_sensitive: æ˜¯å¦å€åˆ†å¤§å°å¯«

        Returns:
            æœå°‹çµæœåˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ åŒ…å«ï¼š
            {
                'file': æª”æ¡ˆåç¨±,
                'timestamp': æ™‚é–“æˆ³,
                'role': è§’è‰² (user/assistant),
                'content': å…§å®¹é è¦½ (å‰ 200 å­—å…ƒ),
                'full_content': å®Œæ•´å…§å®¹
            }
        """
        results = []
        search_keyword = keyword if case_sensitive else keyword.lower()

        try:
            for log_file in self._get_log_files():
                if len(results) >= limit:
                    break

                for message in self._read_messages(log_file):
                    if len(results) >= limit:
                        break

                    content = message.get('content', '')
                    search_content = content if case_sensitive else content.lower()

                    if search_keyword in search_content:
                        results.append({
                            'file': log_file.name,
                            'timestamp': message.get('timestamp', 'Unknown'),
                            'role': message.get('role', 'unknown'),
                            'content': content[:200] + ('...' if len(content) > 200 else ''),
                            'full_content': content
                        })
        except Exception as e:
            logger.error(f"æœå°‹éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            # é™ç´šï¼šè¿”å›å·²æ‰¾åˆ°çš„çµæœ

        return results

    def list_conversations(
        self,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        limit: int = 100
    ) -> List[Dict]:
        """
        åˆ—å‡ºå°è©±è¨˜éŒ„

        Args:
            start_date: é–‹å§‹æ—¥æœŸï¼ˆå¯é¸ï¼‰
            end_date: çµæŸæ—¥æœŸï¼ˆå¯é¸ï¼‰
            limit: æœ€å¤šè¿”å›æ•¸é‡

        Returns:
            å°è©±è¨˜éŒ„åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ åŒ…å«ï¼š
            {
                'file': æª”æ¡ˆåç¨±,
                'date': æ—¥æœŸ,
                'message_count': è¨Šæ¯æ•¸é‡,
                'size': æª”æ¡ˆå¤§å°ï¼ˆbytesï¼‰,
                'preview': å‰ 3 æ¢è¨Šæ¯é è¦½
            }
        """
        conversations = []

        try:
            for log_file in self._get_log_files():
                if len(conversations) >= limit:
                    break

                # æª¢æŸ¥æ—¥æœŸéæ¿¾
                file_time = datetime.fromtimestamp(log_file.stat().st_mtime)
                if start_date and file_time < start_date:
                    continue
                if end_date and file_time > end_date:
                    continue

                # çµ±è¨ˆè¨Šæ¯æ•¸é‡ä¸¦å–å¾—é è¦½
                message_count = 0
                preview_messages = []

                for message in self._read_messages(log_file):
                    message_count += 1
                    if len(preview_messages) < 3:
                        preview_messages.append({
                            'role': message.get('role', 'unknown'),
                            'content': message.get('content', '')[:100]
                        })

                conversations.append({
                    'file': log_file.name,
                    'date': file_time.strftime('%Y-%m-%d %H:%M:%S'),
                    'message_count': message_count,
                    'size': log_file.stat().st_size,
                    'preview': preview_messages
                })
        except Exception as e:
            logger.error(f"åˆ—å‡ºå°è©±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # é™ç´šï¼šè¿”å›å·²æ”¶é›†çš„åˆ—è¡¨

        return conversations

    def export(
        self,
        output_path: str,
        format: str = 'json',
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> Tuple[bool, str]:
        """
        åŒ¯å‡ºå°è©±è¨˜éŒ„

        Args:
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            format: åŒ¯å‡ºæ ¼å¼ ('json' æˆ– 'markdown')
            start_date: é–‹å§‹æ—¥æœŸï¼ˆå¯é¸ï¼‰
            end_date: çµæŸæ—¥æœŸï¼ˆå¯é¸ï¼‰

        Returns:
            (æˆåŠŸèˆ‡å¦, è¨Šæ¯)
        """
        try:
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)

            if format == 'json':
                return self._export_json(output_file, start_date, end_date)
            elif format == 'markdown':
                return self._export_markdown(output_file, start_date, end_date)
            else:
                return False, f"ä¸æ”¯æ´çš„æ ¼å¼: {format}"

        except Exception as e:
            logger.error(f"åŒ¯å‡ºå¤±æ•—: {e}")
            return False, str(e)

    def _export_json(
        self,
        output_file: Path,
        start_date: Optional[datetime],
        end_date: Optional[datetime]
    ) -> Tuple[bool, str]:
        """åŒ¯å‡ºç‚º JSON æ ¼å¼"""
        try:
            all_conversations = []

            for log_file in self._get_log_files():
                file_time = datetime.fromtimestamp(log_file.stat().st_mtime)
                if start_date and file_time < start_date:
                    continue
                if end_date and file_time > end_date:
                    continue

                conversation = {
                    'file': log_file.name,
                    'date': file_time.isoformat(),
                    'messages': list(self._read_messages(log_file))
                }
                all_conversations.append(conversation)

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(all_conversations, f, ensure_ascii=False, indent=2)

            return True, f"å·²åŒ¯å‡º {len(all_conversations)} å€‹å°è©±è‡³ {output_file}"

        except Exception as e:
            return False, f"JSON åŒ¯å‡ºå¤±æ•—: {e}"

    def _export_markdown(
        self,
        output_file: Path,
        start_date: Optional[datetime],
        end_date: Optional[datetime]
    ) -> Tuple[bool, str]:
        """åŒ¯å‡ºç‚º Markdown æ ¼å¼"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("# å°è©±æ­·å²è¨˜éŒ„\n\n")
                f.write(f"**åŒ¯å‡ºæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

                conversation_count = 0

                for log_file in self._get_log_files():
                    file_time = datetime.fromtimestamp(log_file.stat().st_mtime)
                    if start_date and file_time < start_date:
                        continue
                    if end_date and file_time > end_date:
                        continue

                    conversation_count += 1
                    f.write(f"## å°è©± {conversation_count}: {log_file.name}\n\n")
                    f.write(f"**æ—¥æœŸ**: {file_time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")

                    for message in self._read_messages(log_file):
                        role = message.get('role', 'unknown')
                        content = message.get('content', '')
                        timestamp = message.get('timestamp', '')

                        role_emoji = {'user': 'ğŸ‘¤', 'assistant': 'ğŸ¤–', 'system': 'âš™ï¸'}.get(role, 'â“')
                        f.write(f"### {role_emoji} {role.capitalize()} ({timestamp})\n\n")
                        f.write(f"{content}\n\n")
                        f.write("---\n\n")

            return True, f"å·²åŒ¯å‡º {conversation_count} å€‹å°è©±è‡³ {output_file}"

        except Exception as e:
            return False, f"Markdown åŒ¯å‡ºå¤±æ•—: {e}"

    def delete_conversation(
        self,
        file_name: str,
        confirm: bool = False
    ) -> Tuple[bool, str]:
        """
        åˆªé™¤å°è©±è¨˜éŒ„ï¼ˆéœ€äºŒæ¬¡ç¢ºèªï¼‰

        Args:
            file_name: è¦åˆªé™¤çš„æª”æ¡ˆåç¨±
            confirm: æ˜¯å¦å·²ç¢ºèªåˆªé™¤

        Returns:
            (æˆåŠŸèˆ‡å¦, è¨Šæ¯)
        """
        if not confirm:
            return False, "âš ï¸  åˆªé™¤å°è©±è¨˜éŒ„éœ€è¦ç¢ºèªï¼ˆconfirm=Trueï¼‰"

        try:
            file_path = self.log_dir / file_name

            if not file_path.exists():
                return False, f"æª”æ¡ˆä¸å­˜åœ¨: {file_name}"

            # åˆªé™¤æª”æ¡ˆ
            file_path.unlink()

            return True, f"âœ“ å·²åˆªé™¤å°è©±è¨˜éŒ„: {file_name}"

        except Exception as e:
            logger.error(f"åˆªé™¤å¤±æ•—: {e}")
            return False, f"åˆªé™¤å¤±æ•—: {e}"

    def get_statistics(self) -> Dict:
        """
        ç²å–å°è©±çµ±è¨ˆè³‡è¨Š

        Returns:
            çµ±è¨ˆè³‡è¨Šå­—å…¸ï¼š
            {
                'total_conversations': å°è©±ç¸½æ•¸,
                'total_messages': è¨Šæ¯ç¸½æ•¸,
                'total_size': ç¸½å¤§å°ï¼ˆbytesï¼‰,
                'date_range': (æœ€æ—©æ—¥æœŸ, æœ€æ–°æ—¥æœŸ),
                'role_distribution': {'user': N, 'assistant': M}
            }
        """
        stats = {
            'total_conversations': 0,
            'total_messages': 0,
            'total_size': 0,
            'date_range': (None, None),
            'role_distribution': defaultdict(int)
        }

        try:
            log_files = self._get_log_files()
            stats['total_conversations'] = len(log_files)

            if not log_files:
                return stats

            # æ—¥æœŸç¯„åœ
            oldest_time = datetime.fromtimestamp(log_files[-1].stat().st_mtime)
            newest_time = datetime.fromtimestamp(log_files[0].stat().st_mtime)
            stats['date_range'] = (
                oldest_time.strftime('%Y-%m-%d'),
                newest_time.strftime('%Y-%m-%d')
            )

            # çµ±è¨ˆè¨Šæ¯æ•¸é‡å’Œè§’è‰²åˆ†å¸ƒ
            for log_file in log_files:
                stats['total_size'] += log_file.stat().st_size

                for message in self._read_messages(log_file):
                    stats['total_messages'] += 1
                    role = message.get('role', 'unknown')
                    stats['role_distribution'][role] += 1

        except Exception as e:
            logger.error(f"çµ±è¨ˆè³‡è¨Šè¨ˆç®—å¤±æ•—: {e}")
            # é™ç´šï¼šè¿”å›éƒ¨åˆ†çµ±è¨ˆ

        return stats


# ä¾¿æ·å‡½æ•¸ï¼šç²å–å…¨åŸŸå¯¦ä¾‹
_global_manager = None

def get_history_manager() -> ConversationHistoryManager:
    """ç²å–å…¨åŸŸå°è©±æ­·å²ç®¡ç†å™¨å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰"""
    global _global_manager
    if _global_manager is None:
        _global_manager = ConversationHistoryManager()
    return _global_manager


# æ¸¬è©¦ä»£ç¢¼
if __name__ == "__main__":
    # åŸºæœ¬æ¸¬è©¦
    manager = ConversationHistoryManager()

    print("=== æ¸¬è©¦å°è©±æ­·å²ç®¡ç†å™¨ ===\n")

    # æ¸¬è©¦çµ±è¨ˆ
    stats = manager.get_statistics()
    print(f"çµ±è¨ˆè³‡è¨Š:")
    print(f"  - å°è©±ç¸½æ•¸: {stats['total_conversations']}")
    print(f"  - è¨Šæ¯ç¸½æ•¸: {stats['total_messages']}")
    print(f"  - ç¸½å¤§å°: {stats['total_size']} bytes")
    print(f"  - æ—¥æœŸç¯„åœ: {stats['date_range'][0]} ~ {stats['date_range'][1]}")
    print(f"  - è§’è‰²åˆ†å¸ƒ: {dict(stats['role_distribution'])}\n")

    # æ¸¬è©¦åˆ—è¡¨
    conversations = manager.list_conversations(limit=5)
    print(f"æœ€è¿‘ {len(conversations)} å€‹å°è©±:")
    for i, conv in enumerate(conversations, 1):
        print(f"  {i}. {conv['file']} - {conv['date']} ({conv['message_count']} å‰‡è¨Šæ¯)")
    print()

    # æ¸¬è©¦æœå°‹
    keyword = input("è¼¸å…¥æœå°‹é—œéµå­— (Enter è·³é): ").strip()
    if keyword:
        results = manager.search(keyword, limit=10)
        print(f"\næœå°‹çµæœ ({len(results)} ç­†):")
        for i, result in enumerate(results, 1):
            print(f"  {i}. [{result['role']}] {result['content']}")
            print(f"     æª”æ¡ˆ: {result['file']}, æ™‚é–“: {result['timestamp']}\n")
