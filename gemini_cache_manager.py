#!/usr/bin/env python3
"""
Gemini Context Caching ç®¡ç†å™¨
ä½¿ç”¨å¿«å–æ¸›å°‘ API æˆæœ¬ï¼ˆæœ€é«˜çœ 90%ï¼‰
"""
import os
import sys
import time
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
from google.genai import types
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

# å°å…¥åƒ¹æ ¼æ¨¡çµ„ï¼ˆçµ±ä¸€åŒ¯ç‡ï¼‰
from gemini_pricing import USD_TO_TWD, print_savings_summary

# å…±ç”¨å·¥å…·æ¨¡çµ„
from utils.api_client import get_gemini_client
from utils.pricing_loader import (
    get_pricing_calculator,
    PRICING_ENABLED,
    USD_TO_TWD
)

console = Console()

# åˆå§‹åŒ– API å®¢æˆ¶ç«¯
client = get_gemini_client()

# åˆå§‹åŒ–è¨ˆåƒ¹å™¨
global_pricing_calculator = get_pricing_calculator(silent=True)

# Context Caching æœ€ä½ token è¦æ±‚
MIN_TOKENS = {
    'gemini-2.5-pro': 4096,
    'gemini-2.5-flash': 1024,
    'gemini-2.0-flash': 32768,  # 2.0 Flash éœ€è¦æ›´å¤š
}

# å¿«å–æŠ˜æ‰£ç‡
CACHE_DISCOUNT = {
    'gemini-2.5-pro': 0.90,      # 90% æŠ˜æ‰£
    'gemini-2.5-flash': 0.90,    # 90% æŠ˜æ‰£
    'gemini-2.0-flash': 0.75,    # 75% æŠ˜æ‰£
}


class CacheManager:
    """Context Caching ç®¡ç†å™¨"""

    def __init__(self):
        self.active_caches: Dict[str, Any] = {}

    def create_cache(
        self,
        model: str,
        contents: List[str],
        display_name: Optional[str] = None,
        system_instruction: Optional[str] = None,
        ttl_seconds: int = 3600,
        ttl_hours: Optional[int] = None
    ) -> Any:
        """
        å»ºç«‹ Context Cache

        Args:
            model: æ¨¡å‹åç¨±ï¼ˆå¦‚ "gemini-2.5-pro"ï¼‰
            contents: è¦å¿«å–çš„å…§å®¹åˆ—è¡¨
            display_name: å¿«å–é¡¯ç¤ºåç¨±
            system_instruction: ç³»çµ±æŒ‡ä»¤ï¼ˆå¯é¸ï¼‰
            ttl_seconds: å¿«å–å­˜æ´»æ™‚é–“ï¼ˆç§’ï¼‰
            ttl_hours: å¿«å–å­˜æ´»æ™‚é–“ï¼ˆå°æ™‚ï¼‰ï¼Œæœƒè¦†è“‹ ttl_seconds

        Returns:
            å¿«å–ç‰©ä»¶
        """
        # è¨ˆç®— TTL
        if ttl_hours:
            ttl_seconds = ttl_hours * 3600

        # æª¢æŸ¥æ¨¡å‹æ”¯æ´
        if not self._check_model_support(model):
            console.print(f"[yellow]è­¦å‘Šï¼š{model} å¯èƒ½ä¸æ”¯æ´ Context Caching[/yellow]")

        # æª¢æŸ¥æœ€ä½ token è¦æ±‚
        min_tokens = MIN_TOKENS.get(model, 1024)
        console.print(f"\n[cyan]ğŸ“¦ å»ºç«‹ Context Cache[/cyan]")
        console.print(f"   æ¨¡å‹ï¼š{model}")
        console.print(f"   æœ€ä½ tokensï¼š{min_tokens:,}")
        console.print(f"   TTLï¼š{ttl_seconds} ç§’ ({ttl_seconds / 3600:.1f} å°æ™‚)")

        if display_name:
            console.print(f"   åç¨±ï¼š{display_name}")

        try:
            # æº–å‚™é…ç½®
            config_params = {
                "contents": contents,
                "ttl": f"{ttl_seconds}s"
            }

            if system_instruction:
                config_params["system_instruction"] = system_instruction

            if display_name:
                config_params["display_name"] = display_name

            # å»ºç«‹å¿«å–
            console.print("\n[cyan]â³ å»ºç«‹ä¸­...[/cyan]")

            cache = client.caches.create(
                model=f"models/{model}",
                config=types.CreateCachedContentConfig(**config_params)
            )

            console.print(f"[green]âœ“ å¿«å–å·²å»ºç«‹[/green]")
            console.print(f"   å¿«å–åç¨±ï¼š{cache.name}")
            console.print(f"   éæœŸæ™‚é–“ï¼š{cache.expire_time}")

            # å„²å­˜åˆ°æ´»å‹•å¿«å–
            cache_key = display_name or cache.name
            self.active_caches[cache_key] = cache

            # é¡¯ç¤ºçœéŒ¢è³‡è¨Š
            self._show_savings_info(model)

            return cache

        except Exception as e:
            console.print(f"[red]âœ— å»ºç«‹å¿«å–å¤±æ•—ï¼š{e}[/red]")

            # æª¢æŸ¥å¸¸è¦‹éŒ¯èª¤
            error_str = str(e).lower()
            if 'token' in error_str and 'minimum' in error_str:
                console.print(f"\n[yellow]æç¤ºï¼šå…§å®¹å¯èƒ½å°‘æ–¼æœ€ä½ {min_tokens} tokens[/yellow]")
                console.print(f"[yellow]è«‹å¢åŠ å…§å®¹é•·åº¦ä»¥ä½¿ç”¨ Context Caching[/yellow]")
            elif 'not support' in error_str:
                console.print(f"\n[yellow]æç¤ºï¼š{model} å¯èƒ½ä¸æ”¯æ´ Context Caching[/yellow]")

            raise

    def _check_model_support(self, model: str) -> bool:
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æ´ Context Caching"""
        supported_models = ['gemini-2.5-pro', 'gemini-2.5-flash', 'gemini-2.0-flash', 'gemini-1.5-pro', 'gemini-1.5-flash']
        return any(supported in model for supported in supported_models)

    def _show_savings_info(self, model: str):
        """é¡¯ç¤ºçœéŒ¢è³‡è¨Š"""
        discount = CACHE_DISCOUNT.get(model, 0.75)
        discount_percent = int(discount * 100)

        console.print(f"\n[bold green]ğŸ’° æˆæœ¬ç¯€çœè³‡è¨Š[/bold green]")
        console.print(f"   å¿«å–æŠ˜æ‰£ï¼š{discount_percent}%")
        console.print(f"   ç¯„ä¾‹ï¼šåŸæœ¬ $1.00 â†’ ç¾åœ¨ ${1.00 * (1 - discount):.2f}")

    def query_with_cache(
        self,
        cache_name_or_key: str,
        question: str,
        model: Optional[str] = None
    ) -> str:
        """
        ä½¿ç”¨å¿«å–é€²è¡ŒæŸ¥è©¢

        Args:
            cache_name_or_key: å¿«å–åç¨±æˆ– key
            question: å•é¡Œ
            model: æ¨¡å‹ï¼ˆå¯é¸ï¼Œæœƒå¾å¿«å–ç²å–ï¼‰

        Returns:
            å›æ‡‰æ–‡å­—
        """
        # ç²å–å¿«å–
        cache = self.active_caches.get(cache_name_or_key)
        if not cache:
            # å˜—è©¦åˆ—å‡ºä¸¦æŸ¥æ‰¾
            console.print(f"[yellow]åœ¨æœ¬åœ°æ‰¾ä¸åˆ°å¿«å–ï¼Œå˜—è©¦å¾ API ç²å–...[/yellow]")
            cache = self._find_cache_by_name(cache_name_or_key)
            if not cache:
                raise ValueError(f"æ‰¾ä¸åˆ°å¿«å–ï¼š{cache_name_or_key}")

        console.print(f"\n[cyan]ğŸ” ä½¿ç”¨å¿«å–æŸ¥è©¢[/cyan]")
        console.print(f"   å¿«å–ï¼š{cache.name}")
        console.print(f"   å•é¡Œï¼š{question}\n")

        try:
            # ä½¿ç”¨å¿«å–é€²è¡ŒæŸ¥è©¢
            response = client.models.generate_content(
                model=cache.model,
                contents=question,
                config=types.GenerateContentConfig(
                    cached_content=cache.name
                )
            )

            console.print("[cyan]Gemini (ä½¿ç”¨å¿«å–)ï¼š[/cyan]")
            console.print(response.text)

            return response.text

        except Exception as e:
            console.print(f"[red]âœ— æŸ¥è©¢å¤±æ•—ï¼š{e}[/red]")
            raise

    def _find_cache_by_name(self, name: str) -> Optional[Any]:
        """é€šéåç¨±æŸ¥æ‰¾å¿«å–"""
        try:
            caches = client.caches.list()
            for cache in caches:
                if name in cache.name or (hasattr(cache, 'display_name') and cache.display_name == name):
                    return cache
        except Exception as e:
            console.print(f"[red]åˆ—å‡ºå¿«å–å¤±æ•—ï¼š{e}[/red]")
        return None

    def list_caches(self) -> List[Any]:
        """åˆ—å‡ºæ‰€æœ‰å¿«å–"""
        console.print("\n[cyan]ğŸ“¦ å·²å»ºç«‹çš„ Context Cachesï¼š[/cyan]\n")

        try:
            caches = list(client.caches.list())

            if not caches:
                console.print("[yellow]æ²’æœ‰æ‰¾åˆ°å¿«å–[/yellow]")
                return []

            # å»ºç«‹è¡¨æ ¼
            table = Table(show_header=True, header_style="bold cyan")
            table.add_column("åç¨±", style="green")
            table.add_column("æ¨¡å‹")
            table.add_column("å»ºç«‹æ™‚é–“")
            table.add_column("éæœŸæ™‚é–“")
            table.add_column("ç‹€æ…‹", justify="center")

            for cache in caches:
                display_name = getattr(cache, 'display_name', cache.name.split('/')[-1])

                # æª¢æŸ¥æ˜¯å¦éæœŸ
                now = datetime.now()
                expire_time = cache.expire_time
                is_expired = expire_time < now if expire_time else False

                status = "[red]å·²éæœŸ[/red]" if is_expired else "[green]æœ‰æ•ˆ[/green]"

                table.add_row(
                    display_name,
                    cache.model.split('/')[-1],
                    str(cache.create_time).split('.')[0] if cache.create_time else "N/A",
                    str(expire_time).split('.')[0] if expire_time else "N/A",
                    status
                )

            console.print(table)
            console.print(f"\nç¸½è¨ˆï¼š{len(caches)} å€‹å¿«å–")

            return caches

        except Exception as e:
            console.print(f"[red]âœ— åˆ—å‡ºå¿«å–å¤±æ•—ï¼š{e}[/red]")
            return []

    def delete_cache(self, cache_name_or_key: str) -> bool:
        """
        åˆªé™¤å¿«å–

        Args:
            cache_name_or_key: å¿«å–åç¨±æˆ– key

        Returns:
            æ˜¯å¦æˆåŠŸåˆªé™¤
        """
        try:
            # å˜—è©¦å¾ active_caches ç²å–
            cache = self.active_caches.get(cache_name_or_key)
            if cache:
                cache_name = cache.name
            else:
                # å‡è¨­æ˜¯å®Œæ•´åç¨±
                cache_name = cache_name_or_key
                if not cache_name.startswith('cachedContents/'):
                    cache_name = f"cachedContents/{cache_name}"

            client.caches.delete(name=cache_name)
            console.print(f"[green]âœ“ å·²åˆªé™¤å¿«å–ï¼š{cache_name_or_key}[/green]")

            # å¾ active_caches ç§»é™¤
            if cache_name_or_key in self.active_caches:
                del self.active_caches[cache_name_or_key]

            return True

        except Exception as e:
            console.print(f"[red]âœ— åˆªé™¤å¿«å–å¤±æ•—ï¼š{e}[/red]")
            return False

    def calculate_savings(
        self,
        model: str,
        cached_tokens: int,
        query_count: int
    ) -> Dict[str, float]:
        """
        è¨ˆç®—ä½¿ç”¨å¿«å–çš„æˆæœ¬ç¯€çœ

        Args:
            model: æ¨¡å‹åç¨±
            cached_tokens: å¿«å–çš„ token æ•¸
            query_count: æŸ¥è©¢æ¬¡æ•¸

        Returns:
            æˆæœ¬è³‡è¨Šå­—å…¸
        """
        from gemini_pricing import PRICING_TABLE

        # ç²å–å®šåƒ¹
        pricing = PRICING_TABLE.get(model, PRICING_TABLE['default'])
        input_price = pricing.get('input', pricing.get('input_low', 0))

        # è¨ˆç®—æˆæœ¬
        without_cache = (cached_tokens / 1000) * input_price * query_count
        discount = CACHE_DISCOUNT.get(model, 0.75)
        with_cache = without_cache * (1 - discount)
        savings = without_cache - with_cache

        return {
            'without_cache': without_cache,
            'with_cache': with_cache,
            'savings': savings,
            'discount_percent': int(discount * 100),
            'query_count': query_count,
            'cached_tokens': cached_tokens
        }

    def show_savings_report(
        self,
        model: str,
        cached_tokens: int,
        query_count: int
    ):
        """é¡¯ç¤ºæˆæœ¬ç¯€çœå ±å‘Š"""
        result = self.calculate_savings(model, cached_tokens, query_count)

        panel_content = f"""
[cyan]æ¨¡å‹ï¼š[/cyan] {model}
[cyan]å¿«å– Tokensï¼š[/cyan] {result['cached_tokens']:,}
[cyan]æŸ¥è©¢æ¬¡æ•¸ï¼š[/cyan] {result['query_count']}

[yellow]ä¸ä½¿ç”¨å¿«å–æˆæœ¬ï¼š[/yellow] ${result['without_cache']:.6f}
[green]ä½¿ç”¨å¿«å–æˆæœ¬ï¼š[/green] ${result['with_cache']:.6f}
[bold green]ç¯€çœï¼š[/bold green] ${result['savings']:.6f} ({result['discount_percent']}% æŠ˜æ‰£)

[dim]ç´„åˆå°å¹£ç¯€çœï¼šNT${result['savings'] * USD_TO_TWD:.2f}[/dim]
        """

        console.print(Panel(panel_content, title="ğŸ’° æˆæœ¬ç¯€çœå ±å‘Š", border_style="green"))


def main():
    """ä¸»ç¨‹å¼"""
    import argparse

    parser = argparse.ArgumentParser(description='Gemini Context Caching ç®¡ç†å™¨')
    parser.add_argument('command', choices=['create', 'list', 'delete', 'query', 'calculate'],
                       help='å‘½ä»¤')
    parser.add_argument('--model', default='gemini-2.5-flash', help='æ¨¡å‹åç¨±')
    parser.add_argument('--content', help='å¿«å–å…§å®¹ï¼ˆæ–‡å­—æˆ–æª”æ¡ˆè·¯å¾‘ï¼‰')
    parser.add_argument('--name', help='å¿«å–åç¨±')
    parser.add_argument('--ttl', type=int, default=1, help='å­˜æ´»æ™‚é–“ï¼ˆå°æ™‚ï¼‰')
    parser.add_argument('--question', help='æŸ¥è©¢å•é¡Œ')
    parser.add_argument('--cache', help='å¿«å–åç¨±ï¼ˆquery æ™‚ä½¿ç”¨ï¼‰')
    parser.add_argument('--tokens', type=int, help='Token æ•¸é‡ï¼ˆcalculate æ™‚ä½¿ç”¨ï¼‰')
    parser.add_argument('--queries', type=int, default=10, help='æŸ¥è©¢æ¬¡æ•¸ï¼ˆcalculate æ™‚ä½¿ç”¨ï¼‰')

    args = parser.parse_args()

    manager = CacheManager()

    if args.command == 'create':
        if not args.content:
            console.print("[red]éŒ¯èª¤ï¼šè«‹æä¾› --content[/red]")
            sys.exit(1)

        # æª¢æŸ¥æ˜¯å¦ç‚ºæª”æ¡ˆ
        content = args.content
        if os.path.isfile(content):
            with open(content, 'r', encoding='utf-8') as f:
                content = f.read()

        manager.create_cache(
            model=args.model,
            contents=[content],
            display_name=args.name,
            ttl_hours=args.ttl
        )

    elif args.command == 'list':
        manager.list_caches()

    elif args.command == 'delete':
        if not args.cache:
            console.print("[red]éŒ¯èª¤ï¼šè«‹æä¾› --cache[/red]")
            sys.exit(1)
        manager.delete_cache(args.cache)

    elif args.command == 'query':
        if not args.cache or not args.question:
            console.print("[red]éŒ¯èª¤ï¼šè«‹æä¾› --cache å’Œ --question[/red]")
            sys.exit(1)
        manager.query_with_cache(args.cache, args.question)

    elif args.command == 'calculate':
        if not args.tokens:
            console.print("[red]éŒ¯èª¤ï¼šè«‹æä¾› --tokens[/red]")
            sys.exit(1)
        manager.show_savings_report(
            model=args.model,
            cached_tokens=args.tokens,
            query_count=args.queries
        )


if __name__ == "__main__":
    if len(sys.argv) == 1:
        console.print("\n[bold cyan]Gemini Context Caching ç®¡ç†å™¨[/bold cyan]\n")
        console.print("ğŸ’° [bold]ä½¿ç”¨å¿«å–å¯ç¯€çœæœ€é«˜ 90% çš„æˆæœ¬ï¼[/bold]\n")
        console.print("ä½¿ç”¨æ–¹å¼ï¼š")
        console.print("  å»ºç«‹å¿«å–ï¼š")
        console.print("    python gemini_cache_manager.py create --model gemini-2.5-pro --content 'long text...' --name my_cache --ttl 2")
        console.print("    python gemini_cache_manager.py create --content file.txt --name doc_cache\n")
        console.print("  åˆ—å‡ºå¿«å–ï¼š")
        console.print("    python gemini_cache_manager.py list\n")
        console.print("  ä½¿ç”¨å¿«å–æŸ¥è©¢ï¼š")
        console.print("    python gemini_cache_manager.py query --cache my_cache --question 'å•é¡Œ'\n")
        console.print("  åˆªé™¤å¿«å–ï¼š")
        console.print("    python gemini_cache_manager.py delete --cache my_cache\n")
        console.print("  è¨ˆç®—ç¯€çœï¼š")
        console.print("    python gemini_cache_manager.py calculate --model gemini-2.5-pro --tokens 10000 --queries 100\n")
        sys.exit(0)
    else:
        main()
