#!/usr/bin/env python3
"""
Gemini Context Caching ç®¡ç†å™¨
ä½¿ç”¨å¿«å–æ¸›å°‘ API æˆæœ¬ï¼ˆæœ€é«˜çœ 90%ï¼‰
"""
import os
import sys
import time
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
from google.genai import types
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

# å°å…¥åƒ¹æ ¼æ¨¡çµ„ï¼ˆçµ±ä¸€åŒ¯ç‡ï¼‰
from gemini_pricing import USD_TO_TWD, print_savings_summary

# å…±ç”¨å·¥å…·æ¨¡çµ„
from utils.api_client import get_gemini_client
from utils.pricing_loader import (
    get_pricing_calculator,
    PRICING_ENABLED,
    USD_TO_TWD
)

# å°å…¥ i18n åœ‹éš›åŒ–æ”¯æ´
from utils.i18n import safe_t

console = Console()

# åˆå§‹åŒ– API å®¢æˆ¶ç«¯
client = get_gemini_client()

# åˆå§‹åŒ–è¨ˆåƒ¹å™¨
global_pricing_calculator = get_pricing_calculator(silent=True)

# Context Caching æœ€ä½ token è¦æ±‚
MIN_TOKENS = {
    'gemini-2.5-pro': 4096,
    'gemini-2.5-flash': 1024,
    'gemini-2.0-flash': 32768,  # 2.0 Flash éœ€è¦æ›´å¤š
}

# å¿«å–æŠ˜æ‰£ç‡
CACHE_DISCOUNT = {
    'gemini-2.5-pro': 0.90,      # 90% æŠ˜æ‰£
    'gemini-2.5-flash': 0.90,    # 90% æŠ˜æ‰£
    'gemini-2.0-flash': 0.75,    # 75% æŠ˜æ‰£
}


class CacheManager:
    """Context Caching ç®¡ç†å™¨"""

    def __init__(self):
        self.active_caches: Dict[str, Any] = {}

    def create_cache(
        self,
        model: str,
        contents: List[str],
        display_name: Optional[str] = None,
        system_instruction: Optional[str] = None,
        ttl_seconds: int = 3600,
        ttl_hours: Optional[int] = None
    ) -> Any:
        """
        å»ºç«‹ Context Cache

        Args:
            model: æ¨¡å‹åç¨±ï¼ˆå¦‚ "gemini-2.5-pro"ï¼‰
            contents: è¦å¿«å–çš„å…§å®¹åˆ—è¡¨
            display_name: å¿«å–é¡¯ç¤ºåç¨±
            system_instruction: ç³»çµ±æŒ‡ä»¤ï¼ˆå¯é¸ï¼‰
            ttl_seconds: å¿«å–å­˜æ´»æ™‚é–“ï¼ˆç§’ï¼‰
            ttl_hours: å¿«å–å­˜æ´»æ™‚é–“ï¼ˆå°æ™‚ï¼‰ï¼Œæœƒè¦†è“‹ ttl_seconds

        Returns:
            å¿«å–ç‰©ä»¶
        """
        # è¨ˆç®— TTL
        if ttl_hours:
            ttl_seconds = ttl_hours * 3600

        # æª¢æŸ¥æ¨¡å‹æ”¯æ´
        if not self._check_model_support(model):
            console.print(f"[magenta]{safe_t('cache.warning_model_not_support', fallback='è­¦å‘Šï¼š{model} å¯èƒ½ä¸æ”¯æ´ Context Caching', model=model)}[/yellow]")

        # æª¢æŸ¥æœ€ä½ token è¦æ±‚
        min_tokens = MIN_TOKENS.get(model, 1024)
        console.print(f"\n[magenta]{safe_t('cache.create_title', fallback='ğŸ“¦ å»ºç«‹ Context Cache')}[/magenta]")
        console.print(f"   {safe_t('cache.model_info', fallback='æ¨¡å‹ï¼š{model}', model=model)}")
        console.print(f"   {safe_t('cache.min_tokens_info', fallback='æœ€ä½ tokensï¼š{min}', min=f'{min_tokens:,}')}")
        console.print(f"   {safe_t('cache.ttl_info', fallback='TTLï¼š{seconds} ç§’ ({hours} å°æ™‚)', seconds=ttl_seconds, hours=f'{ttl_seconds/3600:.1f}')}")

        if display_name:
            console.print(f"   {safe_t('cache.display_name_info', fallback='åç¨±ï¼š{name}', name=display_name)}")

        try:
            # æº–å‚™é…ç½®
            config_params = {
                "contents": contents,
                "ttl": f"{ttl_seconds}s"
            }

            if system_instruction:
                config_params["system_instruction"] = system_instruction

            if display_name:
                config_params["display_name"] = display_name

            # å»ºç«‹å¿«å–
            console.print(f"\n[magenta]{safe_t('cache.creating', fallback='â³ å»ºç«‹ä¸­...')}[/magenta]")

            cache = client.caches.create(
                model=f"models/{model}",
                config=types.CreateCachedContentConfig(**config_params)
            )

            console.print(f"[bright_magenta]{safe_t('cache.created_success', fallback='âœ“ å¿«å–å·²å»ºç«‹')}[/green]")
            console.print(f"   {safe_t('cache.cache_name_info', fallback='å¿«å–åç¨±ï¼š{name}', name=cache.name)}")
            console.print(f"   {safe_t('cache.expire_time_info', fallback='éæœŸæ™‚é–“ï¼š{time}', time=cache.expire_time)}")

            # å„²å­˜åˆ°æ´»å‹•å¿«å–
            cache_key = display_name or cache.name
            self.active_caches[cache_key] = cache

            # é¡¯ç¤ºçœéŒ¢è³‡è¨Š
            self._show_savings_info(model)

            return cache

        except Exception as e:
            console.print(f"[dim magenta]{safe_t('cache.create_failed', fallback='âœ— å»ºç«‹å¿«å–å¤±æ•—ï¼š{error}', error=str(e))}[/red]")

            # æª¢æŸ¥å¸¸è¦‹éŒ¯èª¤
            error_str = str(e).lower()
            if 'token' in error_str and 'minimum' in error_str:
                console.print(f"\n[magenta]{safe_t('cache.hint_content_too_short', fallback='æç¤ºï¼šå…§å®¹å¯èƒ½å°‘æ–¼æœ€ä½ {min_tokens} tokens', min_tokens=min_tokens)}[/yellow]")
                console.print(f"[magenta]{safe_t('cache.hint_increase_content', fallback='è«‹å¢åŠ å…§å®¹é•·åº¦ä»¥ä½¿ç”¨ Context Caching')}[/yellow]")
            elif 'not support' in error_str:
                console.print(f"\n[magenta]{safe_t('cache.hint_model_not_support', fallback='æç¤ºï¼š{model} å¯èƒ½ä¸æ”¯æ´ Context Caching', model=model)}[/yellow]")

            raise

    def _check_model_support(self, model: str) -> bool:
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æ´ Context Caching"""
        supported_models = ['gemini-2.5-pro', 'gemini-2.5-flash', 'gemini-2.0-flash', 'gemini-1.5-pro', 'gemini-1.5-flash']
        return any(supported in model for supported in supported_models)

    def _show_savings_info(self, model: str):
        """é¡¯ç¤ºçœéŒ¢è³‡è¨Š"""
        discount = CACHE_DISCOUNT.get(model, 0.75)
        discount_percent = int(discount * 100)

        console.print(f"\n[bold green]{safe_t('cache.savings_info_title', fallback='ğŸ’° æˆæœ¬ç¯€çœè³‡è¨Š')}[/bold green]")
        console.print(f"   {safe_t('cache.discount_info', fallback='å¿«å–æŠ˜æ‰£ï¼š{discount}%', discount=discount_percent)}")
        console.print(f"   {safe_t('cache.example_savings', fallback='ç¯„ä¾‹ï¼šåŸæœ¬ ${original} â†’ ç¾åœ¨ ${discounted}', original='1.00', discounted=f'{1.00 * (1 - discount):.2f}')}")

    def query_with_cache(
        self,
        cache_name_or_key: str,
        question: str,
        model: Optional[str] = None
    ) -> str:
        """
        ä½¿ç”¨å¿«å–é€²è¡ŒæŸ¥è©¢

        Args:
            cache_name_or_key: å¿«å–åç¨±æˆ– key
            question: å•é¡Œ
            model: æ¨¡å‹ï¼ˆå¯é¸ï¼Œæœƒå¾å¿«å–ç²å–ï¼‰

        Returns:
            å›æ‡‰æ–‡å­—
        """
        # ç²å–å¿«å–
        cache = self.active_caches.get(cache_name_or_key)
        if not cache:
            # å˜—è©¦åˆ—å‡ºä¸¦æŸ¥æ‰¾
            console.print(f"[magenta]{safe_t('cache.trying_api', fallback='åœ¨æœ¬åœ°æ‰¾ä¸åˆ°å¿«å–ï¼Œå˜—è©¦å¾ API ç²å–...')}[/yellow]")
            cache = self._find_cache_by_name(cache_name_or_key)
            if not cache:
                raise ValueError(safe_t('cache.cache_not_found', fallback='æ‰¾ä¸åˆ°å¿«å–ï¼š{name}', name=cache_name_or_key))

        console.print(f"\n[magenta]{safe_t('cache.query_title', fallback='ğŸ” ä½¿ç”¨å¿«å–æŸ¥è©¢')}[/magenta]")
        console.print(f"   {safe_t('cache.cache_info', fallback='å¿«å–ï¼š{name}', name=cache.name)}")
        console.print(f"   {safe_t('cache.question_info', fallback='å•é¡Œï¼š{question}', question=question)}\n")

        try:
            # ä½¿ç”¨å¿«å–é€²è¡ŒæŸ¥è©¢
            response = client.models.generate_content(
                model=cache.model,
                contents=question,
                config=types.GenerateContentConfig(
                    cached_content=cache.name
                )
            )

            # æå–ä¸¦è¨ˆç®—æˆæœ¬ï¼ˆå«å¿«å–æŠ˜æ‰£ï¼‰
            if PRICING_ENABLED and global_pricing_calculator:
                cached_tokens = getattr(response.usage_metadata, 'cached_content_token_count', 0)
                thinking_tokens = getattr(response.usage_metadata, 'thinking_tokens', 0)
                input_tokens = getattr(response.usage_metadata, 'prompt_tokens', 0)
                output_tokens = getattr(response.usage_metadata, 'candidates_tokens', 0)

                # è¨ˆç®—æˆæœ¬
                cost, details = global_pricing_calculator.calculate_text_cost(
                    cache.model,
                    input_tokens,
                    output_tokens,
                    thinking_tokens
                )

                # é¡¯ç¤ºæˆæœ¬è³‡è¨Šï¼ˆå«å¿«å–æŠ˜æ‰£èªªæ˜ï¼‰
                if cost > 0 or cached_tokens > 0:
                    console.print(f"\n[dim]{safe_t('cache.query_cost', fallback='ğŸ’° æŸ¥è©¢æˆæœ¬ (ä½¿ç”¨å¿«å–): NT${twd} (${usd} USD)', twd=f'{cost * USD_TO_TWD:.2f}', usd=f'{cost:.6f}')}[/dim]")
                    console.print(f"[dim]   {safe_t('cache.cached_tokens_detail', fallback='å¿«å– tokens: {cached} (90% æŠ˜æ‰£)', cached=f'{cached_tokens:,}')}[/dim]")
                    console.print(f"[dim]   {safe_t('cache.tokens_detail', fallback='è¼¸å…¥: {input} tokens, è¼¸å‡º: {output} tokens, æ€è€ƒ: {thinking} tokens', input=f'{input_tokens:,}', output=f'{output_tokens:,}', thinking=f'{thinking_tokens:,}')}[/dim]")

                    # è¨ˆç®—å¦‚æœä¸ä½¿ç”¨å¿«å–çš„æˆæœ¬
                    if cached_tokens > 0:
                        full_cost, _ = global_pricing_calculator.calculate_text_cost(
                            cache.model,
                            input_tokens + cached_tokens,
                            output_tokens,
                            thinking_tokens
                        )
                        savings = full_cost - cost
                        savings_percent = (savings / full_cost * 100) if full_cost > 0 else 0
                        console.print(f"[dim]   {safe_t('cache.savings_detail', fallback='ğŸ’¸ ç¯€çœæˆæœ¬: NT${twd} (ç´„ {percent}%)', twd=f'{savings * USD_TO_TWD:.2f}', percent=f'{savings_percent:.0f}')}[/dim]")

                    console.print(f"[dim]   {safe_t('cache.cumulative_cost_info', fallback='ç´¯è¨ˆæˆæœ¬: NT${twd} (${usd} USD)', twd=f'{global_pricing_calculator.total_cost * USD_TO_TWD:.2f}', usd=f'{global_pricing_calculator.total_cost:.6f}')}[/dim]\n")

            console.print(f"[magenta]{safe_t('cache.using_cache_label', fallback='Gemini (ä½¿ç”¨å¿«å–)ï¼š')}[/magenta]")
            console.print(response.text)

            return response.text

        except Exception as e:
            console.print(f"[dim magenta]{safe_t('cache.query_failed', fallback='âœ— æŸ¥è©¢å¤±æ•—ï¼š{error}', error=str(e))}[/red]")
            raise

    def _find_cache_by_name(self, name: str) -> Optional[Any]:
        """é€šéåç¨±æŸ¥æ‰¾å¿«å–"""
        try:
            caches = client.caches.list()
            for cache in caches:
                if name in cache.name or (hasattr(cache, 'display_name') and cache.display_name == name):
                    return cache
        except Exception as e:
            console.print(f"[dim magenta]åˆ—å‡ºå¿«å–å¤±æ•—ï¼š{e}[/red]")
        return None

    def list_caches(self) -> List[Any]:
        """åˆ—å‡ºæ‰€æœ‰å¿«å–"""
        console.print(f"\n[magenta]{safe_t('cache.list_title', fallback='ğŸ“¦ å·²å»ºç«‹çš„ Context Cachesï¼š')}[/magenta]\n")

        try:
            caches = list(client.caches.list())

            if not caches:
                console.print(f"[magenta]{safe_t('cache.no_caches_found', fallback='æ²’æœ‰æ‰¾åˆ°å¿«å–')}[/yellow]")
                return []

            # å»ºç«‹è¡¨æ ¼
            table = Table(show_header=True, header_style="bold bright_magenta")
            table.add_column(safe_t('cache.table_col_name', fallback='åç¨±'), style="green")
            table.add_column(safe_t('cache.table_col_model', fallback='æ¨¡å‹'))
            table.add_column(safe_t('cache.table_col_created', fallback='å»ºç«‹æ™‚é–“'))
            table.add_column(safe_t('cache.table_col_expire', fallback='éæœŸæ™‚é–“'))
            table.add_column(safe_t('cache.table_col_status', fallback='ç‹€æ…‹'), justify="center")

            for cache in caches:
                display_name = getattr(cache, 'display_name', cache.name.split('/')[-1])

                # æª¢æŸ¥æ˜¯å¦éæœŸ
                now = datetime.now()
                expire_time = cache.expire_time
                is_expired = expire_time < now if expire_time else False

                status = f"[dim magenta]{safe_t('cache.status_expired', fallback='å·²éæœŸ')}[/red]" if is_expired else f"[bright_magenta]{safe_t('cache.status_valid', fallback='æœ‰æ•ˆ')}[/green]"

                table.add_row(
                    display_name,
                    cache.model.split('/')[-1],
                    str(cache.create_time).split('.')[0] if cache.create_time else "N/A",
                    str(expire_time).split('.')[0] if expire_time else "N/A",
                    status
                )

            console.print(table)
            console.print(f"\n{safe_t('cache.total_caches', fallback='ç¸½è¨ˆï¼š{count} å€‹å¿«å–', count=len(caches))}")

            return caches

        except Exception as e:
            console.print(f"[dim magenta]{safe_t('cache.list_failed', fallback='âœ— åˆ—å‡ºå¿«å–å¤±æ•—ï¼š{error}', error=str(e))}[/red]")
            return []

    def delete_cache(self, cache_name_or_key: str) -> bool:
        """
        åˆªé™¤å¿«å–

        Args:
            cache_name_or_key: å¿«å–åç¨±æˆ– key

        Returns:
            æ˜¯å¦æˆåŠŸåˆªé™¤
        """
        try:
            # å˜—è©¦å¾ active_caches ç²å–
            cache = self.active_caches.get(cache_name_or_key)
            if cache:
                cache_name = cache.name
            else:
                # å‡è¨­æ˜¯å®Œæ•´åç¨±
                cache_name = cache_name_or_key
                if not cache_name.startswith('cachedContents/'):
                    cache_name = f"cachedContents/{cache_name}"

            client.caches.delete(name=cache_name)
            console.print(f"[bright_magenta]âœ“ å·²åˆªé™¤å¿«å–ï¼š{cache_name_or_key}[/green]")

            # å¾ active_caches ç§»é™¤
            if cache_name_or_key in self.active_caches:
                del self.active_caches[cache_name_or_key]

            return True

        except Exception as e:
            console.print(f"[dim magenta]âœ— åˆªé™¤å¿«å–å¤±æ•—ï¼š{e}[/red]")
            return False

    def calculate_savings(
        self,
        model: str,
        cached_tokens: int,
        query_count: int
    ) -> Dict[str, float]:
        """
        è¨ˆç®—ä½¿ç”¨å¿«å–çš„æˆæœ¬ç¯€çœ

        Args:
            model: æ¨¡å‹åç¨±
            cached_tokens: å¿«å–çš„ token æ•¸
            query_count: æŸ¥è©¢æ¬¡æ•¸

        Returns:
            æˆæœ¬è³‡è¨Šå­—å…¸
        """
        from gemini_pricing import PRICING_TABLE

        # ç²å–å®šåƒ¹
        pricing = PRICING_TABLE.get(model, PRICING_TABLE['default'])
        input_price = pricing.get('input', pricing.get('input_low', 0))

        # è¨ˆç®—æˆæœ¬
        without_cache = (cached_tokens / 1000) * input_price * query_count
        discount = CACHE_DISCOUNT.get(model, 0.75)
        with_cache = without_cache * (1 - discount)
        savings = without_cache - with_cache

        return {
            'without_cache': without_cache,
            'with_cache': with_cache,
            'savings': savings,
            'discount_percent': int(discount * 100),
            'query_count': query_count,
            'cached_tokens': cached_tokens
        }

    def show_savings_report(
        self,
        model: str,
        cached_tokens: int,
        query_count: int
    ):
        """é¡¯ç¤ºæˆæœ¬ç¯€çœå ±å‘Š"""
        result = self.calculate_savings(model, cached_tokens, query_count)

        panel_content = f"""
[magenta]æ¨¡å‹ï¼š[/magenta] {model}
[magenta]å¿«å– Tokensï¼š[/magenta] {result['cached_tokens']:,}
[magenta]æŸ¥è©¢æ¬¡æ•¸ï¼š[/magenta] {result['query_count']}

[magenta]ä¸ä½¿ç”¨å¿«å–æˆæœ¬ï¼š[/yellow] ${result['without_cache']:.6f}
[bright_magenta]ä½¿ç”¨å¿«å–æˆæœ¬ï¼š[/green] ${result['with_cache']:.6f}
[bold green]ç¯€çœï¼š[/bold green] ${result['savings']:.6f} ({result['discount_percent']}% æŠ˜æ‰£)

[dim]ç´„åˆå°å¹£ç¯€çœï¼šNT${result['savings'] * USD_TO_TWD:.2f}[/dim]
        """

        console.print(Panel(panel_content, title="ğŸ’° æˆæœ¬ç¯€çœå ±å‘Š", border_style="green"))


def main():
    """ä¸»ç¨‹å¼"""
    import argparse

    parser = argparse.ArgumentParser(description='Gemini Context Caching ç®¡ç†å™¨')
    parser.add_argument('command', choices=['create', 'list', 'delete', 'query', 'calculate'],
                       help='å‘½ä»¤')
    parser.add_argument('--model', default='gemini-2.5-flash', help='æ¨¡å‹åç¨±')
    parser.add_argument('--content', help='å¿«å–å…§å®¹ï¼ˆæ–‡å­—æˆ–æª”æ¡ˆè·¯å¾‘ï¼‰')
    parser.add_argument('--name', help='å¿«å–åç¨±')
    parser.add_argument('--ttl', type=int, default=1, help='å­˜æ´»æ™‚é–“ï¼ˆå°æ™‚ï¼‰')
    parser.add_argument('--question', help='æŸ¥è©¢å•é¡Œ')
    parser.add_argument('--cache', help='å¿«å–åç¨±ï¼ˆquery æ™‚ä½¿ç”¨ï¼‰')
    parser.add_argument('--tokens', type=int, help='Token æ•¸é‡ï¼ˆcalculate æ™‚ä½¿ç”¨ï¼‰')
    parser.add_argument('--queries', type=int, default=10, help='æŸ¥è©¢æ¬¡æ•¸ï¼ˆcalculate æ™‚ä½¿ç”¨ï¼‰')

    args = parser.parse_args()

    manager = CacheManager()

    if args.command == 'create':
        if not args.content:
            console.print("[dim magenta]éŒ¯èª¤ï¼šè«‹æä¾› --content[/red]")
            sys.exit(1)

        # æª¢æŸ¥æ˜¯å¦ç‚ºæª”æ¡ˆ
        content = args.content
        if os.path.isfile(content):
            with open(content, 'r', encoding='utf-8') as f:
                content = f.read()

        manager.create_cache(
            model=args.model,
            contents=[content],
            display_name=args.name,
            ttl_hours=args.ttl
        )

    elif args.command == 'list':
        manager.list_caches()

    elif args.command == 'delete':
        if not args.cache:
            console.print("[dim magenta]éŒ¯èª¤ï¼šè«‹æä¾› --cache[/red]")
            sys.exit(1)
        manager.delete_cache(args.cache)

    elif args.command == 'query':
        if not args.cache or not args.question:
            console.print("[dim magenta]éŒ¯èª¤ï¼šè«‹æä¾› --cache å’Œ --question[/red]")
            sys.exit(1)
        manager.query_with_cache(args.cache, args.question)

    elif args.command == 'calculate':
        if not args.tokens:
            console.print("[dim magenta]éŒ¯èª¤ï¼šè«‹æä¾› --tokens[/red]")
            sys.exit(1)
        manager.show_savings_report(
            model=args.model,
            cached_tokens=args.tokens,
            query_count=args.queries
        )


if __name__ == "__main__":
    if len(sys.argv) == 1:
        console.print("\n[bold magenta]Gemini Context Caching ç®¡ç†å™¨[/bold magenta]\n")
        console.print("ğŸ’° [bold]ä½¿ç”¨å¿«å–å¯ç¯€çœæœ€é«˜ 90% çš„æˆæœ¬ï¼[/bold]\n")
        console.print("ä½¿ç”¨æ–¹å¼ï¼š")
        console.print("  å»ºç«‹å¿«å–ï¼š")
        console.print("    python gemini_cache_manager.py create --model gemini-2.5-pro --content 'long text...' --name my_cache --ttl 2")
        console.print("    python gemini_cache_manager.py create --content file.txt --name doc_cache\n")
        console.print("  åˆ—å‡ºå¿«å–ï¼š")
        console.print("    python gemini_cache_manager.py list\n")
        console.print("  ä½¿ç”¨å¿«å–æŸ¥è©¢ï¼š")
        console.print("    python gemini_cache_manager.py query --cache my_cache --question 'å•é¡Œ'\n")
        console.print("  åˆªé™¤å¿«å–ï¼š")
        console.print("    python gemini_cache_manager.py delete --cache my_cache\n")
        console.print("  è¨ˆç®—ç¯€çœï¼š")
        console.print("    python gemini_cache_manager.py calculate --model gemini-2.5-pro --tokens 10000 --queries 100\n")
        sys.exit(0)
    else:
        main()
