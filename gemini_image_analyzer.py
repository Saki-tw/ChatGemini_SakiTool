#!/usr/bin/env python3
"""
Gemini åœ–åƒåˆ†æå·¥å…· - å®Œå…¨ä½¿ç”¨æ–° SDK
æ”¯æ´åœ–åƒç†è§£ã€OCRã€ç‰©é«”åµæ¸¬ã€åœ–åƒæ¯”è¼ƒç­‰åŠŸèƒ½
"""
import os
import sys
import base64
from typing import Optional, List
from PIL import Image
from rich.console import Console
from rich.panel import Panel

# æ–° SDK
from google.genai import types

# å…±ç”¨å·¥å…·æ¨¡çµ„
from utils.api_client import get_gemini_client
from utils.pricing_loader import (
    get_pricing_calculator,
    PRICING_ENABLED,
    USD_TO_TWD
)

# å°å…¥ API é‡è©¦æ©Ÿåˆ¶
try:
    from api_retry_wrapper import with_retry
    API_RETRY_ENABLED = True
except ImportError:
    # å¦‚æœæœªå®‰è£ï¼Œæä¾›ç©ºè£é£¾å™¨
    def with_retry(operation_name: str, max_retries: int = 3):
        def decorator(func):
            return func
        return decorator
    API_RETRY_ENABLED = False

# åˆå§‹åŒ– API å®¢æˆ¶ç«¯
client = get_gemini_client()

# åˆå§‹åŒ–è¨ˆåƒ¹å™¨
global_pricing_calculator = get_pricing_calculator(silent=True)

# Console
console = Console()

# æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
SUPPORTED_FORMATS = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']
DEFAULT_MODEL = 'gemini-2.5-flash'

# é è¨­æç¤ºè©ç¯„æœ¬
PROMPT_TEMPLATES = {
    'describe': 'è©³ç´°æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦ç‰©é«”ã€å ´æ™¯ã€é¡è‰²ã€æ°›åœç­‰ã€‚',
    'ocr': 'æå–åœ–ç‰‡ä¸­æ‰€æœ‰å¯è¦‹çš„æ–‡å­—å…§å®¹ï¼Œä¿æŒåŸå§‹æ ¼å¼å’Œæ’ç‰ˆã€‚',
    'objects': 'åˆ—å‡ºåœ–ç‰‡ä¸­æ‰€æœ‰å¯è¦‹çš„ç‰©é«”ï¼Œä¸¦èªªæ˜å®ƒå€‘çš„ä½ç½®å’Œç‰¹å¾µã€‚',
    'analyze': 'æ·±å…¥åˆ†æé€™å¼µåœ–ç‰‡ï¼ŒåŒ…æ‹¬ï¼š\n1. ä¸»é¡Œå’Œå…§å®¹\n2. æ§‹åœ–å’Œè¦–è¦ºå…ƒç´ \n3. è‰²å½©é‹ç”¨\n4. å¯èƒ½çš„ç”¨é€”æˆ–æ„ç¾©',
    'compare': 'æ¯”è¼ƒé€™äº›åœ–ç‰‡çš„ç•°åŒï¼Œåˆ†æå®ƒå€‘çš„å…±åŒé»å’Œå·®ç•°ã€‚',
    'caption': 'ç‚ºé€™å¼µåœ–ç‰‡ç”Ÿæˆä¸€å€‹ç°¡çŸ­ä½†æœ‰æè¿°æ€§çš„æ¨™é¡Œï¼ˆ20å­—ä»¥å…§ï¼‰ã€‚',
    'translate': 'ç¿»è­¯åœ–ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—ç‚ºä¸­æ–‡ã€‚',
    'count': 'è¨ˆç®—ä¸¦åˆ—å‡ºåœ–ç‰‡ä¸­æ¯ç¨®ç‰©é«”çš„æ•¸é‡ã€‚',
}

# æ”¯æ´æ€è€ƒæ¨¡å¼çš„æ¨¡å‹
THINKING_MODELS = ['gemini-2.5-pro', 'gemini-2.5-flash', 'gemini-2.5-flash-8b']


class ImageAnalyzer:
    """åœ–åƒåˆ†æå™¨ï¼ˆæ–° SDK ç‰ˆæœ¬ï¼‰"""

    def __init__(self, model_name: str = DEFAULT_MODEL):
        self.model_name = model_name
        console.print(f"[green]âœ“ å·²è¼‰å…¥æ¨¡å‹ï¼š{model_name}[/green]")

    def _image_to_part(self, image_path: str) -> types.Part:
        """å°‡åœ–ç‰‡è½‰æ›ç‚º Part ç‰©ä»¶"""
        # è®€å–åœ–ç‰‡
        with open(image_path, 'rb') as f:
            image_bytes = f.read()

        # å–å¾— MIME é¡å‹
        ext = os.path.splitext(image_path)[1].lower()
        mime_map = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.bmp': 'image/bmp',
            '.webp': 'image/webp',
        }
        mime_type = mime_map.get(ext, 'image/jpeg')

        # å»ºç«‹ Part
        return types.Part(
            inline_data=types.Blob(
                mime_type=mime_type,
                data=image_bytes
            )
        )

    @with_retry("åœ–ç‰‡åˆ†æ", max_retries=3)
    def analyze_image(
        self,
        image_path: str,
        prompt: Optional[str] = None,
        task: str = 'describe'
    ) -> str:
        """
        åˆ†æå–®å¼µåœ–ç‰‡ï¼ˆå·²åŒ…å«è‡ªå‹•é‡è©¦ï¼‰

        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            prompt: è‡ªè¨‚æç¤ºè©
            task: é è¨­ä»»å‹™é¡å‹

        Returns:
            åˆ†æçµæœ
        """
        # æª¢æŸ¥æª”æ¡ˆ
        if not os.path.isfile(image_path):
            # ğŸ¯ ä¸€éµä¿®å¾©ï¼šé¡¯ç¤ºä¿®å¾©å»ºè­°ä¸¦å˜—è©¦è‡ªå‹•ä¿®å¾©
            try:
                from error_fix_suggestions import suggest_video_file_not_found
                # æ­¤å‡½æ•¸é€šç”¨æ–¼æ‰€æœ‰æª”æ¡ˆé¡å‹
                alternative_path = suggest_video_file_not_found(image_path, auto_fix=True)

                if alternative_path and os.path.isfile(alternative_path):
                    # ç”¨æˆ¶é¸æ“‡äº†æ›¿ä»£æª”æ¡ˆï¼Œä½¿ç”¨æ–°è·¯å¾‘
                    image_path = alternative_path
                    console.print(f"[green]âœ… å·²åˆ‡æ›è‡³ï¼š{image_path}[/green]\n")
                else:
                    raise FileNotFoundError(f"æ‰¾ä¸åˆ°åœ–ç‰‡ï¼Œè«‹åƒè€ƒä¸Šè¿°å»ºè­°")
            except ImportError:
                # å¦‚æœæ²’æœ‰ä¿®å¾©å»ºè­°æ¨¡çµ„ï¼Œç›´æ¥æ‹‹å‡ºéŒ¯èª¤
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°åœ–ç‰‡ï¼š{image_path}")

        # æª¢æŸ¥æ ¼å¼
        ext = os.path.splitext(image_path)[1].lower()
        if ext not in SUPPORTED_FORMATS:
            console.print(f"[yellow]è­¦å‘Šï¼š{ext} å¯èƒ½ä¸å—æ”¯æ´[/yellow]")

        # è¼‰å…¥åœ–ç‰‡è³‡è¨Š
        try:
            img = Image.open(image_path)
            console.print(f"\n[cyan]ğŸ“· åœ–ç‰‡è³‡è¨Šï¼š[/cyan]")
            console.print(f"   æª”æ¡ˆï¼š{os.path.basename(image_path)}")
            console.print(f"   å¤§å°ï¼š{img.size[0]} Ã— {img.size[1]}")
            console.print(f"   æ ¼å¼ï¼š{img.format}")
        except Exception as e:
            # ğŸ¯ ä¸€éµä¿®å¾©ï¼šé¡¯ç¤ºåœ–ç‰‡è¼‰å…¥å¤±æ•—çš„ä¿®å¾©å»ºè­°
            try:
                from error_fix_suggestions import suggest_image_load_failed
                suggest_image_load_failed(image_path, e)
            except ImportError:
                pass

            raise Exception(f"ç„¡æ³•è¼‰å…¥åœ–ç‰‡ï¼š{e}ï¼Œè«‹åƒè€ƒä¸Šè¿°è§£æ±ºæ–¹æ¡ˆ")

        # é¸æ“‡æç¤ºè©
        if not prompt:
            prompt = PROMPT_TEMPLATES.get(task, PROMPT_TEMPLATES['describe'])

        console.print(f"\n[cyan]ğŸ’­ ä»»å‹™ï¼š{task}[/cyan]")
        console.print(f"[cyan]ğŸ“ æç¤ºï¼š{prompt[:50]}...[/cyan]" if len(prompt) > 50 else f"[cyan]ğŸ“ æç¤ºï¼š{prompt}[/cyan]")

        # åˆ†æåœ–ç‰‡
        console.print(f"\n[cyan]ğŸ¤– Gemini åˆ†æä¸­...[/cyan]\n")

        try:
            # è½‰æ›åœ–ç‰‡ç‚º Part
            image_part = self._image_to_part(image_path)

            # æª¢æŸ¥æ˜¯å¦æ”¯æ´æ€è€ƒæ¨¡å¼
            supports_thinking = any(tm in self.model_name for tm in THINKING_MODELS)

            # é…ç½®
            config = types.GenerateContentConfig()
            if supports_thinking:
                config.thinking_config = types.ThinkingConfig(thinking_budget=-1)

            # ç™¼é€è«‹æ±‚
            response = client.models.generate_content(
                model=self.model_name,
                contents=[prompt, image_part],
                config=config
            )

            # é¡¯ç¤ºçµæœ
            console.print("[cyan]Geminiï¼š[/cyan]")
            console.print(response.text)
            console.print("\n")

            # æå– tokens
            thinking_tokens = 0
            input_tokens = 0
            output_tokens = 0

            if hasattr(response, 'usage_metadata'):
                thinking_tokens = getattr(response.usage_metadata, 'thinking_tokens', 0)
                input_tokens = getattr(response.usage_metadata, 'prompt_tokens', 0)
                output_tokens = getattr(response.usage_metadata, 'candidates_tokens', 0)

            # é¡¯ç¤ºæˆæœ¬ï¼ˆæ–°å°å¹£ï¼‰
            if PRICING_ENABLED and input_tokens > 0:
                try:
                    cost, details = global_pricing_calculator.calculate_text_cost(
                        self.model_name,
                        input_tokens,
                        output_tokens,
                        thinking_tokens
                    )
                    if thinking_tokens > 0:
                        console.print(f"[dim]ğŸ’° æœ¬æ¬¡æˆæœ¬: NT${cost * USD_TO_TWD:.2f} (åœ–ç‰‡+æç¤º: {input_tokens:,} tokens, æ€è€ƒ: {thinking_tokens:,} tokens, å›æ‡‰: {output_tokens:,} tokens) | ç´¯è¨ˆ: NT${global_pricing_calculator.total_cost * USD_TO_TWD:.2f} (${global_pricing_calculator.total_cost:.6f})[/dim]")
                    else:
                        console.print(f"[dim]ğŸ’° æœ¬æ¬¡æˆæœ¬: NT${cost * USD_TO_TWD:.2f} (åœ–ç‰‡+æç¤º: {input_tokens:,} tokens, å›æ‡‰: {output_tokens:,} tokens) | ç´¯è¨ˆ: NT${global_pricing_calculator.total_cost * USD_TO_TWD:.2f} (${global_pricing_calculator.total_cost:.6f})[/dim]")
                except Exception as e:
                    pass

            return response.text

        except Exception as e:
            console.print(f"[red]âœ— åˆ†æå¤±æ•—ï¼š{e}[/red]")
            raise

    def analyze_multiple_images(
        self,
        image_paths: List[str],
        prompt: Optional[str] = None,
        task: str = 'compare'
    ) -> str:
        """åˆ†æå¤šå¼µåœ–ç‰‡"""
        # è¼‰å…¥æ‰€æœ‰åœ–ç‰‡
        console.print(f"\n[cyan]ğŸ“· è¼‰å…¥ {len(image_paths)} å¼µåœ–ç‰‡ï¼š[/cyan]")

        parts = []
        for i, path in enumerate(image_paths, 1):
            try:
                img = Image.open(path)
                console.print(f"   {i}. {os.path.basename(path)} ({img.size[0]}Ã—{img.size[1]})")
                parts.append(self._image_to_part(path))
            except Exception as e:
                console.print(f"   [red]âœ— {os.path.basename(path)} - è¼‰å…¥å¤±æ•—ï¼š{e}[/red]")

        if not parts:
            # ğŸ¯ ä¸€éµä¿®å¾©ï¼šé¡¯ç¤ºç„¡åœ–ç‰‡è¼‰å…¥ä¿®å¾©å»ºè­°
            try:
                from error_fix_suggestions import suggest_no_images_loaded
                suggest_no_images_loaded(len(image_paths), image_paths)
            except ImportError:
                # å¦‚æœæ²’æœ‰ä¿®å¾©å»ºè­°æ¨¡çµ„ï¼Œä½¿ç”¨åŸºæœ¬éŒ¯èª¤è¨Šæ¯
                pass

            raise ValueError("æ²’æœ‰æˆåŠŸè¼‰å…¥ä»»ä½•åœ–ç‰‡")

        # é¸æ“‡æç¤ºè©
        if not prompt:
            prompt = PROMPT_TEMPLATES.get(task, PROMPT_TEMPLATES['compare'])

        console.print(f"\n[cyan]ğŸ’­ ä»»å‹™ï¼š{task}[/cyan]")

        # åˆ†æ
        console.print(f"\n[cyan]ğŸ¤– Gemini åˆ†æä¸­...[/cyan]\n")

        try:
            # é…ç½®
            supports_thinking = any(tm in self.model_name for tm in THINKING_MODELS)
            config = types.GenerateContentConfig()
            if supports_thinking:
                config.thinking_config = types.ThinkingConfig(thinking_budget=-1)

            # æ§‹å»ºå…§å®¹ï¼šæç¤ºè© + æ‰€æœ‰åœ–ç‰‡
            contents = [prompt] + parts

            response = client.models.generate_content(
                model=self.model_name,
                contents=contents,
                config=config
            )

            console.print("[cyan]Geminiï¼š[/cyan]")
            console.print(response.text)
            console.print("\n")

            return response.text

        except Exception as e:
            console.print(f"[red]âœ— åˆ†æå¤±æ•—ï¼š{e}[/red]")
            raise

    def batch_analyze(
        self,
        image_paths: List[str],
        task: str = 'describe'
    ) -> List[dict]:
        """æ‰¹æ¬¡åˆ†æå¤šå¼µåœ–ç‰‡"""
        results = []

        console.print(f"\n[bold cyan]ğŸ“¦ æ‰¹æ¬¡åˆ†æ {len(image_paths)} å¼µåœ–ç‰‡[/bold cyan]")

        for i, path in enumerate(image_paths, 1):
            console.print(f"\n[cyan]â”â”â” åœ–ç‰‡ {i}/{len(image_paths)} â”â”â”[/cyan]")

            try:
                result_text = self.analyze_image(path, task=task)
                results.append({
                    'path': path,
                    'filename': os.path.basename(path),
                    'task': task,
                    'result': result_text,
                    'success': True
                })
            except Exception as e:
                console.print(f"[red]âœ— åˆ†æå¤±æ•—ï¼š{e}[/red]")
                results.append({
                    'path': path,
                    'filename': os.path.basename(path),
                    'task': task,
                    'error': str(e),
                    'success': False
                })

        # çµ±è¨ˆ
        success_count = sum(1 for r in results if r['success'])
        console.print(f"\n[green]âœ“ æ‰¹æ¬¡åˆ†æå®Œæˆï¼š{success_count}/{len(image_paths)} æˆåŠŸ[/green]")

        return results


def show_examples():
    """é¡¯ç¤ºä½¿ç”¨ç¯„ä¾‹"""
    console.print(Panel.fit(
        """[bold cyan]Gemini åœ–åƒåˆ†æå·¥å…· - ä½¿ç”¨ç¯„ä¾‹[/bold cyan]

[yellow]1. åŸºæœ¬åœ–ç‰‡æè¿°[/yellow]
   python3 gemini_image_analyzer.py describe image.jpg

[yellow]2. OCR æ–‡å­—æå–[/yellow]
   python3 gemini_image_analyzer.py ocr document.png

[yellow]3. ç‰©é«”åµæ¸¬[/yellow]
   python3 gemini_image_analyzer.py objects photo.jpg

[yellow]4. åœ–ç‰‡æ¯”è¼ƒ[/yellow]
   python3 gemini_image_analyzer.py compare image1.jpg image2.jpg

[yellow]5. æ‰¹æ¬¡åˆ†æ[/yellow]
   python3 gemini_image_analyzer.py batch *.jpg
        """,
        border_style="cyan"
    ))


def main():
    """ä¸»ç¨‹å¼"""
    import argparse

    parser = argparse.ArgumentParser(description='Gemini åœ–åƒåˆ†æå·¥å…·ï¼ˆæ–° SDKï¼‰')
    parser.add_argument('task', nargs='?', help='ä»»å‹™é¡å‹æˆ– "examples" é¡¯ç¤ºç¯„ä¾‹')
    parser.add_argument('images', nargs='*', help='åœ–ç‰‡è·¯å¾‘')
    parser.add_argument('--model', default=DEFAULT_MODEL, help='æ¨¡å‹åç¨±')
    parser.add_argument('--prompt', help='è‡ªè¨‚æç¤ºè©')

    args = parser.parse_args()

    # é¡¯ç¤ºç¯„ä¾‹
    if args.task == 'examples' or not args.task:
        show_examples()
        sys.exit(0)

    # æª¢æŸ¥åœ–ç‰‡
    if not args.images:
        console.print("[red]éŒ¯èª¤ï¼šè«‹æä¾›åœ–ç‰‡è·¯å¾‘[/red]")
        show_examples()
        sys.exit(1)

    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = ImageAnalyzer(model_name=args.model)

    try:
        # æ¯”è¼ƒæ¨¡å¼ï¼ˆå¤šå¼µåœ–ç‰‡ï¼‰
        if args.task == 'compare' and len(args.images) > 1:
            analyzer.analyze_multiple_images(args.images, task='compare')

        # æ‰¹æ¬¡æ¨¡å¼
        elif args.task == 'batch':
            analyzer.batch_analyze(args.images, task='describe')

        # è‡ªè¨‚æç¤º
        elif args.prompt:
            analyzer.analyze_image(args.images[0], prompt=args.prompt)

        # å–®å¼µåœ–ç‰‡åˆ†æ
        else:
            analyzer.analyze_image(args.images[0], task=args.task)

    except Exception as e:
        console.print(f"[red]âœ— åŸ·è¡Œå¤±æ•—ï¼š{e}[/red]")
        sys.exit(1)


if __name__ == "__main__":
    main()
