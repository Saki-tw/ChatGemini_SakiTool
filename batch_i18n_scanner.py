#!/usr/bin/env python3
"""
æ‰¹æ¬¡ i18n æƒæèˆ‡åˆ†æå·¥å…·
æƒæå°ˆæ¡ˆä¸­æ‰€æœ‰éœ€è¦åœ‹éš›åŒ–çš„ä¸­æ–‡å­—ä¸²
"""
import re
import json
from pathlib import Path
from typing import List, Dict, Tuple

class I18nScanner:
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.results = []

    def scan_file(self, filepath: Path) -> List[Dict]:
        """æƒæå–®ä¸€æª”æ¡ˆï¼Œæå–éœ€è¦åœ‹éš›åŒ–çš„å­—ä¸²"""
        findings = []

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except Exception as e:
            return findings

        for line_num, line in enumerate(lines, 1):
            # è·³éè¨»è§£
            if line.strip().startswith('#'):
                continue

            # æœå°‹å«ä¸­æ–‡çš„ print/console.print èªå¥
            patterns = [
                (r'print\s*\(\s*["\']([^"\']*[\u4e00-\u9fff]+[^"\']*)["\']', 'print'),
                (r'console\.print\s*\(\s*["\']([^"\']*[\u4e00-\u9fff]+[^"\']*)["\']', 'console.print'),
                (r'print\s*\(\s*f["\']([^"\']*[\u4e00-\u9fff]+[^"\']*)["\']', 'f-string'),
            ]

            for pattern, method in patterns:
                matches = re.finditer(pattern, line)
                for match in matches:
                    chinese_text = match.group(1)

                    # ç”Ÿæˆç¿»è­¯éµå»ºè­°
                    suggested_key = self._generate_key(chinese_text, filepath)

                    findings.append({
                        'file': str(filepath.relative_to(self.project_root)),
                        'line': line_num,
                        'original': chinese_text,
                        'method': method,
                        'suggested_key': suggested_key,
                        'full_line': line.strip()
                    })

        return findings

    def _generate_key(self, text: str, filepath: Path) -> str:
        """æ ¹æ“šæ–‡å­—å…§å®¹å’Œæª”æ¡ˆè·¯å¾‘ç”Ÿæˆå»ºè­°çš„ç¿»è­¯éµ"""
        # ç§»é™¤è¡¨æƒ…ç¬¦è™Ÿå’Œç‰¹æ®Šå­—å…ƒ
        clean_text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)

        # æ ¹æ“šæª”æ¡ˆé¡å‹æ¨æ–·é¡åˆ¥
        filename = filepath.stem

        if 'error' in filename or 'Error' in filename:
            category = 'error'
        elif 'video' in filename or 'media' in filename:
            category = 'media'
        elif 'cache' in filename:
            category = 'cache'
        elif 'file' in filename:
            category = 'file'
        elif 'batch' in filename:
            category = 'batch'
        else:
            category = 'system'

        # ç”Ÿæˆå­éµï¼ˆåŸºæ–¼å…§å®¹é—œéµå­—ï¼‰
        if 'å®Œæˆ' in text or 'æˆåŠŸ' in text:
            subkey = 'complete'
        elif 'å¤±æ•—' in text or 'éŒ¯èª¤' in text:
            subkey = 'failed'
        elif 'è™•ç†' in text:
            subkey = 'processing'
        elif 'è¼‰å…¥' in text:
            subkey = 'loading'
        else:
            # ä½¿ç”¨å‰å¹¾å€‹ä¸­æ–‡å­—
            chinese_chars = re.findall(r'[\u4e00-\u9fff]+', clean_text)
            if chinese_chars:
                subkey = chinese_chars[0][:4]
            else:
                subkey = 'message'

        return f"{category}.{subkey}"

    def scan_directory(self, directory: Path, patterns: List[str]) -> Dict:
        """æƒæç›®éŒ„ä¸‹ç¬¦åˆ pattern çš„æ‰€æœ‰æª”æ¡ˆ"""
        all_findings = []

        for pattern in patterns:
            for filepath in directory.rglob(pattern):
                # è·³éç‰¹å®šç›®éŒ„
                if any(skip in str(filepath) for skip in ['venv', '__pycache__', '.git', 'tests']):
                    continue

                findings = self.scan_file(filepath)
                all_findings.extend(findings)

        return {
            'total_files': len(set(f['file'] for f in all_findings)),
            'total_strings': len(all_findings),
            'findings': all_findings
        }

    def generate_report(self, results: Dict, output_path: Path):
        """ç”Ÿæˆæƒæå ±å‘Š"""
        # JSON å ±å‘Š
        with open(output_path.with_suffix('.json'), 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        # æ–‡å­—å ±å‘Š
        with open(output_path.with_suffix('.txt'), 'w', encoding='utf-8') as f:
            f.write(f"=== i18n æƒæå ±å‘Š ===\n\n")
            f.write(f"ç¸½æª”æ¡ˆæ•¸: {results['total_files']}\n")
            f.write(f"ç¸½å­—ä¸²æ•¸: {results['total_strings']}\n\n")

            # æŒ‰æª”æ¡ˆåˆ†çµ„
            by_file = {}
            for finding in results['findings']:
                file = finding['file']
                if file not in by_file:
                    by_file[file] = []
                by_file[file].append(finding)

            for file, findings in sorted(by_file.items()):
                f.write(f"\n## {file} ({len(findings)} è™•)\n")
                for idx, finding in enumerate(findings, 1):
                    f.write(f"{idx}. Line {finding['line']}: {finding['original']}\n")
                    f.write(f"   å»ºè­°éµ: {finding['suggested_key']}\n")

if __name__ == '__main__':
    project_root = Path.cwd()
    scanner = I18nScanner(project_root)

    # æƒæä¸»è¦ Python æª”æ¡ˆ
    print("ğŸ” æƒæå°ˆæ¡ˆä¸­éœ€è¦åœ‹éš›åŒ–çš„å­—ä¸²...")
    results = scanner.scan_directory(project_root, ['gemini_*.py'])

    print(f"\nâœ… æƒæå®Œæˆï¼")
    print(f"   ç¸½æª”æ¡ˆæ•¸: {results['total_files']}")
    print(f"   ç¸½å­—ä¸²æ•¸: {results['total_strings']}")

    # ç”Ÿæˆå ±å‘Š
    output_path = Path('i18n_scan_report')
    scanner.generate_report(results, output_path)
    print(f"\nğŸ“„ å ±å‘Šå·²å„²å­˜:")
    print(f"   - {output_path}.json")
    print(f"   - {output_path}.txt")
