#!/usr/bin/env python3
"""
Gemini å°è©±ç®¡ç†å™¨
å¾ gemini_chat.py æŠ½é›¢
"""

import os
import json
from utils.i18n import safe_t
import logging
from typing import List, Dict, Any
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)

# å¾é…ç½®å–å¾—é è¨­æ—¥èªŒç›®éŒ„
try:
    from config import OUTPUT_DIRS
    DEFAULT_LOG_DIR = str(OUTPUT_DIRS.get('chat_logs', Path.cwd() / 'ChatLogs'))
except ImportError:
    DEFAULT_LOG_DIR = str(Path.cwd() / 'ChatLogs')



class ConversationManager:
    """
    å°è©±æ­·å²ç®¡ç†å™¨ - é˜²æ­¢è¨˜æ†¶é«”æ´©æ¼

    åŠŸèƒ½ï¼š
    - é™åˆ¶æ´»èºå°è©±æ­·å²ç‚º 100 æ¢
    - è‡ªå‹•å­˜æª”èˆŠå°è©±åˆ°ç£ç¢Ÿ
    - é‡‹æ”¾ä¸å†éœ€è¦çš„è¨˜æ†¶é«”
    """

    def __init__(self, max_history: int = 100, archive_dir: str = None):
        """
        åˆå§‹åŒ–å°è©±ç®¡ç†å™¨

        Args:
            max_history: æœ€å¤§æ´»èºå°è©±æ•¸é‡ï¼ˆé è¨­ 100 æ¢ï¼‰
            archive_dir: å­˜æª”ç›®éŒ„ï¼ˆé è¨­ä½¿ç”¨ DEFAULT_LOG_DIRï¼‰
        """
        self.max_history = max_history
        self.history = []  # æ´»èºå°è©±ï¼ˆè¨˜æ†¶é«”ä¸­ï¼‰
        self.archived_count = 0  # å·²å­˜æª”çš„å°è©±æ•¸é‡

        if archive_dir is None:
            archive_dir = DEFAULT_LOG_DIR
        self.archive_dir = archive_dir
        os.makedirs(archive_dir, exist_ok=True)

        self.archive_file = os.path.join(
            archive_dir,
            f"archived_conversations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
        )

        logger.info(f"å°è©±ç®¡ç†å™¨å·²åˆå§‹åŒ–ï¼šæœ€å¤šä¿ç•™ {max_history} æ¢æ´»èºå°è©±")

    def add_message(self, message: dict):
        """
        æ·»åŠ è¨Šæ¯åˆ°å°è©±æ­·å²

        Args:
            message: è¨Šæ¯å­—å…¸,æ ¼å¼ï¼š
                {
                    "role": "user" | "assistant" | "system",
                    "content": "è¨Šæ¯å…§å®¹",
                    "timestamp": "ISOæ™‚é–“æˆ³",
                    ...
                }
        """
        self.history.append(message)

        # æª¢æŸ¥æ˜¯å¦è¶…éé™åˆ¶
        if len(self.history) > self.max_history:
            self._archive_old_messages()

    def _archive_old_messages(self):
        """
        å­˜æª”èˆŠå°è©±ä¸¦æ¸…ç†è¨˜æ†¶é«”

        ç­–ç•¥ï¼šä¿ç•™æœ€æ–°çš„ 50 æ¢,å­˜æª”å‰ 50 æ¢
        """
        archive_count = len(self.history) - 50

        if archive_count <= 0:
            return

        # å–å‡ºè¦å­˜æª”çš„è¨Šæ¯
        to_archive = self.history[:archive_count]

        # å¯«å…¥å­˜æª”æª”æ¡ˆï¼ˆJSONL æ ¼å¼,æ¯è¡Œä¸€æ¢è¨Šæ¯ï¼‰
        try:
            with open(self.archive_file, 'a', encoding='utf-8') as f:
                for msg in to_archive:
                    json.dump(msg, f, ensure_ascii=False)
                    f.write('\n')

            self.archived_count += archive_count
            logger.info(f"å·²å­˜æª” {archive_count} æ¢å°è©±ï¼ˆç¸½è¨ˆ {self.archived_count} æ¢ï¼‰")

            # æ›´æ–°æ´»èºæ­·å²ï¼ˆåƒ…ä¿ç•™æœ€æ–°çš„ 50 æ¢ï¼‰
            history=self.history[archive_count:]

            # æç¤ºï¼šPython çš„ GC æœƒè‡ªå‹•å›æ”¶ä¸å†å¼•ç”¨çš„ç‰©ä»¶

        except Exception as e:
            logger.error(f"å­˜æª”å°è©±å¤±æ•—ï¼š{e}")

    def get_recent_history(self, count: int = None) -> List[dict]:
        """
        ç²å–æœ€è¿‘çš„å°è©±æ­·å²

        Args:
            count: è¿”å›çš„è¨Šæ¯æ•¸é‡ï¼ˆNone=è¿”å›å…¨éƒ¨æ´»èºæ­·å²ï¼‰

        Returns:
            å°è©±åˆ—è¡¨
        """
        if count is None:
            return self.history.copy()
        return self.history[-count:] if count > 0 else []

    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰å°è©±æ­·å²ï¼ˆè¬¹æ…ä½¿ç”¨ï¼‰"""
        self.history.clear()
        logger.info("å°è©±æ­·å²å·²æ¸…ç©º")

    def get_stats(self) -> dict:
        """
        ç²å–çµ±è¨ˆè³‡è¨Š

        Returns:
            çµ±è¨ˆå­—å…¸
        """
        return {
            'active_messages': len(self.history),
            'archived_messages': self.archived_count,
            'total_messages': len(self.history) + self.archived_count,
            'max_history': self.max_history,
            'archive_file': self.archive_file
        }

    def search(self, keyword: str, role: str = None, limit: int = 50) -> List[Dict[str, Any]]:
        """
        æœå°‹å°è©±è¨˜éŒ„

        Args:
            keyword: æœå°‹é—œéµå­—
            role: ç¯©é¸è§’è‰² ("user", "assistant", "system"),None=æ‰€æœ‰è§’è‰²
            limit: æœ€å¤§è¿”å›æ•¸é‡

        Returns:
            ç¬¦åˆæ¢ä»¶çš„è¨Šæ¯åˆ—è¡¨
        """
        results = []
        keyword_lower = keyword.lower()

        # æœå°‹æ´»èºæ­·å²
        for msg in self.history:
            if len(results) >= limit:
                break

            # è§’è‰²ç¯©é¸
            if role and msg.get('role') != role:
                continue

            # é—œéµå­—æœå°‹
            content = msg.get('content', '')
            if isinstance(content, str) and keyword_lower in content.lower():
                results.append(msg.copy())

        # å¦‚æœé‚„éœ€è¦æ›´å¤šçµæœ,æœå°‹å­˜æª”
        if len(results) < limit and os.path.exists(self.archive_file):
            try:
                with open(self.archive_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if len(results) >= limit:
                            break

                        try:
                            msg = json.loads(line.strip())

                            # è§’è‰²ç¯©é¸
                            if role and msg.get('role') != role:
                                continue

                            # é—œéµå­—æœå°‹
                            content = msg.get('content', '')
                            if isinstance(content, str) and keyword_lower in content.lower():
                                results.append(msg)
                        except json.JSONDecodeError:
                            continue

            except Exception as e:
                logger.error(f"æœå°‹å­˜æª”å¤±æ•—ï¼š{e}")

        logger.info(f"æœå°‹ '{keyword}' æ‰¾åˆ° {len(results)} æ¢çµæœ")
        return results

    def export_to_json(self, output_path: str, include_archived: bool = True) -> bool:
        """
        åŒ¯å‡ºå°è©±è¨˜éŒ„ç‚º JSON æ ¼å¼

        Args:
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            include_archived: æ˜¯å¦åŒ…å«å·²å­˜æª”çš„å°è©±

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            export_data = {
                'metadata': {
                    'export_time': datetime.now().isoformat(),
                    'total_messages': len(self.history) + (self.archived_count if include_archived else 0),
                    'active_messages': len(self.history),
                    'archived_messages': self.archived_count if include_archived else 0
                },
                'conversations': []
            }

            # åŒ¯å‡ºæ´»èºå°è©±
            export_data['conversations'].extend(self.history)

            # åŒ¯å‡ºå­˜æª”å°è©±
            if include_archived and os.path.exists(self.archive_file):
                with open(self.archive_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            msg = json.loads(line.strip())
                            export_data['conversations'].append(msg)
                        except json.JSONDecodeError:
                            continue

            # å¯«å…¥æª”æ¡ˆ
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)

            logger.info(f"å·²åŒ¯å‡º {len(export_data['conversations'])} æ¢å°è©±åˆ° {output_path}")
            return True

        except Exception as e:
            logger.error(f"åŒ¯å‡ºå°è©±å¤±æ•—ï¼š{e}")
            return False

    def export_to_markdown(self, output_path: str, include_archived: bool = True) -> bool:
        """
        åŒ¯å‡ºå°è©±è¨˜éŒ„ç‚º Markdown æ ¼å¼

        Args:
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            include_archived: æ˜¯å¦åŒ…å«å·²å­˜æª”çš„å°è©±

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            messages = []

            # æ”¶é›†æ´»èºå°è©±
            messages.extend(self.history)

            # æ”¶é›†å­˜æª”å°è©±
            if include_archived and os.path.exists(self.archive_file):
                with open(self.archive_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        try:
                            msg = json.loads(line.strip())
                            messages.append(msg)
                        except json.JSONDecodeError:
                            continue

            # ç”Ÿæˆ Markdown
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(f"# å°è©±è¨˜éŒ„\n\n")
                f.write(f"**åŒ¯å‡ºæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**ç¸½è¨Šæ¯æ•¸**: {len(messages)}\n\n")
                f.write("---\n\n")

                for i, msg in enumerate(messages, 1):
                    role = msg.get('role', 'unknown')
                    content = msg.get('content', '')
                    timestamp = msg.get('timestamp', 'N/A')

                    # è§’è‰²åœ–ç¤º
                    role_icon = {
                        'user': 'ğŸ‘¤',
                        'assistant': 'ğŸ¤–',
                        'system': 'âš™ï¸'
                    }.get(role, 'â“')

                    f.write(f"## {i}. {role_icon} {role.title()}\n\n")
                    f.write(f"**æ™‚é–“**: {timestamp}\n\n")
                    f.write(f"{content}\n\n")
                    f.write("---\n\n")

            logger.info(f"å·²åŒ¯å‡º {len(messages)} æ¢å°è©±åˆ° {output_path}")
            return True

        except Exception as e:
            logger.error(f"åŒ¯å‡º Markdown å¤±æ•—ï¼š{e}")
            return False
