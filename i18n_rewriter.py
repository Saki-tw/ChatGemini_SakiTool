#!/usr/bin/env python3
"""
i18n æ”¹å¯«è¼”åŠ©å·¥å…·

åŠŸèƒ½ï¼š
1. æƒæ Python æª”æ¡ˆä¸­çš„ä¸­æ–‡å­—ä¸²
2. è‡ªå‹•åŒ¹é… locales/zh_TW.yaml ä¸­çš„ç¿»è­¯éµå€¼
3. ç”Ÿæˆæ”¹å¯«å»ºè­°å ±å‘Š

ä½œè€…: Saki-tw (with Claude Code)
æ—¥æœŸ: 2025-10-25
"""

import re
import yaml
import ast
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from difflib import SequenceMatcher


class I18nRewriter:
    """i18n æ”¹å¯«è¼”åŠ©å·¥å…·"""

    def __init__(self, yaml_path: str = "locales/zh_TW.yaml"):
        """
        åˆå§‹åŒ–

        Args:
            yaml_path: YAML èªè¨€åŒ…è·¯å¾‘
        """
        self.yaml_path = Path(yaml_path)
        self.translations = self._load_yaml()
        self.string_to_key = self._build_reverse_map()

    def _load_yaml(self) -> Dict:
        """è¼‰å…¥ YAML èªè¨€åŒ…"""
        with open(self.yaml_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def _build_reverse_map(self) -> Dict[str, str]:
        """
        å»ºç«‹ ä¸­æ–‡å­—ä¸² â†’ ç¿»è­¯éµå€¼ çš„åå‘æ˜ å°„

        Returns:
            æ˜ å°„å­—å…¸
        """
        mapping = {}

        def traverse(data, prefix=""):
            """éè¿´éæ­· YAML çµæ§‹"""
            if isinstance(data, dict):
                for key, value in data.items():
                    if key == 'meta':
                        continue  # è·³é meta è³‡è¨Š

                    new_prefix = f"{prefix}.{key}" if prefix else key

                    if isinstance(value, str):
                        # ç§»é™¤ Rich æ ¼å¼æ¨™è¨˜é€²è¡ŒåŒ¹é…
                        clean_value = self._strip_rich_tags(value)
                        mapping[clean_value] = new_prefix
                        mapping[value] = new_prefix  # ä¹Ÿä¿ç•™åŸå§‹ç‰ˆæœ¬
                    elif isinstance(value, dict):
                        traverse(value, new_prefix)

        traverse(self.translations)
        return mapping

    def _strip_rich_tags(self, text: str) -> str:
        """ç§»é™¤ Rich æ ¼å¼æ¨™è¨˜"""
        return re.sub(r'\[/?[^\]]+\]', '', text)

    def _contains_chinese(self, text: str) -> bool:
        """æª¢æŸ¥å­—ä¸²æ˜¯å¦åŒ…å«ä¸­æ–‡"""
        return bool(re.search(r'[\u4e00-\u9fa5]', text))

    def _similarity(self, a: str, b: str) -> float:
        """è¨ˆç®—å­—ä¸²ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰"""
        return SequenceMatcher(None, a, b).ratio()

    def find_translation_key(self, chinese_str: str, threshold: float = 0.85) -> Optional[str]:
        """
        æ™ºèƒ½åŒ¹é…ç¿»è­¯éµå€¼

        Args:
            chinese_str: ä¸­æ–‡å­—ä¸²
            threshold: ç›¸ä¼¼åº¦é–¾å€¼

        Returns:
            ç¿»è­¯éµå€¼æˆ– None
        """
        # ç§»é™¤å‰å¾Œç©ºç™½
        chinese_str = chinese_str.strip()

        # 1. ç²¾ç¢ºåŒ¹é…
        if chinese_str in self.string_to_key:
            return self.string_to_key[chinese_str]

        # 2. ç§»é™¤ Rich æ ¼å¼å¾ŒåŒ¹é…
        clean_str = self._strip_rich_tags(chinese_str)
        if clean_str in self.string_to_key:
            return self.string_to_key[clean_str]

        # 3. æ¨¡ç³ŠåŒ¹é…ï¼ˆåªå°çŸ­å­—ä¸²ï¼Œé¿å…èª¤åŒ¹é…ï¼‰
        if len(chinese_str) < 50:
            best_match = None
            best_score = 0

            for key_str, key in self.string_to_key.items():
                score = self._similarity(clean_str, self._strip_rich_tags(key_str))
                if score > best_score and score >= threshold:
                    best_score = score
                    best_match = key

            if best_match:
                return best_match

        return None

    def extract_chinese_strings(self, file_path: str) -> List[Tuple[int, str, str]]:
        """
        æå–æª”æ¡ˆä¸­çš„ä¸­æ–‡å­—ä¸²

        Args:
            file_path: Python æª”æ¡ˆè·¯å¾‘

        Returns:
            [(è¡Œè™Ÿ, åŸå§‹å­—ä¸², å»ºè­°éµå€¼), ...]
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        results = []

        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å­—ä¸²ï¼ˆç°¡åŒ–ç‰ˆï¼Œé©ç”¨æ–¼å¤§å¤šæ•¸æƒ…æ³ï¼‰
        patterns = [
            (r'\"([^\"]*[\u4e00-\u9fa5]+[^\"]*)\"', 'é›™å¼•è™Ÿ'),
            (r"'([^']*[\u4e00-\u9fa5]+[^']*)'", 'å–®å¼•è™Ÿ'),
            (r'f\"([^\"]*[\u4e00-\u9fa5]+[^\"]*)\"', 'f-string é›™å¼•è™Ÿ'),
            (r"f'([^']*[\u4e00-\u9fa5]+[^']*)'", 'f-string å–®å¼•è™Ÿ'),
        ]

        lines = content.split('\n')

        for line_no, line in enumerate(lines, 1):
            # è·³éè¨»è§£
            if line.strip().startswith('#'):
                continue

            for pattern, pattern_type in patterns:
                matches = re.finditer(pattern, line)
                for match in matches:
                    chinese_str = match.group(1)

                    # è·³ééçŸ­æˆ–éé•·çš„å­—ä¸²
                    if len(chinese_str) < 2 or len(chinese_str) > 200:
                        continue

                    # æŸ¥æ‰¾ç¿»è­¯éµå€¼
                    key = self.find_translation_key(chinese_str)

                    results.append((line_no, chinese_str, key))

        return results

    def generate_report(self, file_path: str) -> str:
        """
        ç”Ÿæˆæ”¹å¯«å ±å‘Š

        Args:
            file_path: Python æª”æ¡ˆè·¯å¾‘

        Returns:
            Markdown æ ¼å¼å ±å‘Š
        """
        strings = self.extract_chinese_strings(file_path)

        report = []
        report.append(f"# i18n æ”¹å¯«å ±å‘Š: {Path(file_path).name}\n")
        report.append(f"**æƒææ™‚é–“**: 2025-10-25\n")
        report.append(f"**æª”æ¡ˆè·¯å¾‘**: {file_path}\n")
        report.append(f"**ç™¼ç¾ä¸­æ–‡å­—ä¸²**: {len(strings)} å€‹\n")

        # çµ±è¨ˆ
        matched = sum(1 for _, _, key in strings if key)
        unmatched = len(strings) - matched

        report.append(f"\n## ğŸ“Š çµ±è¨ˆ\n")
        report.append(f"- âœ… å·²åŒ¹é…: {matched} å€‹\n")
        report.append(f"- âŒ æœªåŒ¹é…: {unmatched} å€‹\n")
        report.append(f"- ğŸ“ˆ åŒ¹é…ç‡: {matched/len(strings)*100:.1f}%\n" if strings else "- ğŸ“ˆ åŒ¹é…ç‡: N/A\n")

        # è©³ç´°åˆ—è¡¨
        report.append(f"\n## ğŸ“‹ è©³ç´°åˆ—è¡¨\n")

        if matched > 0:
            report.append(f"\n### âœ… å·²åŒ¹é…å­—ä¸² ({matched} å€‹)\n")
            for line_no, chinese_str, key in strings:
                if key:
                    # æˆªæ–·éé•·å­—ä¸²
                    display_str = chinese_str if len(chinese_str) <= 50 else chinese_str[:50] + "..."
                    report.append(f"- **L{line_no}**: `{display_str}`\n")
                    report.append(f"  - éµå€¼: `{key}`\n")
                    report.append(f"  - å»ºè­°: `t('{key}')`\n")

        if unmatched > 0:
            report.append(f"\n### âŒ æœªåŒ¹é…å­—ä¸² ({unmatched} å€‹)\n")
            report.append(f"**é€™äº›å­—ä¸²éœ€è¦æ‰‹å‹•è™•ç†æˆ–æ·»åŠ åˆ° zh_TW.yaml**\n\n")
            for line_no, chinese_str, key in strings:
                if not key:
                    display_str = chinese_str if len(chinese_str) <= 50 else chinese_str[:50] + "..."
                    report.append(f"- **L{line_no}**: `{display_str}`\n")

        # æ”¹å¯«å»ºè­°
        report.append(f"\n## ğŸ› ï¸ æ”¹å¯«æ­¥é©Ÿ\n")
        report.append(f"\n1. åœ¨æª”æ¡ˆé–‹é ­æ·»åŠ å°å…¥:\n")
        report.append(f"```python\n")
        report.append(f"from utils.i18n import t, _\n")
        report.append(f"```\n")

        report.append(f"\n2. æ›¿æ›å·²åŒ¹é…çš„å­—ä¸²ï¼ˆ{matched} è™•ï¼‰\n")

        if unmatched > 0:
            report.append(f"\n3. è™•ç†æœªåŒ¹é…å­—ä¸²ï¼ˆ{unmatched} è™•ï¼‰:\n")
            report.append(f"   - é¸é … A: æ·»åŠ åˆ° locales/zh_TW.yaml\n")
            report.append(f"   - é¸é … B: ä¿æŒåŸæ¨£ï¼ˆå¦‚æœæ˜¯å‹•æ…‹å­—ä¸²æˆ–ä¸éœ€ç¿»è­¯ï¼‰\n")

        report.append(f"\n## âœ… å®Œæˆæª¢æŸ¥æ¸…å–®\n")
        report.append(f"- [ ] æ·»åŠ  i18n å°å…¥èªå¥\n")
        report.append(f"- [ ] æ›¿æ›æ‰€æœ‰å·²åŒ¹é…å­—ä¸²\n")
        report.append(f"- [ ] è™•ç†æœªåŒ¹é…å­—ä¸²\n")
        report.append(f"- [ ] æ¸¬è©¦æª”æ¡ˆèªæ³•æ­£ç¢ºæ€§\n")
        report.append(f"- [ ] æ¸¬è©¦åŠŸèƒ½å®Œæ•´æ€§\n")

        return ''.join(report)

    def analyze_file(self, file_path: str):
        """
        åˆ†ææª”æ¡ˆä¸¦è¼¸å‡ºå ±å‘Šï¼ˆå‘½ä»¤åˆ—ä½¿ç”¨ï¼‰

        Args:
            file_path: Python æª”æ¡ˆè·¯å¾‘
        """
        print("=" * 60)
        print(f"åˆ†ææª”æ¡ˆ: {file_path}")
        print("=" * 60)

        strings = self.extract_chinese_strings(file_path)

        print(f"\nç™¼ç¾ {len(strings)} å€‹ä¸­æ–‡å­—ä¸²")

        matched = [(line, s, k) for line, s, k in strings if k]
        unmatched = [(line, s, k) for line, s, k in strings if not k]

        print(f"âœ… å·²åŒ¹é…: {len(matched)} å€‹")
        print(f"âŒ æœªåŒ¹é…: {len(unmatched)} å€‹")

        if matched:
            print(f"\nå‰ 5 å€‹å·²åŒ¹é…ç¯„ä¾‹:")
            for line_no, chinese_str, key in matched[:5]:
                display_str = chinese_str[:40] + "..." if len(chinese_str) > 40 else chinese_str
                print(f"  L{line_no}: {display_str}")
                print(f"        â†’ t('{key}')")

        if unmatched:
            print(f"\nå‰ 5 å€‹æœªåŒ¹é…å­—ä¸²:")
            for line_no, chinese_str, _ in unmatched[:5]:
                display_str = chinese_str[:40] + "..." if len(chinese_str) > 40 else chinese_str
                print(f"  L{line_no}: {display_str}")

        print("\n" + "=" * 60)


def main():
    """å‘½ä»¤åˆ—å…¥å£"""
    import sys

    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹å¼: python i18n_rewriter.py <python_file>")
        print("ç¯„ä¾‹: python i18n_rewriter.py gemini_pricing.py")
        sys.exit(1)

    file_path = sys.argv[1]

    if not Path(file_path).exists():
        print(f"âŒ æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
        sys.exit(1)

    rewriter = I18nRewriter()

    # åˆ†ææª”æ¡ˆ
    rewriter.analyze_file(file_path)

    # ç”Ÿæˆè©³ç´°å ±å‘Š
    report = rewriter.generate_report(file_path)
    report_path = Path(file_path).stem + "_i18n_report.md"

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"\nğŸ“ è©³ç´°å ±å‘Šå·²å„²å­˜è‡³: {report_path}")


if __name__ == "__main__":
    main()
