#!/usr/bin/env python3
"""
æ‰¹æ¬¡è«‹æ±‚åˆä½µå™¨
å°‡å¤šå€‹ API è«‹æ±‚åˆä½µç‚ºå–®ä¸€èª¿ç”¨ï¼Œæ¸›å°‘ç¶²è·¯å¾€è¿”æ¬¡æ•¸

ç‰¹æ€§ï¼š
1. æ™‚é–“è¦–çª—åˆä½µï¼ˆé è¨­ 500msï¼‰
2. è«‹æ±‚ ID è¿½è¹¤èˆ‡å›æ‡‰æ‹†åˆ†
3. æ™ºèƒ½æ‹†åˆ†ç­–ç•¥ï¼ˆæ¨™è¨˜ â†’ åˆ†éš”ç¬¦ â†’ å¹³å‡åˆ†é…ï¼‰
4. å®Œæ•´éŒ¯èª¤è™•ç†ï¼ˆéƒ¨åˆ†å¤±æ•—æ”¯æ´ï¼‰
5. çµ±è¨ˆè³‡è¨Šæ”¶é›†

ä½œè€…ï¼šClaude Code (Sonnet 4.5)
æ—¥æœŸï¼š2025-10-25
ç‰ˆæœ¬ï¼š1.0.0
"""
import asyncio
import re
import time
from typing import Callable, List, Dict, Any, Optional
from dataclasses import dataclass, field
from rich.console import Console

console = Console()


# ==================== è³‡æ–™çµæ§‹ ====================

@dataclass
class BatchRequest:
    """æ‰¹æ¬¡è«‹æ±‚è³‡æ–™çµæ§‹"""
    request_id: int
    model: str
    content: str
    future: asyncio.Future
    timestamp: float = field(default_factory=time.time)


# ==================== æ ¸å¿ƒåˆä½µå™¨ ====================

class BatchRequestMerger:
    """
    æ‰¹æ¬¡è«‹æ±‚åˆä½µå™¨

    å°‡æ™‚é–“è¦–çª—å…§çš„å¤šå€‹è«‹æ±‚åˆä½µç‚ºå–®ä¸€ API èª¿ç”¨ï¼Œ
    ç„¶å¾Œæ™ºèƒ½æ‹†åˆ†å›æ‡‰ä¸¦åˆ†é…çµ¦å„å€‹è«‹æ±‚ã€‚

    ä½¿ç”¨ç¯„ä¾‹ï¼š
        merger = BatchRequestMerger(merge_window=0.5)

        # API èª¿ç”¨å‡½æ•¸
        async def api_caller(content):
            response = await client.generate_content(content)
            return response.text

        # æäº¤è«‹æ±‚ï¼ˆè‡ªå‹•åˆä½µï¼‰
        result = await merger.submit(
            model='gemini-2.5-flash',
            content='åˆ†æé€™å¼µåœ–ç‰‡',
            api_caller=api_caller
        )
    """

    def __init__(
        self,
        merge_window: float = 0.5,
        max_batch_size: int = 10,
        enabled: bool = True,
        verbose: bool = False
    ):
        """
        åˆå§‹åŒ–åˆä½µå™¨

        Args:
            merge_window: åˆä½µè¦–çª—æ™‚é–“ï¼ˆç§’ï¼‰
            max_batch_size: å–®æ‰¹æ¬¡æœ€å¤§è«‹æ±‚æ•¸
            enabled: æ˜¯å¦å•Ÿç”¨åˆä½µ
            verbose: æ˜¯å¦é¡¯ç¤ºè©³ç´°è³‡è¨Š
        """
        self.merge_window = merge_window
        self.max_batch_size = max_batch_size
        self.enabled = enabled
        self.verbose = verbose

        # è«‹æ±‚ä½‡åˆ— {model: [requests]}
        self.pending_requests: Dict[str, List[BatchRequest]] = {}

        # è¨ˆæ™‚å™¨ {model: Task}
        self.merge_timers: Dict[str, asyncio.Task] = {}

        # è«‹æ±‚ ID è¨ˆæ•¸å™¨
        self._next_request_id = 0

        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            'total_requests': 0,
            'merged_batches': 0,
            'total_api_calls': 0,
            'total_merged_requests': 0
        }

        # é–ï¼ˆä¿è­·ä½‡åˆ—ï¼‰
        self._lock = asyncio.Lock()

    async def submit(
        self,
        model: str,
        content: str,
        api_caller: Callable[[str], Any]
    ) -> str:
        """
        æäº¤è«‹æ±‚ï¼ˆè‡ªå‹•åˆä½µï¼‰

        Args:
            model: æ¨¡å‹åç¨±
            content: è«‹æ±‚å…§å®¹
            api_caller: API èª¿ç”¨å‡½æ•¸ï¼ˆæ¥å— merged_contentï¼Œè¿”å› responseï¼‰

        Returns:
            API å›æ‡‰çµæœ
        """
        if not self.enabled:
            # åˆä½µå™¨åœç”¨ï¼Œç›´æ¥èª¿ç”¨
            return await api_caller(content)

        self.stats['total_requests'] += 1

        # åˆ†é…è«‹æ±‚ ID
        request_id = self._next_request_id
        self._next_request_id += 1

        # å‰µå»º futureï¼ˆç”¨æ–¼ç­‰å¾…çµæœï¼‰
        future = asyncio.Future()

        # å‰µå»ºè«‹æ±‚
        request = BatchRequest(
            request_id=request_id,
            model=model,
            content=content,
            future=future
        )

        # åŠ å…¥ä½‡åˆ—
        async with self._lock:
            if model not in self.pending_requests:
                self.pending_requests[model] = []

            self.pending_requests[model].append(request)

            # æª¢æŸ¥æ˜¯å¦éœ€è¦ç«‹å³åŸ·è¡Œï¼ˆé”åˆ°æ‰¹æ¬¡å¤§å°ï¼‰
            if len(self.pending_requests[model]) >= self.max_batch_size:
                # ç«‹å³åŸ·è¡Œï¼ˆå–æ¶ˆè¨ˆæ™‚å™¨ï¼‰
                if model in self.merge_timers:
                    self.merge_timers[model].cancel()
                    del self.merge_timers[model]

                # åŸ·è¡Œæ‰¹æ¬¡
                asyncio.create_task(self._execute_batch(model, api_caller))

            # å¦å‰‡ï¼Œå•Ÿå‹•/é‡è¨­è¨ˆæ™‚å™¨
            elif model not in self.merge_timers or self.merge_timers[model].done():
                self.merge_timers[model] = asyncio.create_task(
                    self._merge_timer(model, api_caller)
                )

        # ç­‰å¾…çµæœ
        return await future

    async def _merge_timer(self, model: str, api_caller: Callable):
        """åˆä½µè¨ˆæ™‚å™¨ï¼ˆç­‰å¾…è¦–çª—çµæŸå¾ŒåŸ·è¡Œæ‰¹æ¬¡ï¼‰"""
        await asyncio.sleep(self.merge_window)
        await self._execute_batch(model, api_caller)

    async def _execute_batch(self, model: str, api_caller: Callable):
        """
        åŸ·è¡Œæ‰¹æ¬¡è«‹æ±‚

        1. å–å‡ºæ‰€æœ‰å¾…è™•ç†è«‹æ±‚
        2. åˆä½µç‚ºå–®ä¸€è«‹æ±‚
        3. èª¿ç”¨ API
        4. æ‹†åˆ†å›æ‡‰
        5. åˆ†é…çµæœ
        """
        async with self._lock:
            # å–å‡ºè«‹æ±‚
            if model not in self.pending_requests or not self.pending_requests[model]:
                return

            requests = self.pending_requests[model]
            self.pending_requests[model] = []

            # æ¸…é™¤è¨ˆæ™‚å™¨
            if model in self.merge_timers:
                del self.merge_timers[model]

        # çµ±è¨ˆ
        batch_size = len(requests)
        if batch_size > 1:
            self.stats['merged_batches'] += 1
            self.stats['total_merged_requests'] += batch_size

        self.stats['total_api_calls'] += 1

        # æç¤ºï¼ˆdimï¼Œä¸å¹²æ“¾ï¼‰
        if self.verbose and batch_size > 1:
            console.print(f"[dim]ğŸ”— åˆä½µæ‰¹æ¬¡ï¼š{batch_size} å€‹è«‹æ±‚ â†’ 1 æ¬¡ API èª¿ç”¨[/dim]")

        # åˆä½µè«‹æ±‚
        merged_content = self._merge_requests(requests)

        try:
            # èª¿ç”¨ API
            merged_response = await api_caller(merged_content)

            # æ‹†åˆ†å›æ‡‰
            responses = self._split_response(merged_response, requests)

            # åˆ†é…çµæœ
            for request, response in zip(requests, responses):
                if not request.future.done():
                    request.future.set_result(response)

        except Exception as e:
            # API èª¿ç”¨å¤±æ•—ï¼Œæ‰€æœ‰è«‹æ±‚éƒ½æ¨™è¨˜ç‚ºå¤±æ•—
            for request in requests:
                if not request.future.done():
                    request.future.set_exception(e)

    def _merge_requests(self, requests: List[BatchRequest]) -> str:
        """
        åˆä½µå¤šå€‹è«‹æ±‚ç‚ºå–®ä¸€è«‹æ±‚

        æ ¼å¼ï¼š
        [REQUEST_0]
        {content_0}
        [END_REQUEST_0]

        [REQUEST_1]
        {content_1}
        [END_REQUEST_1]
        ...
        """
        if len(requests) == 1:
            return requests[0].content

        merged_parts = []
        for req in requests:
            merged_parts.append(
                f"[REQUEST_{req.request_id}]\n"
                f"{req.content}\n"
                f"[END_REQUEST_{req.request_id}]"
            )

        return "\n\n".join(merged_parts)

    def _split_response(
        self,
        merged_response: str,
        requests: List[BatchRequest]
    ) -> List[str]:
        """
        æ‹†åˆ†åˆä½µå¾Œçš„å›æ‡‰

        ç­–ç•¥ï¼š
        1. å°‹æ‰¾ [RESPONSE_N] æ¨™è¨˜
        2. å¦‚æœæ²’æœ‰æ¨™è¨˜ï¼Œä½¿ç”¨åˆ†éš”ç¬¦ï¼ˆ---ï¼‰
        3. å¦‚æœæ²’æœ‰åˆ†éš”ç¬¦ï¼ŒæŒ‰é•·åº¦å¹³å‡åˆ†é…

        Args:
            merged_response: åˆä½µå¾Œçš„å›æ‡‰
            requests: è«‹æ±‚åˆ—è¡¨

        Returns:
            æ‹†åˆ†å¾Œçš„å›æ‡‰åˆ—è¡¨
        """
        num_requests = len(requests)

        # å–®ä¸€è«‹æ±‚ï¼Œç„¡éœ€æ‹†åˆ†
        if num_requests == 1:
            return [merged_response]

        # ç­–ç•¥ 1ï¼šå°‹æ‰¾ [RESPONSE_N] æ¨™è¨˜
        try:
            responses = self._split_by_markers(merged_response, requests)
            if responses:
                if self.verbose:
                    console.print(f"[dim]âœ‚ï¸  ä½¿ç”¨æ¨™è¨˜æ‹†åˆ†å›æ‡‰[/dim]")
                return responses
        except Exception:
            pass

        # ç­–ç•¥ 2ï¼šä½¿ç”¨åˆ†éš”ç¬¦ (---)
        try:
            responses = self._split_by_delimiter(merged_response, num_requests)
            if responses:
                if self.verbose:
                    console.print(f"[dim]âœ‚ï¸  ä½¿ç”¨åˆ†éš”ç¬¦æ‹†åˆ†å›æ‡‰[/dim]")
                return responses
        except Exception:
            pass

        # ç­–ç•¥ 3ï¼šå¹³å‡åˆ†é…ï¼ˆé™ç´šï¼‰
        if self.verbose:
            console.print(f"[dim]âš ï¸  é™ç´šï¼šä½¿ç”¨å¹³å‡åˆ†é…æ‹†åˆ†å›æ‡‰[/dim]")

        return self._split_by_length(merged_response, num_requests)

    def _split_by_markers(
        self,
        response: str,
        requests: List[BatchRequest]
    ) -> Optional[List[str]]:
        """ç­–ç•¥ 1ï¼šä½¿ç”¨ [RESPONSE_N] æ¨™è¨˜æ‹†åˆ†"""
        # å°‹æ‰¾æ‰€æœ‰æ¨™è¨˜
        pattern = r'\[RESPONSE_(\d+)\](.*?)\[END_RESPONSE_\1\]'
        matches = re.findall(pattern, response, re.DOTALL)

        if len(matches) != len(requests):
            return None

        # æŒ‰ request_id æ’åº
        matches_dict = {int(match[0]): match[1].strip() for match in matches}

        # æŒ‰è«‹æ±‚é †åºæå–
        responses = []
        for req in requests:
            if req.request_id not in matches_dict:
                return None
            responses.append(matches_dict[req.request_id])

        return responses

    def _split_by_delimiter(
        self,
        response: str,
        num_requests: int
    ) -> Optional[List[str]]:
        """ç­–ç•¥ 2ï¼šä½¿ç”¨åˆ†éš”ç¬¦ (---) æ‹†åˆ†"""
        # å˜—è©¦å¤šç¨®åˆ†éš”ç¬¦
        delimiters = ['---', '***', '===', '___']

        for delimiter in delimiters:
            parts = response.split(delimiter)
            if len(parts) == num_requests:
                return [part.strip() for part in parts]

        return None

    def _split_by_length(
        self,
        response: str,
        num_requests: int
    ) -> List[str]:
        """ç­–ç•¥ 3ï¼šæŒ‰é•·åº¦å¹³å‡åˆ†é…ï¼ˆé™ç´šï¼‰"""
        # è¨ˆç®—æ¯å€‹éƒ¨åˆ†çš„é•·åº¦
        length_per_request = len(response) // num_requests

        responses = []
        for i in range(num_requests):
            start = i * length_per_request
            end = start + length_per_request if i < num_requests - 1 else len(response)
            responses.append(response[start:end].strip())

        return responses

    def get_stats(self) -> Dict[str, Any]:
        """
        ç²å–çµ±è¨ˆè³‡è¨Š

        Returns:
            çµ±è¨ˆè³‡è¨Šå­—å…¸
        """
        total_requests = self.stats['total_requests']
        total_api_calls = self.stats['total_api_calls']

        return {
            **self.stats,
            'reduction_rate': (
                1 - (total_api_calls / total_requests)
            ) if total_requests > 0 else 0,
            'avg_batch_size': (
                self.stats['total_merged_requests'] / self.stats['merged_batches']
            ) if self.stats['merged_batches'] > 0 else 1
        }

    async def close(self):
        """é—œé–‰åˆä½µå™¨ï¼ˆæ¸…ç†è³‡æºï¼‰"""
        # å–æ¶ˆæ‰€æœ‰è¨ˆæ™‚å™¨
        for timer in self.merge_timers.values():
            if not timer.done():
                timer.cancel()

        self.merge_timers.clear()
        self.pending_requests.clear()


# ==================== ä½¿ç”¨ç¯„ä¾‹ ====================

if __name__ == "__main__":
    import random

    async def demo():
        """ç¤ºç¯„æ‰¹æ¬¡è«‹æ±‚åˆä½µ"""
        print("\n" + "="*70)
        print("æ‰¹æ¬¡è«‹æ±‚åˆä½µå™¨ç¤ºç¯„")
        print("="*70 + "\n")

        # æ¨¡æ“¬ API èª¿ç”¨
        api_call_count = 0

        async def mock_api_caller(content: str) -> str:
            """æ¨¡æ“¬ API èª¿ç”¨"""
            nonlocal api_call_count
            api_call_count += 1

            await asyncio.sleep(0.1)  # æ¨¡æ“¬ç¶²è·¯å»¶é²

            # ç°¡å–®å›æ‡‰ï¼ˆæŒ‰æ¨™è¨˜åˆ†éš”ï¼‰
            lines = content.split('\n')
            responses = []

            for i, line in enumerate(lines):
                if '[REQUEST_' in line:
                    req_id = re.search(r'\[REQUEST_(\d+)\]', line)
                    if req_id:
                        responses.append(
                            f"[RESPONSE_{req_id.group(1)}]"
                            f"Response to request {req_id.group(1)}"
                            f"[END_RESPONSE_{req_id.group(1)}]"
                        )

            return "\n\n".join(responses)

        # å‰µå»ºåˆä½µå™¨
        merger = BatchRequestMerger(
            merge_window=0.5,
            max_batch_size=10,
            verbose=True
        )

        # æ¸¬è©¦ 1ï¼šä¸¦è¡Œæäº¤å¤šå€‹è«‹æ±‚
        print("æ¸¬è©¦ 1ï¼šä¸¦è¡Œæäº¤ 20 å€‹è«‹æ±‚")
        print("-" * 70)

        start = time.time()

        tasks = [
            merger.submit(
                model='gemini-2.5-flash',
                content=f'åˆ†æä»»å‹™ {i}',
                api_caller=mock_api_caller
            )
            for i in range(20)
        ]

        results = await asyncio.gather(*tasks)
        elapsed = time.time() - start

        print(f"\nâœ… å®Œæˆ {len(results)} å€‹è«‹æ±‚")
        print(f"â±ï¸  ç¸½è€—æ™‚ï¼š{elapsed:.2f}s")
        print(f"ğŸ“ API èª¿ç”¨æ¬¡æ•¸ï¼š{api_call_count} æ¬¡")
        print(f"ğŸ“Š æ¸›å°‘ç‡ï¼š{(1 - api_call_count/20)*100:.1f}%")

        # çµ±è¨ˆè³‡è¨Š
        stats = merger.get_stats()
        print(f"\nçµ±è¨ˆè³‡è¨Šï¼š")
        print(f"  ç¸½è«‹æ±‚æ•¸ï¼š{stats['total_requests']}")
        print(f"  åˆä½µæ‰¹æ¬¡æ•¸ï¼š{stats['merged_batches']}")
        print(f"  å¹³å‡æ‰¹æ¬¡å¤§å°ï¼š{stats['avg_batch_size']:.1f}")
        print(f"  API èª¿ç”¨æ¸›å°‘ï¼š{stats['reduction_rate']*100:.1f}%")

        print("\n" + "="*70)
        print("ç¤ºç¯„å®Œæˆ")
        print("="*70 + "\n")

        await merger.close()

    asyncio.run(demo())
