#!/usr/bin/env python3
"""
æ€§èƒ½ç›£æ§æ¨¡çµ„
æä¾›è™•ç†æ™‚é–“çµ±è¨ˆã€è³‡æºä½¿ç”¨ç›£æ§ã€ç“¶é ¸åˆ†æå ±å‘ŠåŠŸèƒ½
"""
import time
import psutil
import threading
from datetime import datetime
from typing import Dict, List, Optional, Callable, Any
from dataclasses import dataclass, field
from contextlib import contextmanager
from functools import wraps
from collections import defaultdict
import json
import os

# Rich æ ¼å¼åŒ–è¼¸å‡º
try:
    from rich.console import Console
    from rich.table import Table
    from rich.panel import Panel
    from rich.progress import Progress, SpinnerColumn, TextColumn
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False

console = Console() if RICH_AVAILABLE else None


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ¨™è³‡æ–™çµæ§‹"""
    name: str                           # æ“ä½œåç¨±
    start_time: float                   # é–‹å§‹æ™‚é–“ï¼ˆtimestampï¼‰
    end_time: Optional[float] = None    # çµæŸæ™‚é–“ï¼ˆtimestampï¼‰
    duration: Optional[float] = None    # æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰
    cpu_usage_start: Optional[float] = None   # é–‹å§‹æ™‚ CPU ä½¿ç”¨ç‡ï¼ˆ%ï¼‰
    cpu_usage_end: Optional[float] = None     # çµæŸæ™‚ CPU ä½¿ç”¨ç‡ï¼ˆ%ï¼‰
    cpu_usage_avg: Optional[float] = None     # å¹³å‡ CPU ä½¿ç”¨ç‡ï¼ˆ%ï¼‰
    memory_usage_start: Optional[float] = None  # é–‹å§‹æ™‚è¨˜æ†¶é«”ä½¿ç”¨ï¼ˆMBï¼‰
    memory_usage_end: Optional[float] = None    # çµæŸæ™‚è¨˜æ†¶é«”ä½¿ç”¨ï¼ˆMBï¼‰
    memory_usage_peak: Optional[float] = None   # å³°å€¼è¨˜æ†¶é«”ä½¿ç”¨ï¼ˆMBï¼‰
    metadata: Dict[str, Any] = field(default_factory=dict)  # é¡å¤–å…ƒæ•¸æ“š


@dataclass
class BottleneckAnalysis:
    """ç“¶é ¸åˆ†æçµæœ"""
    operation: str          # æ“ä½œåç¨±
    total_time: float       # ç¸½è€—æ™‚ï¼ˆç§’ï¼‰
    percentage: float       # å ç¸½æ™‚é–“ç™¾åˆ†æ¯”
    count: int              # åŸ·è¡Œæ¬¡æ•¸
    avg_time: float         # å¹³å‡è€—æ™‚ï¼ˆç§’ï¼‰
    max_time: float         # æœ€å¤§è€—æ™‚ï¼ˆç§’ï¼‰
    min_time: float         # æœ€å°è€—æ™‚ï¼ˆç§’ï¼‰
    memory_impact: float    # è¨˜æ†¶é«”å½±éŸ¿ï¼ˆMBï¼‰
    cpu_impact: float       # CPU å½±éŸ¿ï¼ˆ%ï¼‰


class PerformanceMonitor:
    """
    æ€§èƒ½ç›£æ§å™¨

    åŠŸèƒ½ï¼š
    1. è™•ç†æ™‚é–“çµ±è¨ˆ - è¿½è¹¤æ¯å€‹æ“ä½œçš„åŸ·è¡Œæ™‚é–“
    2. è³‡æºä½¿ç”¨ç›£æ§ - ç›£æ§ CPUã€è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
    3. ç“¶é ¸åˆ†æå ±å‘Š - è­˜åˆ¥æ€§èƒ½ç“¶é ¸ä¸¦ç”Ÿæˆå ±å‘Š

    ä½¿ç”¨æ–¹å¼ï¼š
    1. è£é£¾å™¨ï¼š@monitor.track_performance("æ“ä½œåç¨±")
    2. ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼šwith monitor.measure("æ“ä½œåç¨±"):
    3. æ‰‹å‹•èª¿ç”¨ï¼šmonitor.start() / monitor.stop()
    """

    def __init__(self, enabled: bool = True):
        """
        åˆå§‹åŒ–æ€§èƒ½ç›£æ§å™¨

        Args:
            enabled: æ˜¯å¦å•Ÿç”¨ç›£æ§ï¼ˆé è¨­ Trueï¼‰
        """
        self.enabled = enabled
        self.metrics: List[PerformanceMetrics] = []
        self.current_operations: Dict[str, PerformanceMetrics] = {}
        self._lock = threading.Lock()
        self._monitoring_thread: Optional[threading.Thread] = None
        self._stop_monitoring = threading.Event()
        self._resource_samples: Dict[str, List[tuple]] = defaultdict(list)  # {operation: [(timestamp, cpu, mem), ...]}

    def enable(self):
        """å•Ÿç”¨ç›£æ§"""
        self.enabled = True

    def disable(self):
        """åœç”¨ç›£æ§"""
        self.enabled = False

    def clear(self):
        """æ¸…é™¤æ‰€æœ‰è¨˜éŒ„"""
        with self._lock:
            self.metrics.clear()
            self.current_operations.clear()
            self._resource_samples.clear()

    def _get_current_resources(self) -> tuple:
        """
        ç²å–ç•¶å‰è³‡æºä½¿ç”¨æƒ…æ³

        Returns:
            (cpu_percent, memory_mb)
        """
        try:
            process = psutil.Process()
            cpu_percent = process.cpu_percent(interval=0.1)
            memory_mb = process.memory_info().rss / 1024 / 1024
            return cpu_percent, memory_mb
        except Exception:
            return 0.0, 0.0

    def _start_resource_monitoring(self, operation_name: str, interval: float = 0.5):
        """
        é–‹å§‹èƒŒæ™¯è³‡æºç›£æ§

        Args:
            operation_name: æ“ä½œåç¨±
            interval: æ¡æ¨£é–“éš”ï¼ˆç§’ï¼‰
        """
        def monitor_loop():
            while not self._stop_monitoring.is_set():
                timestamp = time.time()
                cpu, mem = self._get_current_resources()
                with self._lock:
                    self._resource_samples[operation_name].append((timestamp, cpu, mem))
                time.sleep(interval)

        self._stop_monitoring.clear()
        self._monitoring_thread = threading.Thread(target=monitor_loop, daemon=True)
        self._monitoring_thread.start()

    def _stop_resource_monitoring(self):
        """åœæ­¢èƒŒæ™¯è³‡æºç›£æ§"""
        if self._monitoring_thread:
            self._stop_monitoring.set()
            self._monitoring_thread.join(timeout=1.0)
            self._monitoring_thread = None

    @contextmanager
    def measure(self, name: str, metadata: Optional[Dict[str, Any]] = None):
        """
        ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼šæ¸¬é‡ä»£ç¢¼å¡Šæ€§èƒ½

        ä½¿ç”¨ç¯„ä¾‹ï¼š
            with monitor.measure("å½±ç‰‡åˆ†æ"):
                # ä½ çš„ä»£ç¢¼
                analyze_video()

        Args:
            name: æ“ä½œåç¨±
            metadata: é¡å¤–å…ƒæ•¸æ“š
        """
        if not self.enabled:
            yield
            return

        # é–‹å§‹æ¸¬é‡
        start_time = time.time()
        cpu_start, mem_start = self._get_current_resources()

        # å•Ÿå‹•èƒŒæ™¯è³‡æºç›£æ§
        self._start_resource_monitoring(name)

        metric = PerformanceMetrics(
            name=name,
            start_time=start_time,
            cpu_usage_start=cpu_start,
            memory_usage_start=mem_start,
            metadata=metadata or {}
        )

        with self._lock:
            self.current_operations[name] = metric

        try:
            yield
        finally:
            # åœæ­¢èƒŒæ™¯ç›£æ§
            self._stop_resource_monitoring()

            # çµæŸæ¸¬é‡
            end_time = time.time()
            cpu_end, mem_end = self._get_current_resources()

            metric.end_time = end_time
            metric.duration = end_time - start_time
            metric.cpu_usage_end = cpu_end
            metric.memory_usage_end = mem_end

            # è¨ˆç®—å¹³å‡å€¼èˆ‡å³°å€¼
            with self._lock:
                samples = self._resource_samples.get(name, [])
                if samples:
                    cpu_values = [s[1] for s in samples]
                    mem_values = [s[2] for s in samples]
                    metric.cpu_usage_avg = sum(cpu_values) / len(cpu_values)
                    metric.memory_usage_peak = max(mem_values)
                else:
                    metric.cpu_usage_avg = (cpu_start + cpu_end) / 2
                    metric.memory_usage_peak = max(mem_start, mem_end)

                self.current_operations.pop(name, None)
                self.metrics.append(metric)
                self._resource_samples.pop(name, None)

    def track_performance(self, name: Optional[str] = None):
        """
        è£é£¾å™¨ï¼šè¿½è¹¤å‡½æ•¸æ€§èƒ½

        ä½¿ç”¨ç¯„ä¾‹ï¼š
            @monitor.track_performance("å½±ç‰‡è™•ç†")
            def process_video():
                pass

        Args:
            name: æ“ä½œåç¨±ï¼ˆè‹¥æœªæä¾›å‰‡ä½¿ç”¨å‡½æ•¸åï¼‰
        """
        def decorator(func: Callable) -> Callable:
            operation_name = name or func.__name__

            @wraps(func)
            def wrapper(*args, **kwargs):
                if not self.enabled:
                    return func(*args, **kwargs)

                with self.measure(operation_name):
                    return func(*args, **kwargs)

            return wrapper
        return decorator

    def get_summary(self) -> Dict[str, Any]:
        """
        ç²å–æ€§èƒ½æ‘˜è¦

        Returns:
            åŒ…å«ç¸½é«”çµ±è¨ˆçš„å­—å…¸
        """
        if not self.metrics:
            return {
                "total_operations": 0,
                "total_time": 0.0,
                "avg_time": 0.0,
                "total_memory_used": 0.0,
                "avg_cpu_usage": 0.0
            }

        total_time = sum(m.duration for m in self.metrics if m.duration)
        avg_time = total_time / len(self.metrics) if self.metrics else 0

        memory_deltas = [
            (m.memory_usage_end - m.memory_usage_start)
            for m in self.metrics
            if m.memory_usage_start and m.memory_usage_end
        ]
        total_memory = sum(memory_deltas) if memory_deltas else 0

        cpu_values = [
            m.cpu_usage_avg
            for m in self.metrics
            if m.cpu_usage_avg
        ]
        avg_cpu = sum(cpu_values) / len(cpu_values) if cpu_values else 0

        return {
            "total_operations": len(self.metrics),
            "total_time": total_time,
            "avg_time": avg_time,
            "total_memory_used": total_memory,
            "avg_cpu_usage": avg_cpu,
            "operations": [m.name for m in self.metrics]
        }

    def analyze_bottlenecks(self, top_n: int = 10) -> List[BottleneckAnalysis]:
        """
        åˆ†ææ€§èƒ½ç“¶é ¸

        Args:
            top_n: è¿”å›å‰ N å€‹ç“¶é ¸

        Returns:
            ç“¶é ¸åˆ†æçµæœåˆ—è¡¨ï¼ˆæŒ‰ç¸½è€—æ™‚é™åºæ’åˆ—ï¼‰
        """
        if not self.metrics:
            return []

        # æŒ‰æ“ä½œåç¨±åˆ†çµ„
        operation_groups: Dict[str, List[PerformanceMetrics]] = defaultdict(list)
        for metric in self.metrics:
            operation_groups[metric.name].append(metric)

        # è¨ˆç®—ç¸½æ™‚é–“
        total_time = sum(m.duration for m in self.metrics if m.duration)
        if total_time == 0:
            return []

        # åˆ†ææ¯å€‹æ“ä½œ
        analyses = []
        for op_name, op_metrics in operation_groups.items():
            durations = [m.duration for m in op_metrics if m.duration]
            if not durations:
                continue

            op_total_time = sum(durations)
            op_count = len(durations)

            # è¨˜æ†¶é«”å½±éŸ¿
            memory_deltas = [
                (m.memory_usage_peak - m.memory_usage_start)
                for m in op_metrics
                if m.memory_usage_peak and m.memory_usage_start
            ]
            memory_impact = sum(memory_deltas) / len(memory_deltas) if memory_deltas else 0

            # CPU å½±éŸ¿
            cpu_values = [m.cpu_usage_avg for m in op_metrics if m.cpu_usage_avg]
            cpu_impact = sum(cpu_values) / len(cpu_values) if cpu_values else 0

            analysis = BottleneckAnalysis(
                operation=op_name,
                total_time=op_total_time,
                percentage=(op_total_time / total_time) * 100,
                count=op_count,
                avg_time=op_total_time / op_count,
                max_time=max(durations),
                min_time=min(durations),
                memory_impact=memory_impact,
                cpu_impact=cpu_impact
            )
            analyses.append(analysis)

        # æŒ‰ç¸½è€—æ™‚é™åºæ’åˆ—
        analyses.sort(key=lambda x: x.total_time, reverse=True)

        return analyses[:top_n]

    def print_summary(self):
        """åˆ—å°æ€§èƒ½æ‘˜è¦ï¼ˆä½¿ç”¨ Rich æ ¼å¼åŒ–ï¼‰"""
        summary = self.get_summary()

        if RICH_AVAILABLE and console:
            table = Table(title="âš¡ æ€§èƒ½ç›£æ§æ‘˜è¦", show_header=True, header_style="bold bright_magenta")
            table.add_column("æŒ‡æ¨™", style="bright_magenta")
            table.add_column("æ•¸å€¼", style="#DDA0DD")

            table.add_row("ç¸½æ“ä½œæ•¸", f"{summary['total_operations']:,}")
            table.add_row("ç¸½è€—æ™‚", f"{summary['total_time']:.2f} ç§’")
            table.add_row("å¹³å‡è€—æ™‚", f"{summary['avg_time']:.2f} ç§’")
            table.add_row("è¨˜æ†¶é«”ä½¿ç”¨", f"{summary['total_memory_used']:.2f} MB")
            table.add_row("å¹³å‡ CPU ä½¿ç”¨ç‡", f"{summary['avg_cpu_usage']:.1f}%")

            console.print(table)
        else:
            print("\nâš¡ æ€§èƒ½ç›£æ§æ‘˜è¦")
            print("=" * 50)
            print(f"ç¸½æ“ä½œæ•¸: {summary['total_operations']:,}")
            print(f"ç¸½è€—æ™‚: {summary['total_time']:.2f} ç§’")
            print(f"å¹³å‡è€—æ™‚: {summary['avg_time']:.2f} ç§’")
            print(f"è¨˜æ†¶é«”ä½¿ç”¨: {summary['total_memory_used']:.2f} MB")
            print(f"å¹³å‡ CPU ä½¿ç”¨ç‡: {summary['avg_cpu_usage']:.1f}%")
            print("=" * 50)

    def print_bottleneck_report(self, top_n: int = 10):
        """
        åˆ—å°ç“¶é ¸åˆ†æå ±å‘Š

        Args:
            top_n: é¡¯ç¤ºå‰ N å€‹ç“¶é ¸
        """
        bottlenecks = self.analyze_bottlenecks(top_n=top_n)

        if not bottlenecks:
            if RICH_AVAILABLE and console:
                console.print("[#DDA0DD]æ²’æœ‰æ€§èƒ½æ•¸æ“šå¯ä¾›åˆ†æ[/#DDA0DD]")
            else:
                print("æ²’æœ‰æ€§èƒ½æ•¸æ“šå¯ä¾›åˆ†æ")
            return

        if RICH_AVAILABLE and console:
            table = Table(
                title=f"ğŸ” ç“¶é ¸åˆ†æå ±å‘Šï¼ˆTop {len(bottlenecks)}ï¼‰",
                show_header=True,
                header_style="bold #DDA0DD"
            )
            console_width = console.width or 120
            table.add_column("æ’å", style="bright_magenta", width=max(6, int(console_width * 0.05)))
            table.add_column("æ“ä½œ", style="#DDA0DD")
            table.add_column("ç¸½è€—æ™‚", style="red")
            table.add_column("å æ¯”", style="red")
            table.add_column("æ¬¡æ•¸", style="green")
            table.add_column("å¹³å‡", style="bright_magenta")
            table.add_column("è¨˜æ†¶é«”", style="#DDA0DD")
            table.add_column("CPU", style="bright_magenta")

            for idx, b in enumerate(bottlenecks, 1):
                table.add_row(
                    f"#{idx}",
                    b.operation,
                    f"{b.total_time:.2f}s",
                    f"{b.percentage:.1f}%",
                    f"{b.count}",
                    f"{b.avg_time:.2f}s",
                    f"{b.memory_impact:.1f}MB",
                    f"{b.cpu_impact:.1f}%"
                )

            console.print(table)

            # å»ºè­°
            console.print("\n[bold #DDA0DD]ğŸ’¡ å„ªåŒ–å»ºè­°ï¼š[/bold #DDA0DD]")
            for idx, b in enumerate(bottlenecks[:3], 1):
                suggestion = self._get_optimization_suggestion(b)
                console.print(f"  {idx}. {b.operation}: {suggestion}")
        else:
            print(f"\nğŸ” ç“¶é ¸åˆ†æå ±å‘Šï¼ˆTop {len(bottlenecks)}ï¼‰")
            print("=" * 100)
            print(f"{'æ’å':<6} {'æ“ä½œ':<30} {'ç¸½è€—æ™‚':<12} {'å æ¯”':<8} {'æ¬¡æ•¸':<6} {'å¹³å‡':<10} {'è¨˜æ†¶é«”':<10} {'CPU':<8}")
            print("-" * 100)

            for idx, b in enumerate(bottlenecks, 1):
                print(f"#{idx:<5} {b.operation:<30} {b.total_time:>10.2f}s {b.percentage:>6.1f}% "
                      f"{b.count:>6} {b.avg_time:>8.2f}s {b.memory_impact:>8.1f}MB {b.cpu_impact:>6.1f}%")

            print("=" * 100)

    def _get_optimization_suggestion(self, bottleneck: BottleneckAnalysis) -> str:
        """
        æ ¹æ“šç“¶é ¸åˆ†ææä¾›å„ªåŒ–å»ºè­°

        Args:
            bottleneck: ç“¶é ¸åˆ†æçµæœ

        Returns:
            å„ªåŒ–å»ºè­°å­—ä¸²
        """
        suggestions = []

        # æ™‚é–“å»ºè­°
        if bottleneck.percentage > 50:
            suggestions.append("æ­¤æ“ä½œå ç”¨è¶…é 50% ç¸½æ™‚é–“ï¼Œæ‡‰å„ªå…ˆå„ªåŒ–")
        elif bottleneck.avg_time > 10:
            suggestions.append("å¹³å‡è€—æ™‚è¼ƒé•·ï¼Œè€ƒæ…®ä¸¦è¡Œè™•ç†æˆ–å¿«å–")

        # è¨˜æ†¶é«”å»ºè­°
        if bottleneck.memory_impact > 500:
            suggestions.append("è¨˜æ†¶é«”ä½¿ç”¨é‡å¤§ï¼Œè€ƒæ…®åˆ†æ‰¹è™•ç†")
        elif bottleneck.memory_impact > 100:
            suggestions.append("æ³¨æ„è¨˜æ†¶é«”ä½¿ç”¨ï¼Œå¯èƒ½éœ€è¦å„ªåŒ–è³‡æ–™çµæ§‹")

        # CPU å»ºè­°
        if bottleneck.cpu_impact > 80:
            suggestions.append("CPU ä½¿ç”¨ç‡é«˜ï¼Œè€ƒæ…®ä½¿ç”¨å¤šåŸ·è¡Œç·’")

        # åŸ·è¡Œæ¬¡æ•¸å»ºè­°
        if bottleneck.count > 100:
            suggestions.append("åŸ·è¡Œæ¬¡æ•¸å¤šï¼Œè€ƒæ…®æ‰¹æ¬¡è™•ç†æˆ–å¿«å–çµæœ")

        return "ï¼›".join(suggestions) if suggestions else "é‹ä½œæ­£å¸¸"

    def export_report(self, output_path: str = "performance_report.json"):
        """
        åŒ¯å‡ºæ€§èƒ½å ±å‘Šç‚º JSON æª”æ¡ˆ

        Args:
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": self.get_summary(),
            "bottlenecks": [
                {
                    "operation": b.operation,
                    "total_time": b.total_time,
                    "percentage": b.percentage,
                    "count": b.count,
                    "avg_time": b.avg_time,
                    "max_time": b.max_time,
                    "min_time": b.min_time,
                    "memory_impact": b.memory_impact,
                    "cpu_impact": b.cpu_impact
                }
                for b in self.analyze_bottlenecks(top_n=20)
            ],
            "detailed_metrics": [
                {
                    "name": m.name,
                    "duration": m.duration,
                    "cpu_usage_avg": m.cpu_usage_avg,
                    "memory_usage_peak": m.memory_usage_peak,
                    "timestamp": datetime.fromtimestamp(m.start_time).isoformat(),
                    "metadata": m.metadata
                }
                for m in self.metrics
            ]
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        if RICH_AVAILABLE and console:
            console.print(f"[#DA70D6]âœ“ æ€§èƒ½å ±å‘Šå·²åŒ¯å‡ºï¼š{output_path}[/green]")
        else:
            print(f"âœ“ æ€§èƒ½å ±å‘Šå·²åŒ¯å‡ºï¼š{output_path}")


# å…¨åŸŸç›£æ§å™¨å¯¦ä¾‹ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰
_global_monitor: Optional[PerformanceMonitor] = None


def get_performance_monitor(enabled: bool = True) -> PerformanceMonitor:
    """
    ç²å–å…¨åŸŸæ€§èƒ½ç›£æ§å™¨ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰

    Args:
        enabled: æ˜¯å¦å•Ÿç”¨ç›£æ§

    Returns:
        PerformanceMonitor å¯¦ä¾‹
    """
    global _global_monitor
    if _global_monitor is None:
        _global_monitor = PerformanceMonitor(enabled=enabled)
    return _global_monitor


def reset_monitor():
    """é‡ç½®å…¨åŸŸç›£æ§å™¨"""
    global _global_monitor
    if _global_monitor:
        _global_monitor.clear()


# ä¾¿æ·å‡½æ•¸
def measure(name: str, metadata: Optional[Dict[str, Any]] = None):
    """
    ä¾¿æ·å‡½æ•¸ï¼šæ¸¬é‡æ€§èƒ½ï¼ˆä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰

    ä½¿ç”¨ç¯„ä¾‹ï¼š
        from utils.performance_monitor import measure

        with measure("å½±ç‰‡è™•ç†"):
            process_video()
    """
    monitor = get_performance_monitor()
    return monitor.measure(name, metadata)


def track_performance(name: Optional[str] = None):
    """
    ä¾¿æ·å‡½æ•¸ï¼šè¿½è¹¤æ€§èƒ½ï¼ˆè£é£¾å™¨ï¼‰

    ä½¿ç”¨ç¯„ä¾‹ï¼š
        from utils.performance_monitor import track_performance

        @track_performance("å½±ç‰‡åˆ†æ")
        def analyze_video():
            pass
    """
    monitor = get_performance_monitor()
    return monitor.track_performance(name)


def print_performance_summary():
    """ä¾¿æ·å‡½æ•¸ï¼šåˆ—å°æ€§èƒ½æ‘˜è¦"""
    monitor = get_performance_monitor()
    monitor.print_summary()


def print_bottleneck_report(top_n: int = 10):
    """ä¾¿æ·å‡½æ•¸ï¼šåˆ—å°ç“¶é ¸å ±å‘Š"""
    monitor = get_performance_monitor()
    monitor.print_bottleneck_report(top_n)


def export_performance_report(output_path: str = "performance_report.json"):
    """ä¾¿æ·å‡½æ•¸ï¼šåŒ¯å‡ºæ€§èƒ½å ±å‘Š"""
    monitor = get_performance_monitor()
    monitor.export_report(output_path)


if __name__ == "__main__":
    # æ¸¬è©¦æ€§èƒ½ç›£æ§å™¨
    monitor = get_performance_monitor()

    # æ¸¬è©¦ 1: ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    with monitor.measure("æ¸¬è©¦æ“ä½œ 1"):
        time.sleep(1.0)
        # æ¨¡æ“¬ä¸€äº› CPU å¯†é›†æ“ä½œ
        sum([i**2 for i in range(1000000)])

    # æ¸¬è©¦ 2: ä½¿ç”¨è£é£¾å™¨
    @monitor.track_performance("æ¸¬è©¦æ“ä½œ 2")
    def test_function():
        time.sleep(0.5)
        return "å®Œæˆ"

    test_function()
    test_function()

    # æ¸¬è©¦ 3: å¤šæ¬¡åŸ·è¡Œ
    for i in range(3):
        with monitor.measure("é‡è¤‡æ“ä½œ"):
            time.sleep(0.2)

    # é¡¯ç¤ºçµæœ
    print("\n" + "=" * 50)
    monitor.print_summary()
    print()
    monitor.print_bottleneck_report()
    print()

    # åŒ¯å‡ºå ±å‘Š
    monitor.export_report("test_performance_report.json")
