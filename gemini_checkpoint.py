#!/usr/bin/env python3
"""
Gemini Checkpoint System
æª¢æŸ¥é»ç³»çµ± - è‡ªå‹•ä¿å­˜èˆ‡å›æº¯åŠŸèƒ½

æ­¤æ¨¡çµ„æä¾›ï¼š
1. è‡ªå‹•æª¢æŸ¥é»ä¿å­˜ï¼ˆæª”æ¡ˆè®Šæ›´å‰ï¼‰
2. å›æº¯åŠŸèƒ½ï¼ˆ/rewind æŒ‡ä»¤ + Esc é›™æ“Šï¼‰
3. å¢é‡å„²å­˜ï¼ˆdiff æ¼”ç®—æ³•ï¼‰
4. æª¢æŸ¥é»ç®¡ç†ï¼ˆåˆ—è¡¨ã€åˆªé™¤ã€æ¸…ç†ï¼‰

è¨­è¨ˆç†å¿µï¼š
- è¼•é‡ç´šï¼šåƒ…ä¿å­˜å·®ç•°ï¼Œé™ä½å„²å­˜ç©ºé–“
- å¿«é€Ÿï¼šä½¿ç”¨ difflib é€²è¡Œå¢é‡è¨ˆç®—
- å®‰å…¨ï¼šSQLite äº‹å‹™ä¿è­‰è³‡æ–™å®Œæ•´æ€§
- å¯è¦–åŒ–ï¼šRich UI å±•ç¤ºæª¢æŸ¥é»æ¸…å–®

ä½œè€…ï¼šSaki-tw (with Claude Code)
æ—¥æœŸï¼š2025-10-23
ç‰ˆæœ¬ï¼š1.0.0
"""

import os
import sqlite3
import gzip
import json
import shutil
import hashlib
from pathlib import Path
from typing import Optional, List, Dict, Any, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime
from enum import Enum
import difflib
import uuid
import re

from rich.console import Console
from utils.i18n import safe_t
from rich.table import Table
from rich.panel import Panel
from rich.prompt import Confirm, Prompt
from rich.tree import Tree

console = Console()


# ============================================================================
# è³‡æ–™çµæ§‹
# ============================================================================

class CheckpointType(Enum):
    """æª¢æŸ¥é»é¡å‹"""
    AUTO = "auto"           # è‡ªå‹•æª¢æŸ¥é»ï¼ˆæª”æ¡ˆè®Šæ›´å‰ï¼‰
    MANUAL = "manual"       # æ‰‹å‹•æª¢æŸ¥é»ï¼ˆä½¿ç”¨è€…æ˜ç¢ºå»ºç«‹ï¼‰
    SNAPSHOT = "snapshot"   # å®Œæ•´å¿«ç…§ï¼ˆéå¢é‡ï¼‰
    BRANCH = "branch"       # åˆ†æ”¯æª¢æŸ¥é»ï¼ˆå¯¦é©—æ€§è®Šæ›´ï¼‰


class FileChangeType(Enum):
    """æª”æ¡ˆè®Šæ›´é¡å‹"""
    CREATED = "created"     # æ–°å»ºæª”æ¡ˆ
    MODIFIED = "modified"   # ä¿®æ”¹æª”æ¡ˆ
    DELETED = "deleted"     # åˆªé™¤æª”æ¡ˆ
    RENAMED = "renamed"     # é‡å‘½åæª”æ¡ˆ


@dataclass
class FileChange:
    """æª”æ¡ˆè®Šæ›´è³‡è¨Š"""
    file_path: str                      # æª”æ¡ˆè·¯å¾‘ï¼ˆç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰
    change_type: FileChangeType         # è®Šæ›´é¡å‹
    content_before: Optional[str] = None  # è®Šæ›´å‰å…§å®¹
    content_after: Optional[str] = None   # è®Šæ›´å¾Œå…§å®¹
    diff: Optional[str] = None          # å·®ç•°ï¼ˆunified diff æ ¼å¼ï¼‰
    hash_before: Optional[str] = None   # è®Šæ›´å‰é›œæ¹Š
    hash_after: Optional[str] = None    # è®Šæ›´å¾Œé›œæ¹Š
    size_before: int = 0                # è®Šæ›´å‰å¤§å°ï¼ˆbytesï¼‰
    size_after: int = 0                 # è®Šæ›´å¾Œå¤§å°ï¼ˆbytesï¼‰

    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'file_path': self.file_path,
            'change_type': self.change_type.value,
            'content_before': self.content_before,
            'content_after': self.content_after,
            'diff': self.diff,
            'hash_before': self.hash_before,
            'hash_after': self.hash_after,
            'size_before': self.size_before,
            'size_after': self.size_after
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'FileChange':
        """å¾å­—å…¸å»ºç«‹"""
        data['change_type'] = FileChangeType(data['change_type'])
        return cls(**data)


@dataclass
class Checkpoint:
    """æª¢æŸ¥é»è³‡æ–™çµæ§‹"""
    id: str                             # æª¢æŸ¥é» IDï¼ˆUUIDï¼‰
    timestamp: datetime                 # å»ºç«‹æ™‚é–“
    checkpoint_type: CheckpointType     # æª¢æŸ¥é»é¡å‹
    description: str                    # æè¿°
    tags: List[str] = field(default_factory=list)  # æ¨™ç±¤
    file_changes: List[FileChange] = field(default_factory=list)  # æª”æ¡ˆè®Šæ›´æ¸…å–®
    parent_id: Optional[str] = None     # çˆ¶æª¢æŸ¥é» IDï¼ˆç”¨æ–¼åˆ†æ”¯ï¼‰
    metadata: Dict[str, Any] = field(default_factory=dict)  # é¡å¤–å…ƒæ•¸æ“š
    total_size: int = 0                 # ç¸½å¤§å°ï¼ˆbytesï¼‰
    compressed_size: int = 0            # å£“ç¸®å¾Œå¤§å°ï¼ˆbytesï¼‰

    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'id': self.id,
            'timestamp': self.timestamp.isoformat(),
            'checkpoint_type': self.checkpoint_type.value,
            'description': self.description,
            'tags': self.tags,
            'file_changes': [fc.to_dict() for fc in self.file_changes],
            'parent_id': self.parent_id,
            'metadata': self.metadata,
            'total_size': self.total_size,
            'compressed_size': self.compressed_size
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Checkpoint':
        """å¾å­—å…¸å»ºç«‹"""
        data['timestamp'] = datetime.fromisoformat(data['timestamp'])
        data['checkpoint_type'] = CheckpointType(data['checkpoint_type'])
        data['file_changes'] = [FileChange.from_dict(fc) for fc in data['file_changes']]
        return cls(**data)


# ============================================================================
# å¿«ç…§å¼•æ“ï¼ˆDiff æ¼”ç®—æ³•ï¼‰
# ============================================================================

class SnapshotEngine:
    """
    å¿«ç…§å¼•æ“ - è² è²¬è¨ˆç®—æª”æ¡ˆå·®ç•°èˆ‡å¿«ç…§

    åŠŸèƒ½ï¼š
    - è¨ˆç®—å…©å€‹æª”æ¡ˆç‰ˆæœ¬çš„å·®ç•°ï¼ˆunified diffï¼‰
    - æ‡‰ç”¨å·®ç•°ä»¥æ¢å¾©æª”æ¡ˆ
    - è¨ˆç®—æª”æ¡ˆé›œæ¹Š
    - å£“ç¸®/è§£å£“ç¸®å…§å®¹
    """

    @staticmethod
    def calculate_hash(content: str) -> str:
        """è¨ˆç®—å…§å®¹é›œæ¹Šï¼ˆSHA-256ï¼‰"""
        return hashlib.sha256(content.encode('utf-8')).hexdigest()

    @staticmethod
    def generate_diff(content_before: str, content_after: str, filename: str = "file") -> str:
        """
        ç”Ÿæˆ unified diff

        Args:
            content_before: è®Šæ›´å‰å…§å®¹
            content_after: è®Šæ›´å¾Œå…§å®¹
            filename: æª”æ¡ˆåç¨±ï¼ˆç”¨æ–¼ diff æ¨™é ­ï¼‰

        Returns:
            unified diff å­—ä¸²ï¼ˆæ¨™æº– unified diff æ ¼å¼ï¼‰
        """
        lines_before = content_before.splitlines(keepends=True)
        lines_after = content_after.splitlines(keepends=True)

        # è™•ç†ç©ºæ–‡ä»¶æˆ–ç„¡æ›è¡Œçµå°¾çš„æƒ…æ³
        if content_before and not content_before.endswith('\n'):
            if lines_before:
                lines_before[-1] = lines_before[-1] + '\n'

        if content_after and not content_after.endswith('\n'):
            if lines_after:
                lines_after[-1] = lines_after[-1] + '\n'

        diff_lines = difflib.unified_diff(
            lines_before,
            lines_after,
            fromfile=f"a/{filename}",
            tofile=f"b/{filename}",
            lineterm='\n'
        )

        # ç§»é™¤æ¯è¡Œæœ«å°¾å¤šé¤˜çš„ '\n\n'ï¼ˆå› ç‚º lineterm='\n' æœƒåŠ ä¸Šé¡å¤–çš„æ›è¡Œï¼‰
        result = []
        for line in diff_lines:
            if line.endswith('\n'):
                result.append(line)
            else:
                result.append(line + '\n')

        return ''.join(result)

    @staticmethod
    def apply_diff(content_before: str, diff: str) -> str:
        """
        æ‡‰ç”¨ unified diff ä»¥æ¢å¾©å…§å®¹

        ä½¿ç”¨ç‹€æ…‹æ©Ÿæ¨¡å¼è§£æä¸¦æ‡‰ç”¨ unified diffï¼Œæ”¯æ´å®Œæ•´çš„ diff æ ¼å¼ã€‚
        æ¼”ç®—æ³•è¤‡é›œåº¦ï¼šO(n + m)ï¼Œå…¶ä¸­ n ç‚ºåŸå§‹è¡Œæ•¸ï¼Œm ç‚º diff è¡Œæ•¸ã€‚

        Args:
            content_before: åŸå§‹å…§å®¹
            diff: unified diff æ ¼å¼å­—ä¸²

        Returns:
            æ‡‰ç”¨ diff å¾Œçš„å…§å®¹

        Raises:
            ValueError: ç•¶ diff æ ¼å¼ç„¡æ•ˆæ™‚

        Algorithm:
            1. è§£æ diff ç‚º hunksï¼ˆè®Šæ›´å€å¡Šï¼‰
            2. æŒ‰é †åºè™•ç†æ¯å€‹ hunkï¼š
               - è¤‡è£½ hunk å‰çš„æœªè®Šæ›´è¡Œ
               - æ‡‰ç”¨ hunk å…§çš„è®Šæ›´ï¼ˆ-/+/ æ“ä½œï¼‰
            3. è¤‡è£½å‰©é¤˜çš„æœªè®Šæ›´è¡Œ

        Example:
            >>> original = "line1\\nline2\\nline3\\n"
            >>> diff = "@@ -1,3 +1,3 @@\\n line1\\n-line2\\n+modified\\n line3\\n"
            >>> result = SnapshotEngine.apply_diff(original, diff)
            >>> print(result)
            line1
            modified
            line3
        """
        if not diff or not diff.strip():
            return content_before

        # å°‡å…§å®¹åˆ†å‰²ç‚ºè¡Œï¼ˆä¿ç•™æ›è¡Œç¬¦ï¼‰
        lines_before = content_before.splitlines(keepends=True)
        # è™•ç†ç©ºæ–‡ä»¶æˆ–ç„¡æ›è¡Œçµå°¾çš„æƒ…æ³
        if content_before and not content_before.endswith('\n'):
            if lines_before:
                lines_before[-1] = lines_before[-1] + '\n'

        result_lines = []
        diff_lines = diff.splitlines()

        original_idx = 0  # ç•¶å‰åœ¨åŸå§‹å…§å®¹ä¸­çš„ä½ç½®ï¼ˆå¾ 0 é–‹å§‹ï¼‰
        i = 0  # diff è¡Œç´¢å¼•

        while i < len(diff_lines):
            line = diff_lines[i]

            # è·³é diff æ¨™é ­è¡Œï¼ˆ--- å’Œ +++ï¼‰
            if line.startswith('---') or line.startswith('+++'):
                i += 1
                continue

            # è§£æ hunk æ¨™é ­ï¼š@@ -old_start,old_count +new_start,new_count @@
            if line.startswith('@@'):
                match = re.match(r'@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@', line)
                if not match:
                    # ç„¡æ•ˆçš„ hunk æ¨™é ­ï¼Œè·³é
                    i += 1
                    continue

                # æå–è¡Œè™Ÿï¼ˆdiff ä½¿ç”¨ 1-based ç´¢å¼•ï¼‰
                old_start = int(match.group(1))
                old_count = int(match.group(2)) if match.group(2) else 1
                new_start = int(match.group(3))
                new_count = int(match.group(4)) if match.group(4) else 1

                # è¤‡è£½ hunk å‰çš„æ‰€æœ‰æœªè®Šæ›´è¡Œ
                while original_idx < old_start - 1:
                    if original_idx < len(lines_before):
                        result_lines.append(lines_before[original_idx])
                    original_idx += 1

                # è™•ç† hunk å…§å®¹
                i += 1
                hunk_old_processed = 0
                hunk_new_processed = 0

                while i < len(diff_lines):
                    hunk_line = diff_lines[i]

                    # é‡åˆ°ä¸‹ä¸€å€‹ hunk æˆ–æª”æ¡ˆæ¨™é ­ï¼ŒçµæŸç•¶å‰ hunk
                    if hunk_line.startswith('@@') or hunk_line.startswith('---') or hunk_line.startswith('+++'):
                        break

                    # ç©ºè¡Œå¯èƒ½æ˜¯ diff æ ¼å¼çš„ä¸€éƒ¨åˆ†
                    if not hunk_line:
                        i += 1
                        continue

                    first_char = hunk_line[0]
                    content = hunk_line[1:] if len(hunk_line) > 1 else ''

                    if first_char == ' ':
                        # ä¸Šä¸‹æ–‡è¡Œï¼ˆæœªè®Šæ›´ï¼‰- å¾åŸå§‹å…§å®¹è¤‡è£½
                        if original_idx < len(lines_before):
                            result_lines.append(lines_before[original_idx])
                        original_idx += 1
                        hunk_old_processed += 1
                        hunk_new_processed += 1

                    elif first_char == '-':
                        # åˆªé™¤è¡Œ - è·³éåŸå§‹å…§å®¹ä¸­çš„é€™ä¸€è¡Œ
                        original_idx += 1
                        hunk_old_processed += 1

                    elif first_char == '+':
                        # æ–°å¢è¡Œ - åŠ å…¥çµæœ
                        # ç¢ºä¿è¡Œæœ«æœ‰æ›è¡Œç¬¦ï¼ˆé™¤éæ˜¯æœ€å¾Œä¸€è¡Œä¸”åŸå§‹å…§å®¹ä¹Ÿæ²’æœ‰ï¼‰
                        if content and not content.endswith('\n'):
                            content += '\n'
                        result_lines.append(content)
                        hunk_new_processed += 1

                    elif first_char == '\\':
                        # ç‰¹æ®Šæ¨™è¨˜è¡Œï¼ˆå¦‚ "\ No newline at end of file"ï¼‰
                        # ç§»é™¤æœ€å¾Œä¸€è¡Œçš„æ›è¡Œç¬¦
                        if hunk_line.strip() == '\\ No newline at end of file':
                            if result_lines and result_lines[-1].endswith('\n'):
                                result_lines[-1] = result_lines[-1][:-1]

                    i += 1

                    # æª¢æŸ¥æ˜¯å¦å·²è™•ç†å®Œæ•´å€‹ hunk
                    if hunk_old_processed >= old_count and hunk_new_processed >= new_count:
                        break

                continue

            i += 1

        # è¤‡è£½å‰©é¤˜çš„æœªè®Šæ›´è¡Œ
        while original_idx < len(lines_before):
            result_lines.append(lines_before[original_idx])
            original_idx += 1

        result = ''.join(result_lines)

        # è™•ç†æª”æ¡ˆçµå°¾æ›è¡Œç¬¦
        if content_before and not content_before.endswith('\n'):
            result = result.rstrip('\n')

        return result

    @staticmethod
    def compress(content: str) -> bytes:
        """å£“ç¸®å…§å®¹ï¼ˆgzipï¼‰"""
        return gzip.compress(content.encode('utf-8'))

    @staticmethod
    def decompress(data: bytes) -> str:
        """è§£å£“ç¸®å…§å®¹ï¼ˆgzipï¼‰"""
        return gzip.decompress(data).decode('utf-8')

    @staticmethod
    def create_file_change(
        file_path: str,
        content_before: Optional[str],
        content_after: Optional[str],
        change_type: FileChangeType = FileChangeType.MODIFIED
    ) -> FileChange:
        """
        å»ºç«‹æª”æ¡ˆè®Šæ›´ç‰©ä»¶

        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            content_before: è®Šæ›´å‰å…§å®¹
            content_after: è®Šæ›´å¾Œå…§å®¹
            change_type: è®Šæ›´é¡å‹

        Returns:
            FileChange ç‰©ä»¶
        """
        file_change = FileChange(
            file_path=file_path,
            change_type=change_type
        )

        # è¨ˆç®—é›œæ¹Šèˆ‡å¤§å°
        if content_before:
            file_change.content_before = content_before
            file_change.hash_before = SnapshotEngine.calculate_hash(content_before)
            file_change.size_before = len(content_before.encode('utf-8'))

        if content_after:
            file_change.content_after = content_after
            file_change.hash_after = SnapshotEngine.calculate_hash(content_after)
            file_change.size_after = len(content_after.encode('utf-8'))

        # ç”Ÿæˆ diffï¼ˆåƒ…å°ä¿®æ”¹çš„æª”æ¡ˆï¼‰
        if change_type == FileChangeType.MODIFIED and content_before and content_after:
            file_change.diff = SnapshotEngine.generate_diff(
                content_before,
                content_after,
                filename=os.path.basename(file_path)
            )

        return file_change


# ============================================================================
# æª¢æŸ¥é»ç®¡ç†å™¨
# ============================================================================

class CheckpointManager:
    """
    æª¢æŸ¥é»ç®¡ç†å™¨ - æ ¸å¿ƒç®¡ç†é¡åˆ¥

    åŠŸèƒ½ï¼š
    - å»ºç«‹/åˆªé™¤/åˆ—å‡ºæª¢æŸ¥é»
    - å›æº¯è‡³æŒ‡å®šæª¢æŸ¥é»
    - è‡ªå‹•æ¸…ç†èˆŠæª¢æŸ¥é»
    - æª¢æŸ¥é»æœå°‹èˆ‡éæ¿¾
    """

    def __init__(self, project_root: Path, checkpoints_dir: Optional[Path] = None):
        """
        åˆå§‹åŒ–æª¢æŸ¥é»ç®¡ç†å™¨

        Args:
            project_root: å°ˆæ¡ˆæ ¹ç›®éŒ„
            checkpoints_dir: æª¢æŸ¥é»å„²å­˜ç›®éŒ„ï¼ˆé è¨­ç‚º .checkpointsï¼‰
        """
        self.project_root = Path(project_root).resolve()
        self.checkpoints_dir = checkpoints_dir or (self.project_root / ".checkpoints")
        snapshots_dir=self.checkpoints_dir / "snapshots"
        db_path=self.checkpoints_dir / "metadata.db"

        # å»ºç«‹ç›®éŒ„çµæ§‹
        self.checkpoints_dir.mkdir(parents=True, exist_ok=True)
        self.snapshots_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–è³‡æ–™åº«
        self._init_database()

        console.print(safe_t('common.completed', fallback='[dim]âœ“ CheckpointManager åˆå§‹åŒ–å®Œæˆ: {checkpoints_dir}[/dim]', checkpoints_dir=self.checkpoints_dir))

    def _init_database(self):
        """åˆå§‹åŒ– SQLite è³‡æ–™åº«"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # å»ºç«‹æª¢æŸ¥é»è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS checkpoints (
                id TEXT PRIMARY KEY,
                timestamp TEXT NOT NULL,
                checkpoint_type TEXT NOT NULL,
                description TEXT,
                tags TEXT,
                parent_id TEXT,
                metadata TEXT,
                total_size INTEGER,
                compressed_size INTEGER,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # å»ºç«‹æª”æ¡ˆè®Šæ›´è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS file_changes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                checkpoint_id TEXT NOT NULL,
                file_path TEXT NOT NULL,
                change_type TEXT NOT NULL,
                hash_before TEXT,
                hash_after TEXT,
                size_before INTEGER,
                size_after INTEGER,
                snapshot_path TEXT,
                FOREIGN KEY (checkpoint_id) REFERENCES checkpoints(id) ON DELETE CASCADE
            )
        """)

        # å»ºç«‹ç´¢å¼•
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_timestamp ON checkpoints(timestamp)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_type ON checkpoints(checkpoint_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_checkpoint_id ON file_changes(checkpoint_id)")

        conn.commit()
        conn.close()

    def create_checkpoint(
        self,
        file_changes: List[FileChange],
        description: str = "",
        checkpoint_type: CheckpointType = CheckpointType.AUTO,
        tags: Optional[List[str]] = None,
        parent_id: Optional[str] = None
    ) -> Checkpoint:
        """
        å»ºç«‹æ–°æª¢æŸ¥é»

        Args:
            file_changes: æª”æ¡ˆè®Šæ›´æ¸…å–®
            description: æè¿°
            checkpoint_type: æª¢æŸ¥é»é¡å‹
            tags: æ¨™ç±¤
            parent_id: çˆ¶æª¢æŸ¥é» ID

        Returns:
            å»ºç«‹çš„ Checkpoint ç‰©ä»¶
        """
        checkpoint_id = str(uuid.uuid4())
        timestamp = datetime.now()

        # å»ºç«‹æª¢æŸ¥é»ç‰©ä»¶
        checkpoint = Checkpoint(
            id=checkpoint_id,
            timestamp=timestamp,
            checkpoint_type=checkpoint_type,
            description=description or f"è‡ªå‹•æª¢æŸ¥é» {timestamp.strftime('%Y-%m-%d %H:%M:%S')}",
            tags=tags or [],
            file_changes=file_changes,
            parent_id=parent_id
        )

        # å„²å­˜å¿«ç…§æª”æ¡ˆ
        total_size = 0
        compressed_size = 0

        for file_change in file_changes:
            snapshot_data = file_change.to_dict()
            snapshot_json = json.dumps(snapshot_data, ensure_ascii=False, indent=2)

            # å£“ç¸®ä¸¦å„²å­˜
            compressed = SnapshotEngine.compress(snapshot_json)
            snapshot_filename = f"{checkpoint_id}_{hashlib.md5(file_change.file_path.encode()).hexdigest()}.json.gz"
            snapshot_path = self.snapshots_dir / snapshot_filename

            with open(snapshot_path, 'wb') as f:
                f.write(compressed)

            total_size += len(snapshot_json.encode('utf-8'))
            compressed_size += len(compressed)

        checkpoint.total_size = total_size
        checkpoint.compressed_size = compressed_size

        # å„²å­˜è‡³è³‡æ–™åº«
        self._save_checkpoint_to_db(checkpoint)

        console.print(safe_t('common.completed', fallback='[green]âœ“[/green] æª¢æŸ¥é»å·²å»ºç«‹: [#87CEEB]{checkpoint_id[:8]}[/#87CEEB]', checkpoint_id_short=checkpoint_id[:8]))
        console.print(safe_t('common.message', fallback='  â””â”€ æª”æ¡ˆè®Šæ›´: {len(file_changes)} å€‹', file_changes_count=len(file_changes)))
        console.print(f"  â””â”€ å£“ç¸®ç‡: {compressed_size / total_size * 100:.1f}%" if total_size > 0 else "  â””â”€ ç©ºæª¢æŸ¥é»")

        return checkpoint

    def _save_checkpoint_to_db(self, checkpoint: Checkpoint):
        """å„²å­˜æª¢æŸ¥é»è‡³è³‡æ–™åº«"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            # æ’å…¥æª¢æŸ¥é»
            cursor.execute("""
                INSERT INTO checkpoints (
                    id, timestamp, checkpoint_type, description, tags,
                    parent_id, metadata, total_size, compressed_size
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                checkpoint.id,
                checkpoint.timestamp.isoformat(),
                checkpoint.checkpoint_type.value,
                checkpoint.description,
                json.dumps(checkpoint.tags),
                checkpoint.parent_id,
                json.dumps(checkpoint.metadata),
                checkpoint.total_size,
                checkpoint.compressed_size
            ))

            # æ’å…¥æª”æ¡ˆè®Šæ›´
            for file_change in checkpoint.file_changes:
                snapshot_filename = f"{checkpoint.id}_{hashlib.md5(file_change.file_path.encode()).hexdigest()}.json.gz"

                cursor.execute("""
                    INSERT INTO file_changes (
                        checkpoint_id, file_path, change_type,
                        hash_before, hash_after, size_before, size_after, snapshot_path
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    checkpoint.id,
                    file_change.file_path,
                    file_change.change_type.value,
                    file_change.hash_before,
                    file_change.hash_after,
                    file_change.size_before,
                    file_change.size_after,
                    snapshot_filename
                ))

            conn.commit()
        except Exception as e:
            conn.rollback()
            console.print(safe_t('error.failed', fallback='[red]âœ—[/red] å„²å­˜æª¢æŸ¥é»å¤±æ•—: {e}', e=e))
            raise
        finally:
            conn.close()

    def list_checkpoints(
        self,
        limit: int = 20,
        checkpoint_type: Optional[CheckpointType] = None,
        tags: Optional[List[str]] = None
    ) -> List[Checkpoint]:
        """
        åˆ—å‡ºæª¢æŸ¥é»

        Args:
            limit: æœ€å¤§æ•¸é‡
            checkpoint_type: éæ¿¾æª¢æŸ¥é»é¡å‹
            tags: éæ¿¾æ¨™ç±¤

        Returns:
            Checkpoint ç‰©ä»¶æ¸…å–®
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        query = "SELECT * FROM checkpoints WHERE 1=1"
        params = []

        if checkpoint_type:
            query += " AND checkpoint_type = ?"
            params.append(checkpoint_type.value)

        query += " ORDER BY timestamp DESC LIMIT ?"
        params.append(limit)

        cursor.execute(query, params)
        rows = cursor.fetchall()

        checkpoints = []
        for row in rows:
            checkpoint_data = {
                'id': row[0],
                'timestamp': row[1],
                'checkpoint_type': row[2],
                'description': row[3],
                'tags': json.loads(row[4]) if row[4] else [],
                'parent_id': row[5],
                'metadata': json.loads(row[6]) if row[6] else {},
                'total_size': row[7],
                'compressed_size': row[8],
                'file_changes': []
            }

            # è¼‰å…¥æª”æ¡ˆè®Šæ›´
            cursor.execute("""
                SELECT file_path, change_type, hash_before, hash_after,
                       size_before, size_after, snapshot_path
                FROM file_changes
                WHERE checkpoint_id = ?
            """, (row[0],))

            file_changes_rows = cursor.fetchall()
            for fc_row in file_changes_rows:
                file_change_dict = {
                    'file_path': fc_row[0],
                    'change_type': fc_row[1],
                    'hash_before': fc_row[2],
                    'hash_after': fc_row[3],
                    'size_before': fc_row[4] or 0,
                    'size_after': fc_row[5] or 0,
                    'content_before': None,
                    'content_after': None,
                    'diff': None
                }
                checkpoint_data['file_changes'].append(file_change_dict)

            checkpoint = Checkpoint.from_dict(checkpoint_data)

            # éæ¿¾æ¨™ç±¤
            if tags:
                if any(tag in checkpoint.tags for tag in tags):
                    checkpoints.append(checkpoint)
            else:
                checkpoints.append(checkpoint)

        conn.close()
        return checkpoints

    def get_checkpoint(self, checkpoint_id: str) -> Optional[Checkpoint]:
        """å–å¾—æŒ‡å®šæª¢æŸ¥é»"""
        checkpoints = self.list_checkpoints(limit=1000)
        for cp in checkpoints:
            if cp.id.startswith(checkpoint_id):
                return cp
        return None

    def rewind_to_checkpoint(self, checkpoint_id: str, confirm: bool = True) -> bool:
        """
        å›æº¯è‡³æŒ‡å®šæª¢æŸ¥é»

        Args:
            checkpoint_id: æª¢æŸ¥é» IDï¼ˆå¯ç‚ºéƒ¨åˆ† IDï¼‰
            confirm: æ˜¯å¦éœ€è¦ç¢ºèª

        Returns:
            æ˜¯å¦æˆåŠŸå›æº¯
        """
        checkpoint = self.get_checkpoint(checkpoint_id)

        if not checkpoint:
            console.print(safe_t('common.message', fallback='[red]âœ—[/red] æ‰¾ä¸åˆ°æª¢æŸ¥é»: {checkpoint_id}', checkpoint_id=checkpoint_id))
            return False

        # é¡¯ç¤ºæª¢æŸ¥é»è³‡è¨Š
        self._display_checkpoint_detail(checkpoint)

        # ç¢ºèª
        if confirm:
            if not Confirm.ask(f"\nç¢ºå®šè¦å›æº¯è‡³æ­¤æª¢æŸ¥é»å—ï¼Ÿ"):
                console.print(safe_t('common.message', fallback='[#DDA0DD]å·²å–æ¶ˆå›æº¯[/#DDA0DD]'))
                return False

        # åŸ·è¡Œå›æº¯
        console.print(safe_t('common.message', fallback='\n[#87CEEB]é–‹å§‹å›æº¯è‡³æª¢æŸ¥é» {checkpoint_id_short}...[/#87CEEB]', checkpoint_id_short=checkpoint.id[:8]))

        success_count = 0
        fail_count = 0

        for file_change in checkpoint.file_changes:
            try:
                file_path = self.project_root / file_change.file_path

                # è¼‰å…¥å¿«ç…§
                snapshot_filename = f"{checkpoint.id}_{hashlib.md5(file_change.file_path.encode()).hexdigest()}.json.gz"
                snapshot_path = self.snapshots_dir / snapshot_filename

                if not snapshot_path.exists():
                    console.print(safe_t('common.message', fallback='  [#DDA0DD]âš [/#DDA0DD] å¿«ç…§æª”æ¡ˆä¸å­˜åœ¨: {file_path}', file_path=file_change.file_path))
                    fail_count += 1
                    continue

                with open(snapshot_path, 'rb') as f:
                    compressed_data = f.read()
                    snapshot_json = SnapshotEngine.decompress(compressed_data)
                    snapshot_data = json.loads(snapshot_json)

                # æ ¹æ“šè®Šæ›´é¡å‹åŸ·è¡Œæ“ä½œ
                if file_change.change_type == FileChangeType.CREATED:
                    # åˆªé™¤æ–°å»ºçš„æª”æ¡ˆ
                    if file_path.exists():
                        file_path.unlink()
                        console.print(safe_t('common.completed', fallback='  [green]âœ“[/green] åˆªé™¤: {file_path}', file_path=file_change.file_path))
                    success_count += 1

                elif file_change.change_type == FileChangeType.DELETED:
                    # æ¢å¾©åˆªé™¤çš„æª”æ¡ˆ
                    file_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(snapshot_data['content_before'] or '')
                    console.print(safe_t('common.completed', fallback='  [green]âœ“[/green] æ¢å¾©: {file_path}', file_path=file_change.file_path))
                    success_count += 1

                elif file_change.change_type == FileChangeType.MODIFIED:
                    # æ¢å¾©ä¿®æ”¹çš„æª”æ¡ˆ
                    file_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(snapshot_data['content_before'] or '')
                    console.print(safe_t('common.completed', fallback='  [green]âœ“[/green] æ¢å¾©: {file_path}', file_path=file_change.file_path))
                    success_count += 1

            except Exception as e:
                console.print(safe_t('error.failed', fallback='  [red]âœ—[/red] å¤±æ•—: {file_path} - {e}', file_path=file_change.file_path, e=e))
                fail_count += 1

        # é¡¯ç¤ºçµæœ
        console.print(safe_t('common.completed', fallback='\n[green]âœ“[/green] å›æº¯å®Œæˆ:'))
        console.print(safe_t('common.message', fallback='  â””â”€ æˆåŠŸ: {success_count} å€‹æª”æ¡ˆ', success_count=success_count))
        if fail_count > 0:
            console.print(safe_t('error.failed', fallback='  â””â”€ å¤±æ•—: {fail_count} å€‹æª”æ¡ˆ', fail_count=fail_count))

        return fail_count == 0

    def _display_checkpoint_detail(self, checkpoint: Checkpoint):
        """é¡¯ç¤ºæª¢æŸ¥é»è©³ç´°è³‡è¨Š"""
        panel = Panel(
            f"[bold #87CEEB]{checkpoint.description}[/bold #87CEEB]\n\n"
            f"ID: {checkpoint_id_short}...\n"
            f"æ™‚é–“: {checkpoint.timestamp.strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"é¡å‹: {checkpoint.checkpoint_type.value}\n"
            f"æª”æ¡ˆè®Šæ›´: {len(checkpoint.file_changes)} å€‹\n"
            f"å¤§å°: {checkpoint.total_size / 1024:.2f} KB â†’ {checkpoint.compressed_size / 1024:.2f} KB "
            f"(å£“ç¸®ç‡ {checkpoint.compressed_size / checkpoint.total_size * 100:.1f}%)",
            title="[bold]æª¢æŸ¥é»è³‡è¨Š[/bold]",
            border_style="#87CEEB"
        )
        console.print(panel)

        # é¡¯ç¤ºæª”æ¡ˆæ¸…å–®
        if checkpoint.file_changes:
            table = Table(title="æª”æ¡ˆè®Šæ›´æ¸…å–®", show_header=True, header_style="bold #DDA0DD")
            table.add_column("è®Šæ›´é¡å‹", style="#87CEEB", width=12)
            table.add_column("æª”æ¡ˆè·¯å¾‘", style="white")
            table.add_column("å¤§å°è®ŠåŒ–", justify="right", style="#DDA0DD")

            for fc in checkpoint.file_changes:
                change_emoji = {
                    FileChangeType.CREATED: "â• æ–°å»º",
                    FileChangeType.MODIFIED: "ğŸ“ ä¿®æ”¹",
                    FileChangeType.DELETED: "â– åˆªé™¤",
                    FileChangeType.RENAMED: "ğŸ”„ é‡å‘½å"
                }.get(fc.change_type, "â“ æœªçŸ¥")

                size_change = f"{fc.size_before} â†’ {fc.size_after}" if fc.change_type == FileChangeType.MODIFIED else str(fc.size_after)

                table.add_row(change_emoji, fc.file_path, size_change)

            console.print(table)

    def show_checkpoints_ui(self, limit: int = 20):
        """é¡¯ç¤ºæª¢æŸ¥é»æ¸…å–® UI"""
        checkpoints = self.list_checkpoints(limit=limit)

        if not checkpoints:
            console.print(safe_t('common.message', fallback='[#DDA0DD]æ²’æœ‰æª¢æŸ¥é»[/#DDA0DD]'))
            return

        table = Table(title=f"æª¢æŸ¥é»æ¸…å–®ï¼ˆæœ€è¿‘ {len(checkpoints)} å€‹ï¼‰", show_header=True, header_style="bold #DDA0DD")
        table.add_column("ID", style="#87CEEB", width=10)
        table.add_column("æ™‚é–“", style="white", width=20)
        table.add_column("é¡å‹", style="#DDA0DD", width=10)
        table.add_column("æè¿°", style="white")
        table.add_column("æª”æ¡ˆæ•¸", justify="right", style="green", width=8)

        for cp in checkpoints:
            type_emoji = {
                CheckpointType.AUTO: "ğŸ¤–",
                CheckpointType.MANUAL: "ğŸ‘¤",
                CheckpointType.SNAPSHOT: "ğŸ“¸",
                CheckpointType.BRANCH: "ğŸŒ¿"
            }.get(cp.checkpoint_type, "â“")

            table.add_row(
                cp.id[:8],
                cp.timestamp.strftime('%Y-%m-%d %H:%M:%S'),
                f"{type_emoji} {cp.checkpoint_type.value}",
                cp.description[:50] + "..." if len(cp.description) > 50 else cp.description,
                str(len(cp.file_changes))
            )

        console.print(table)

    def delete_checkpoint(self, checkpoint_id: str) -> bool:
        """åˆªé™¤æª¢æŸ¥é»"""
        checkpoint = self.get_checkpoint(checkpoint_id)

        if not checkpoint:
            console.print(safe_t('common.message', fallback='[red]âœ—[/red] æ‰¾ä¸åˆ°æª¢æŸ¥é»: {checkpoint_id}', checkpoint_id=checkpoint_id))
            return False

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            # åˆªé™¤å¿«ç…§æª”æ¡ˆ
            for file_change in checkpoint.file_changes:
                snapshot_filename = f"{checkpoint.id}_{hashlib.md5(file_change.file_path.encode()).hexdigest()}.json.gz"
                snapshot_path = self.snapshots_dir / snapshot_filename
                if snapshot_path.exists():
                    snapshot_path.unlink()

            # åˆªé™¤è³‡æ–™åº«è¨˜éŒ„
            cursor.execute("DELETE FROM file_changes WHERE checkpoint_id = ?", (checkpoint.id,))
            cursor.execute("DELETE FROM checkpoints WHERE id = ?", (checkpoint.id,))
            conn.commit()

            console.print(safe_t('common.completed', fallback='[green]âœ“[/green] å·²åˆªé™¤æª¢æŸ¥é»: {checkpoint_id_short}', checkpoint_id_short=checkpoint.id[:8]))
            return True

        except Exception as e:
            conn.rollback()
            console.print(safe_t('error.failed', fallback='[red]âœ—[/red] åˆªé™¤å¤±æ•—: {e}', e=e))
            return False
        finally:
            conn.close()

    def cleanup_old_checkpoints(self, keep_count: int = 50, dry_run: bool = True):
        """
        æ¸…ç†èˆŠæª¢æŸ¥é»

        Args:
            keep_count: ä¿ç•™æœ€è¿‘ N å€‹æª¢æŸ¥é»
            dry_run: æ˜¯å¦ç‚ºè©¦é‹è¡Œï¼ˆä¸å¯¦éš›åˆªé™¤ï¼‰
        """
        checkpoints = self.list_checkpoints(limit=1000)

        if len(checkpoints) <= keep_count:
            console.print(safe_t('common.message', fallback='[green]ç„¡éœ€æ¸…ç†ï¼ˆå…± {len(checkpoints)} å€‹æª¢æŸ¥é»ï¼Œä¿ç•™ {keep_count} å€‹ï¼‰[/green]', checkpoints_count=len(checkpoints), keep_count=keep_count))
            return

        to_delete = checkpoints[keep_count:]

        console.print(safe_t('common.message', fallback='\n[#DDA0DD]å°‡åˆªé™¤ {len(to_delete)} å€‹èˆŠæª¢æŸ¥é»:[/#DDA0DD]', to_delete_count=len(to_delete)))
        for cp in to_delete[:10]:  # é¡¯ç¤ºå‰ 10 å€‹
            console.print(f"  - {cp.id[:8]} | {cp.timestamp.strftime('%Y-%m-%d %H:%M:%S')} | {cp.description[:40]}")

        if len(to_delete) > 10:
            console.print(safe_t('common.message', fallback='  ... åŠå…¶ä»– {remaining_count} å€‹', remaining_count=len(to_delete) - 10))

        if dry_run:
            console.print(safe_t('common.message', fallback='\n[#87CEEB]ï¼ˆè©¦é‹è¡Œæ¨¡å¼ï¼Œæœªå¯¦éš›åˆªé™¤ï¼‰[/#87CEEB]'))
            return

        if not Confirm.ask("\nç¢ºå®šè¦åˆªé™¤é€™äº›æª¢æŸ¥é»å—ï¼Ÿ"):
            console.print(safe_t('common.message', fallback='[#DDA0DD]å·²å–æ¶ˆæ¸…ç†[/#DDA0DD]'))
            return

        deleted_count = 0
        for cp in to_delete:
            if self.delete_checkpoint(cp.id):
                deleted_count += 1

        console.print(safe_t('common.completed', fallback='\n[green]âœ“[/green] å·²æ¸…ç† {deleted_count} å€‹èˆŠæª¢æŸ¥é»', deleted_count=deleted_count))


# ============================================================================
# ä¾¿åˆ©å‡½æ•¸
# ============================================================================

# å…¨åŸŸç®¡ç†å™¨å¯¦ä¾‹ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰
_global_checkpoint_manager: Optional[CheckpointManager] = None


def get_checkpoint_manager(project_root: Optional[Path] = None) -> CheckpointManager:
    """å–å¾—å…¨åŸŸæª¢æŸ¥é»ç®¡ç†å™¨"""
    global _global_checkpoint_manager

    if _global_checkpoint_manager is None:
        if project_root is None:
            project_root = Path.cwd()
        _global_checkpoint_manager = CheckpointManager(project_root)

    return _global_checkpoint_manager


def auto_checkpoint(file_paths: List[str], description: str = ""):
    """
    è‡ªå‹•å»ºç«‹æª¢æŸ¥é»ï¼ˆä¾¿åˆ©å‡½æ•¸ï¼‰

    Args:
        file_paths: æª”æ¡ˆè·¯å¾‘æ¸…å–®
        description: æè¿°
    """
    manager = get_checkpoint_manager()

    file_changes = []
    for file_path in file_paths:
        full_path = Path(file_path)
        if full_path.exists():
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()

            file_change = SnapshotEngine.create_file_change(
                file_path=str(full_path.relative_to(manager.project_root)),
                content_before=content,
                content_after=content,
                change_type=FileChangeType.MODIFIED
            )
            file_changes.append(file_change)

    if file_changes:
        manager.create_checkpoint(
            file_changes=file_changes,
            description=description,
            checkpoint_type=CheckpointType.AUTO
        )


# ============================================================================
# CLI æ¸¬è©¦ä»‹é¢
# ============================================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Gemini Checkpoint System")
    parser.add_argument('command', choices=['list', 'create', 'rewind', 'delete', 'cleanup', 'test'],
                        help='æŒ‡ä»¤')
    parser.add_argument('--id', help='æª¢æŸ¥é» ID')
    parser.add_argument('--limit', type=int, default=20, help='åˆ—å‡ºæ•¸é‡')
    parser.add_argument('--keep', type=int, default=50, help='ä¿ç•™æ•¸é‡')
    parser.add_argument('--description', help='æè¿°')
    parser.add_argument('--files', nargs='+', help='æª”æ¡ˆæ¸…å–®')
    parser.add_argument('--dry-run', action='store_true', help='è©¦é‹è¡Œ')

    args = parser.parse_args()

    manager = get_checkpoint_manager()

    if args.command == 'list':
        manager.show_checkpoints_ui(limit=args.limit)

    elif args.command == 'create':
        if not args.files:
            console.print(safe_t('common.message', fallback='[red]éœ€è¦æŒ‡å®š --files[/red]'))
        else:
            auto_checkpoint(args.files, args.description or "")

    elif args.command == 'rewind':
        if not args.id:
            console.print(safe_t('common.message', fallback='[red]éœ€è¦æŒ‡å®š --id[/red]'))
        else:
            manager.rewind_to_checkpoint(args.id)

    elif args.command == 'delete':
        if not args.id:
            console.print(safe_t('common.message', fallback='[red]éœ€è¦æŒ‡å®š --id[/red]'))
        else:
            manager.delete_checkpoint(args.id)

    elif args.command == 'cleanup':
        manager.cleanup_old_checkpoints(keep_count=args.keep, dry_run=args.dry_run)

    elif args.command == 'test':
        # æ¸¬è©¦æ¨¡å¼
        console.print(safe_t('common.message', fallback='[#87CEEB]æ¸¬è©¦æ¨¡å¼ - å»ºç«‹ç¯„ä¾‹æª¢æŸ¥é»[/#87CEEB]\n'))

        # å»ºç«‹æ¸¬è©¦æª”æ¡ˆ
        test_file = Path("test_checkpoint.txt")
        test_file.write_text("Hello, World!\nThis is a test file.")

        # å»ºç«‹æª¢æŸ¥é»
        auto_checkpoint([str(test_file)], "æ¸¬è©¦æª¢æŸ¥é»")

        # åˆ—å‡ºæª¢æŸ¥é»
        manager.show_checkpoints_ui(limit=5)

        # æ¸…ç†
        test_file.unlink()
        console.print(safe_t('common.completed', fallback='\n[green]âœ“[/green] æ¸¬è©¦å®Œæˆ'))
